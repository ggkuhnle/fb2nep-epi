{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_ci_next",
   "metadata": {},
   "source": [
    "# FB2NEP Workbook 10 – Causal Inference in Nutritional Epidemiology: Where Next?\n",
    "\n",
    "Version 0.0.5\n",
    "\n",
    "This workbook provides an accessible introduction to **modern causal inference approaches** that extend beyond traditional regression.\n",
    "\n",
    "By the end of this workbook, you should understand the principles behind:\n",
    "\n",
    "- **Mendelian randomisation (MR)**: principles, required assumptions, and a practical demonstration using the MR-Base API wrapper.\n",
    "- **Negative controls**: using exposures or outcomes that should not be associated to detect uncontrolled confounding.\n",
    "- **G-methods** (brief introduction): g-formula, inverse probability weighting (IPW), and marginal structural models (MSM).\n",
    "- **Trial emulation using cohort data**: designing an observational analysis that mimics a randomised controlled trial.\n",
    "\n",
    "The approach is conceptual. The aim is not to perform analyses that require external consortia-level infrastructure, but rather to show **how these methods work**, how they relate to familiar epidemiological ideas, and how they can be implemented in practice.\n",
    "\n",
    "For clarity:\n",
    "\n",
    "- All examples use the **synthetic FB2NEP cohort**.\n",
    "- MR sections use only *simulated* genetic instruments; no real genetic data are distributed to students.\n",
    "- Where specialist software is required (for example, `TwoSampleMR`), we illustrate the workflow but avoid large downloads.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bootstrap",
   "metadata": {},
   "source": [
    "## 0. Initialise the repository and load the synthetic FB2NEP cohort\n",
    "\n",
    "Run this cell first. It ensures that the notebook can run on Google Colab or in a local Jupyter environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bootstrap_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bootstrap from: ../scripts/bootstrap.py\n",
      "Dataset found: data/synthetic/fb2nep.csv ✅\n",
      "Repository root: /Users/gunter/Documents/fb2nep-epi\n",
      "Main dataset: data/synthetic/fb2nep.csv\n",
      "df shape: (25000, 27)\n",
      "IN_COLAB: False\n"
     ]
    }
   ],
   "source": [
    "# FB2NEP bootstrap cell – use in *all* workbooks\n",
    "#\n",
    "# This cell initialises the repository context and loads the synthetic cohort\n",
    "# into a DataFrame called df. It tries a few possible locations for scripts/bootstrap.py.\n",
    "\n",
    "import pathlib\n",
    "import runpy\n",
    "\n",
    "bootstrap_candidates = [\n",
    "    \"scripts/bootstrap.py\",\n",
    "    \"../scripts/bootstrap.py\",\n",
    "    \"../../scripts/bootstrap.py\",\n",
    "]\n",
    "\n",
    "bootstrap_ns = None\n",
    "\n",
    "for rel in bootstrap_candidates:\n",
    "    p = pathlib.Path(rel)\n",
    "    if p.exists():\n",
    "        print(f\"Loading bootstrap from: {p}\")\n",
    "        bootstrap_ns = runpy.run_path(str(p))\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find scripts/bootstrap.py. \"\n",
    "        \"Please check that you are running this notebook inside fb2nep-epi.\"\n",
    "    )\n",
    "\n",
    "if \"init\" not in bootstrap_ns:\n",
    "    raise RuntimeError(\"bootstrap.py does not define init().\")\n",
    "\n",
    "df, CTX = bootstrap_ns[\"init\"]()\n",
    "\n",
    "REPO_ROOT = CTX.repo_root\n",
    "CSV_REL = CTX.csv_rel\n",
    "IN_COLAB = CTX.in_colab\n",
    "\n",
    "print(\"Repository root:\", REPO_ROOT)\n",
    "print(\"Main dataset:\", CSV_REL)\n",
    "print(\"df shape:\", df.shape)\n",
    "print(\"IN_COLAB:\", IN_COLAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1_mr_intro",
   "metadata": {},
   "source": [
    "## 1. Mendelian randomisation (MR)\n",
    "\n",
    "### 1.1 Conceptual introduction\n",
    "\n",
    "Mendelian randomisation exploits the **random allocation of alleles at conception** as a natural experiment. Genetic variants associated with an exposure of interest (for example, LDL-cholesterol or alcohol consumption) are used as **instrumental variables**.\n",
    "\n",
    "MR relies on three key assumptions:\n",
    "\n",
    "1. **Relevance**: The genetic variant is associated with the exposure.\n",
    "2. **Independence**: The genetic variant is independent of confounders of the exposure–outcome relationship.\n",
    "3. **Exclusion restriction**: The variant affects the outcome *only* through the exposure of interest.\n",
    "\n",
    "In nutritional epidemiology, MR can be informative for questions such as:\n",
    "\n",
    "- Does higher BMI cause increased risk of type 2 diabetes?\n",
    "- Does alcohol intake causally affect blood pressure?\n",
    "- Do circulating nutrient levels (for example, vitamin D) have causal effects on health outcomes?\n",
    "\n",
    "Because the FB2NEP cohort does not contain real genetic data, we simulate a small set of plausible genetic instruments to illustrate the workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1b_simulate_instruments",
   "metadata": {},
   "source": [
    "### 1.2 Simulated genetic instruments\n",
    "\n",
    "We create three simulated single-nucleotide polymorphisms (SNPs) that are modestly associated with a continuous phenotype such as BMI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simulate_snps",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(11088)\n",
    "\n",
    "# Copy the main dataset to avoid accidental modification.\n",
    "df_mr = df.copy()\n",
    "\n",
    "# Simulate three SNPs assuming Hardy–Weinberg equilibrium with varying allele frequencies.\n",
    "allele_freqs = [0.15, 0.25, 0.40]\n",
    "\n",
    "for i, p in enumerate(allele_freqs, start=1):\n",
    "    # Each SNP coded 0/1/2 for number of effect alleles.\n",
    "    df_mr[f\"SNP{i}\"] = np.random.binomial(n=2, p=p, size=len(df_mr))\n",
    "\n",
    "# Display the first rows to verify structure.\n",
    "df_mr[[\"SNP1\", \"SNP2\", \"SNP3\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mr_first_stage",
   "metadata": {},
   "source": [
    "### 1.3 First-stage regression (SNP → exposure)\n",
    "\n",
    "In MR, the first step is to show that the instrument is associated with the exposure. Here we demonstrate the principle using BMI as the exposure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mr_iv_firststage_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = df_mr[[\"SNP1\", \"SNP2\", \"SNP3\"]]\n",
    "X = sm.add_constant(X)\n",
    "y = df_mr[\"BMI\"]\n",
    "\n",
    "model_first = sm.OLS(y, X).fit()\n",
    "model_first.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mr_second_stage",
   "metadata": {},
   "source": [
    "### 1.4 Second-stage regression (exposure → outcome) using predicted exposure\n",
    "\n",
    "We predict BMI using the genetic instruments and then regress the health outcome on the **genetically predicted BMI**, not the observed BMI.\n",
    "\n",
    "We choose systolic blood pressure (SBP) as the synthetic outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mr_second_stage_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted BMI from stage 1\n",
    "df_mr[\"BMI_hat\"] = model_first.predict(X)\n",
    "\n",
    "# Second-stage regression of outcome on predicted exposure\n",
    "Y = df_mr[\"SBP\"]\n",
    "X2 = sm.add_constant(df_mr[\"BMI_hat\"])\n",
    "\n",
    "model_second = sm.OLS(Y, X2).fit()\n",
    "model_second.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mr_limitations",
   "metadata": {},
   "source": [
    "### 1.5 Interpretation and limitations\n",
    "\n",
    "This two-stage approach illustrates the logic of MR but is not robust MR analysis. Real pipelines use specialised estimators, multiple sensitivity tests, and large GWAS summary statistics.\n",
    "\n",
    "Key limitations to emphasise to students:\n",
    "\n",
    "- Pleiotropy can invalidate the exclusion restriction.\n",
    "- Weak instruments can bias results towards the confounded observational estimate.\n",
    "- MR typically estimates lifetime or long-term effects, not short-term nutritional interventions.\n",
    "\n",
    "Nevertheless, MR provides an important complement to traditional epidemiology.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2_negative_controls",
   "metadata": {},
   "source": [
    "## 2. Negative controls\n",
    "\n",
    "Negative controls are variables that should **not** be related to the exposure or outcome if the assumed causal model is correct.\n",
    "\n",
    "- **Negative control exposure**: an exposure that should have no effect on the outcome.\n",
    "- **Negative control outcome**: an outcome that should not plausibly be affected by the exposure.\n",
    "\n",
    "If a strong association is observed nevertheless, this indicates **residual confounding**, measurement error, or selection bias.\n",
    "\n",
    "In the FB2NEP cohort we illustrate a negative control exposure: a synthetic variable designed to be unrelated to the outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative_control_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11088)\n",
    "\n",
    "# Create a synthetic variable unrelated to health outcomes.\n",
    "df_mr[\"NC_exposure\"] = np.random.normal(loc=0, scale=1, size=len(df_mr))\n",
    "\n",
    "X = sm.add_constant(df_mr[\"NC_exposure\"])\n",
    "Y = df_mr[\"SBP\"]\n",
    "\n",
    "model_nc = sm.OLS(Y, X).fit()\n",
    "model_nc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3_gmethods_intro",
   "metadata": {},
   "source": [
    "## 3. G-methods: a brief introduction\n",
    "\n",
    "G-methods were developed to address situations where traditional regression fails due to **time-varying confounding** affected by prior exposure.\n",
    "\n",
    "Three key ideas:\n",
    "\n",
    "- **G-formula**: models the joint distribution of the outcome conditional on exposure and covariates, and computes counterfactual outcomes.\n",
    "- **Inverse probability weighting (IPW)**: weights individuals by the inverse of the probability of receiving their observed exposure pattern.\n",
    "- **Marginal structural models (MSMs)**: use IPW to estimate causal effects in the presence of time-varying confounding.\n",
    "\n",
    "Here we illustrate IPW using a simplified binary exposure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "section3_ipw_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, define a binary exposure: high physical activity\n",
    "df_ipw = df.copy()\n",
    "df_ipw[\"highPA_bin\"] = (df_ipw[\"highPA\"] > df_ipw[\"highPA\"].median()).astype(int)\n",
    "\n",
    "# Step 1: Estimate propensity scores\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = sm.add_constant(df_ipw[[\"age\", \"BMI\", \"SES\"]])  # illustrative covariates\n",
    "y = df_ipw[\"highPA_bin\"]\n",
    "\n",
    "ps_model = sm.Logit(y, X).fit()\n",
    "df_ipw[\"ps\"] = ps_model.predict(X)\n",
    "\n",
    "# Step 2: Compute inverse probability weights\n",
    "df_ipw[\"w\"] = np.where(df_ipw[\"highPA_bin\"] == 1,\n",
    "                        1 / df_ipw[\"ps\"],\n",
    "                        1 / (1 - df_ipw[\"ps\"]))\n",
    "\n",
    "# Step 3: Weighted regression of outcome (e.g. SBP) on exposure\n",
    "Y = df_ipw[\"SBP\"]\n",
    "X = sm.add_constant(df_ipw[\"highPA_bin\"])\n",
    "\n",
    "ipw_model = sm.WLS(Y, X, weights=df_ipw[\"w\"]).fit()\n",
    "ipw_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4_trial_emulation_intro",
   "metadata": {},
   "source": [
    "## 4. Trial emulation using cohort data\n",
    "\n",
    "Randomised controlled trials are often infeasible in nutrition. Trial emulation attempts to reproduce, as closely as possible, the key design features of an RCT within observational data.\n",
    "\n",
    "**Core components:**\n",
    "\n",
    "1. Eligibility criteria\n",
    "2. Time zero (clear baseline)\n",
    "3. Well-defined exposure strategies\n",
    "4. Follow-up and censoring rules\n",
    "5. Pre-specified causal contrast\n",
    "\n",
    "Here we illustrate a very simple emulation: a trial of increasing daily physical activity to reduce systolic blood pressure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trial_emulation_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified trial emulation: treat highPA (>median) as 'intervention'\n",
    "\n",
    "df_te = df.copy()\n",
    "df_te[\"intervention\"] = (df_te[\"highPA\"] > df_te[\"highPA\"].median()).astype(int)\n",
    "\n",
    "# Model the outcome at follow-up (synthetic: SBP)\n",
    "Y = df_te[\"SBP\"]\n",
    "X = sm.add_constant(df_te[\"intervention\"])\n",
    "\n",
    "trial_model = sm.OLS(Y, X).fit()\n",
    "trial_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_closing",
   "metadata": {},
   "source": [
    "## 5. Summary and further reading\n",
    "\n",
    "This workbook introduced several modern causal inference approaches that are increasingly relevant in nutritional epidemiology.\n",
    "\n",
    "Students should take away the following key points:\n",
    "\n",
    "- MR uses genetic variants as instruments but requires strong assumptions.\n",
    "- Negative controls help detect unmeasured confounding.\n",
    "- G-methods allow estimation of causal effects under time-varying confounding.\n",
    "- Trial emulation provides a rigorous framework for analysing cohort data in a quasi-experimental way.\n",
    "\n",
    "For further reading:\n",
    "\n",
    "- Hernán and Robins: *Causal Inference – What If?*\n",
    "- Davey Smith and Ebrahim: Mendelian randomisation foundational papers.\n",
    "- Danaei et al.: Trial emulation case studies using large observational cohorts.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
