{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_fb2nep_7",
   "metadata": {},
   "source": [
    "# FB2NEP Workbook 7 – Confounding, DAGs, and Causal Structure\n",
    "\n",
    "Version 0.0.5\n",
    "\n",
    "This workbook builds on Workbook 6.\n",
    "\n",
    "In Workbook 6, we treated regression as a practical tool for estimating associations\n",
    "between an exposure and an outcome, and we focused on model types (linear, logistic,\n",
    "Cox), assumptions, diagnostics, and basic interpretation of coefficients (β, OR, RR, HR).\n",
    "\n",
    "In this workbook, we move from **association** to **causal thinking**. We introduce:\n",
    "\n",
    "- Confounders.\n",
    "- Colliders.\n",
    "- Mediators.\n",
    "- Directed acyclic graphs (DAGs) as a way to formalise causal assumptions.\n",
    "- Approaches to adjustment (stratification and regression).\n",
    "- The special role of **energy intake** in nutritional epidemiology.\n",
    "- A brief introduction to **counterfactual** thinking.\n",
    "\n",
    "A more formal treatment of causal inference, including modern notation and methods,\n",
    "is given in **Workbook 9**. Here we focus on intuition and on how causal structure\n",
    "affects regression analyses in practice.\n",
    "\n",
    "We will use the synthetic *FB2NEP cohort* throughout. The precise variable names may\n",
    "differ slightly from those used here; if you obtain an error (for example, `KeyError`),\n",
    "carefully check the column names of the dataset and adapt the code accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bootstrap_fb2nep_7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FB2NEP bootstrap cell – use in *all* workbooks\n",
    "#\n",
    "# This cell initialises the repository context and loads the synthetic cohort\n",
    "# into a DataFrame called df. It tries a few possible locations for scripts/bootstrap.py.\n",
    "\n",
    "import pathlib\n",
    "import runpy\n",
    "\n",
    "bootstrap_candidates = [\n",
    "    \"scripts/bootstrap.py\",\n",
    "    \"../scripts/bootstrap.py\",\n",
    "    \"../../scripts/bootstrap.py\",\n",
    "]\n",
    "\n",
    "bootstrap_ns = None\n",
    "\n",
    "for rel in bootstrap_candidates:\n",
    "    p = pathlib.Path(rel)\n",
    "    if p.exists():\n",
    "        print(f\"Loading bootstrap from: {p}\")\n",
    "        bootstrap_ns = runpy.run_path(str(p))\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find scripts/bootstrap.py. \"\n",
    "        \"Please check that you are running this notebook inside fb2nep-epi.\"\n",
    "    )\n",
    "\n",
    "if \"init\" not in bootstrap_ns:\n",
    "    raise RuntimeError(\"bootstrap.py does not define init().\")\n",
    "\n",
    "df, CTX = bootstrap_ns[\"init\"]()\n",
    "\n",
    "REPO_ROOT = CTX.repo_root\n",
    "CSV_REL = CTX.csv_rel\n",
    "IN_COLAB = CTX.in_colab\n",
    "\n",
    "print(\"Repository root:\", REPO_ROOT)\n",
    "print(\"Main dataset:\", CSV_REL)\n",
    "print(\"df shape:\", df.shape)\n",
    "print(\"IN_COLAB:\", IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports_fb2nep_7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports and quick inspection\n",
    "============================\n",
    "\n",
    "In this cell we:\n",
    "\n",
    "- Import common packages used in this workbook.\n",
    "- Display basic information about the dataset to confirm that it is loaded.\n",
    "\n",
    "The imports are deliberately explicit. Many students using this workbook\n",
    "will not yet have much experience with Python, so we avoid implicit\n",
    "magic and keep the code readable.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"DataFrame shape (rows, columns):\", df.shape)\n",
    "print(\"\\nFirst five rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nVariable types (first 20 columns):\")\n",
    "display(df.dtypes.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assoc_causation_fb2nep_7",
   "metadata": {},
   "source": [
    "## 1. Association and causation\n",
    "\n",
    "Regression models (linear, logistic, Cox) quantify **associations**:\n",
    "\n",
    "- In linear regression, a coefficient describes how the *mean* outcome changes\n",
    "  with the exposure.\n",
    "- In logistic regression, we obtain *odds ratios*.\n",
    "- In Cox regression, we obtain *hazard ratios*.\n",
    "\n",
    "However, public health decisions concern **causal effects**:\n",
    "\n",
    "> *If we changed this exposure (for example, salt intake), what would happen to the outcome?*\n",
    "\n",
    "In observational data, a non-zero regression coefficient does **not** automatically\n",
    "imply a causal effect. Several types of variables can distort or create associations:\n",
    "\n",
    "- **Confounders**: common causes of exposure and outcome that, if unadjusted,\n",
    "  bias estimated effects.\n",
    "- **Colliders**: variables that are caused by two other variables; conditioning\n",
    "  on them can create spurious associations.\n",
    "- **Mediators**: variables lying *on* the causal pathway; adjusting for them can\n",
    "  remove part of a genuine effect.\n",
    "\n",
    "To move from association to causation we need to consider the **causal structure**\n",
    "of the variables. In this workbook we introduce DAGs and basic adjustment strategies.\n",
    "Workbook 9 provides a more formal framework for causal inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dags_intro_fb2nep_7",
   "metadata": {},
   "source": [
    "## 2. DAGs for model development and identification of confounders, colliders, and mediators\n",
    "\n",
    "A **directed acyclic graph (DAG)** is a diagram with arrows that represents\n",
    "assumptions about which variables cause which. It is:\n",
    "\n",
    "- **Directed**: arrows have a direction (cause → effect).\n",
    "- **Acyclic**: there are no feedback loops.\n",
    "\n",
    "DAGs are useful because they make assumptions **explicit** and allow us to reason\n",
    "about which variables we should adjust for in regression models.\n",
    "\n",
    "### 2.1 Constructing a DAG\n",
    "\n",
    "To construct a DAG for a research question:\n",
    "\n",
    "1. **List key variables**\n",
    "   - Exposure (for example, red meat intake).\n",
    "   - Outcome (for example, incident cancer).\n",
    "   - Plausible causes of exposure and outcome (for example, socio-economic status,\n",
    "     age, smoking).\n",
    "\n",
    "2. **Draw arrows according to subject-matter knowledge**\n",
    "   - If variable A can plausibly influence variable B, draw `A → B`.\n",
    "   - Do **not** add arrows simply because two variables are correlated in the data.\n",
    "\n",
    "3. **Identify paths between exposure and outcome**\n",
    "   - Causal paths (exposure → … → outcome).\n",
    "   - Non-causal “backdoor” paths (exposure ← … → outcome) that create confounding.\n",
    "\n",
    "4. **Decide on an adjustment set**\n",
    "   - Choose variables to adjust for so that all non-causal backdoor paths are blocked,\n",
    "     without conditioning on colliders or mediators.\n",
    "\n",
    "![DAG](../_assets/epi_dag.png)\n",
    "\n",
    "### 2.2 Why we do not include everything\n",
    "\n",
    "It might be tempting to adjust for **every available variable**. This is usually\n",
    "a bad idea because:\n",
    "\n",
    "- Adjusting for **colliders** can *create* bias.\n",
    "- Adjusting for **mediators** can remove part of the effect we are interested in\n",
    "  (for example, when estimating the total effect of an exposure).\n",
    "- Adjusting for variables that are neither confounders nor mediators can increase\n",
    "  variance and complicate interpretation without reducing bias.\n",
    "\n",
    "A good DAG includes **enough** variables to capture the main causal structure, but\n",
    "not every variable in the dataset. We use subject-matter knowledge and parsimony:\n",
    "include variables that are plausible causes of exposure and outcome, and that are\n",
    "important for the research question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confounders_intro_fb2nep_7",
   "metadata": {},
   "source": [
    "## 3. Confounders\n",
    "\n",
    "### 3.1 Definition and informal examples\n",
    "\n",
    "A variable is a **confounder** for the association between an exposure and an outcome if:\n",
    "\n",
    "1. It is associated with the exposure.\n",
    "2. It is a cause of, or associated with a cause of, the outcome.\n",
    "3. It is not on the causal pathway from exposure to outcome.\n",
    "\n",
    "Intuitively, a confounder is a variable that makes exposed and unexposed individuals\n",
    "systematically different, in a way that also affects the outcome.\n",
    "\n",
    "Classic informal examples include:\n",
    "\n",
    "- **Number of children and BRCA risk**:\n",
    "  women with more children tend to be older, and age affects the probability of\n",
    "  having developed breast cancer; age can confound the association between\n",
    "  “number of children” and “current breast cancer status”.\n",
    "\n",
    "- **Hair length and income**:\n",
    "  there may appear to be an association between hair length and income if, in a\n",
    "  given setting, women tend to have longer hair than men and also have different\n",
    "  average incomes; sex is a confounder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196d9a9a",
   "metadata": {},
   "source": [
    "### Hippo example (confounding)\n",
    "\n",
    "**Hippo size and daily grass intake**\n",
    "\n",
    "Suppose we observe that *larger hippos eat more grass per day*.  \n",
    "We might be tempted to conclude that **being large makes hippos eat more**.\n",
    "\n",
    "But consider the underlying biology:\n",
    "\n",
    "- Older hippos tend to be larger (simply through growth).\n",
    "- Older hippos also spend more hours grazing because they no longer play in the water as much as juveniles.\n",
    "\n",
    "**Age** is therefore a confounder:\n",
    "\n",
    "```text\n",
    "       age\n",
    "      /    \\\n",
    " hippo size  grass intake\n",
    "```\n",
    "In causal terms:\n",
    "\n",
    "Size ← Age → Grass intake\n",
    "\n",
    "If we ignore age, the association between hippo size and grass intake partly reflects the fact that older hippos both weigh more and eat more, not necessarily that body size itself increases grazing behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213f4a45",
   "metadata": {},
   "source": [
    "### 3.2 Approaches to adjustment\n",
    "\n",
    "There are two basic ways to adjust for confounders:\n",
    "\n",
    "- **Stratification**\n",
    "  - Analyse the exposure–outcome association *within levels* of the confounder.\n",
    "  - For example, estimate the association separately in high and low socio-economic\n",
    "    status (SES) groups.\n",
    "\n",
    "- **Inclusion in a regression model**\n",
    "  - Include the confounder as a **covariate** (predictor) in the regression model.\n",
    "  - For a linear model:\n",
    "    $$\n",
    "    Y = \\beta_0 + \\beta_1 X + \\beta_2 C + \\varepsilon,\n",
    "    $$\n",
    "    where $ X $ is the exposure and $ C $ is the confounder.\n",
    "  - The coefficient $ \\beta_1 $ is then interpreted as the association between\n",
    "    $ X $ and $ Y $ **for individuals with the same value of $ C $**.\n",
    "\n",
    "In practice, regression models with appropriate covariates are the most common\n",
    "approach, but stratified analyses are useful for checking assumptions and for\n",
    "illustrating confounding.\n",
    "\n",
    "In the next section we use the FB2NEP cohort to demonstrate confounding in a setting\n",
    "where the data-generating mechanism includes known confounders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6390c531",
   "metadata": {},
   "source": [
    "## 3.3 Example: salt intake, blood pressure, and incident CVD\n",
    "\n",
    "We now consider a more realistic example using the FB2NEP cohort.\n",
    "\n",
    "- **Exposure**: daily salt intake (`salt_g_d`).\n",
    "- **Outcome**: incident cardiovascular disease during follow-up (`CVD_incident`).\n",
    "- **Potential covariate**: systolic blood pressure (`SBP`).\n",
    "\n",
    "From a clinical perspective, it is plausible that:\n",
    "\n",
    "- Higher salt intake increases SBP.\n",
    "- Higher SBP increases CVD risk.\n",
    "- Salt may also have a direct effect on CVD risk (beyond SBP).\n",
    "\n",
    "A very simple causal diagram (DAG) might be:\n",
    "\n",
    "```text\n",
    "salt_g_d  →  SBP  →  CVD_incident\n",
    "   ↘                ↑\n",
    "     ───────────────\n",
    "```\n",
    "\n",
    "In addition, other variables (such as age, BMI, smoking) may influence both SBP and CVD:\n",
    "\n",
    "```text\n",
    "age  →  SBP  →  CVD_incident\n",
    "  ↘           ↑\n",
    "    ──────────\n",
    "\n",
    "BMI  →  SBP  →  CVD_incident\n",
    "  ↘           ↑\n",
    "    ──────────\n",
    "```\n",
    "In this section, we:\n",
    "\n",
    "1. Fit a crude logistic regression model of CVD on salt.\n",
    "2. Fit an adjusted model that includes SBP.\n",
    "3. Optionally explore stratification by SBP.\n",
    "\n",
    "The aim is to see how adjustment for a strongly related risk factor (here SBP) changes\n",
    "the estimated association between salt intake and incident CVD, and to reflect on whether\n",
    "we are estimating a total or a direct effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confounders_demo_fb2nep_7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.helpers_tables import summarise_logit_coef\n",
    "\n",
    "\n",
    "OUTCOME_VAR   = \"CVD_incident\"\n",
    "EXPOSURE_VAR  = \"salt_g_d\"\n",
    "COVARIATE_VAR = \"SBP\"\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1. Check variables and prepare analysis dataset\n",
    "# ---------------------------------------------------------------------\n",
    "for v in [OUTCOME_VAR, EXPOSURE_VAR, COVARIATE_VAR]:\n",
    "    if v not in df.columns:\n",
    "        raise KeyError(f\"Variable '{v}' not found in df. \"\n",
    "                       f\"Available columns (first 20): {list(df.columns)[:20]}\")\n",
    "\n",
    "df_salt = df[[OUTCOME_VAR, EXPOSURE_VAR, COVARIATE_VAR]].dropna().copy()\n",
    "print(f\"Complete-case sample size: {df_salt.shape[0]} observations\\n\")\n",
    "\n",
    "# Optional: quick descriptive summaries\n",
    "print(\"Descriptive statistics (salt_g_d and SBP):\\n\")\n",
    "display(df_salt[[EXPOSURE_VAR, COVARIATE_VAR]].describe().T)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2. Fit crude and SBP-adjusted logistic regression models\n",
    "# ---------------------------------------------------------------------\n",
    "formula_crude = f\"{OUTCOME_VAR} ~ {EXPOSURE_VAR}\"\n",
    "formula_adj   = f\"{OUTCOME_VAR} ~ {EXPOSURE_VAR} + {COVARIATE_VAR}\"\n",
    "\n",
    "model_crude = smf.logit(formula_crude, data=df_salt).fit(disp=False)\n",
    "model_adj   = smf.logit(formula_adj,   data=df_salt).fit(disp=False)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3. Summarise the effect of salt_g_d in each model\n",
    "# ---------------------------------------------------------------------\n",
    "rows = []\n",
    "rows.append(\n",
    "    summarise_logit_coef(\n",
    "        model_crude,\n",
    "        var_name=EXPOSURE_VAR,\n",
    "        label=\"Crude model (CVD_incident ~ salt_g_d)\"\n",
    "    )\n",
    ")\n",
    "rows.append(\n",
    "    summarise_logit_coef(\n",
    "        model_adj,\n",
    "        var_name=EXPOSURE_VAR,\n",
    "        label=\"Adjusted model (CVD_incident ~ salt_g_d + SBP)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "summary_salt = pd.DataFrame(rows)\n",
    "\n",
    "print(\"\\nAssociation between salt intake and incident CVD:\")\n",
    "print(\"Crude vs SBP-adjusted logistic regression\\n\")\n",
    "display(summary_salt.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ab570",
   "metadata": {},
   "source": [
    "### Interpreting crude vs SBP-adjusted models\n",
    "\n",
    "The table above shows the estimated association between salt intake (`salt_g_d`)\n",
    "and incident CVD, first **without** and then **with** adjustment for SBP.\n",
    "\n",
    "Focus on the rows for `salt_g_d`:\n",
    "\n",
    "- Compare the **odds ratios (OR)** from the crude and adjusted models.\n",
    "- Compare their **95 % confidence intervals**.\n",
    "- Check whether the p-value changes meaningfully.\n",
    "\n",
    "Typical questions to ask:\n",
    "\n",
    "1. **Direction and magnitude**  \n",
    "   - Is the adjusted OR further from 1.0 than the crude OR, or closer to 1.0?\n",
    "   - Does adjustment for SBP increase or reduce the apparent effect of salt?\n",
    "\n",
    "2. **Statistical evidence**  \n",
    "   - Does the p-value change from “non-significant” to “significant”, or vice versa?\n",
    "   - Do the confidence intervals overlap substantially?\n",
    "\n",
    "3. **Causal interpretation**  \n",
    "   - If SBP lies on the causal pathway from salt to CVD (salt → SBP → CVD),\n",
    "     adjusting for SBP shifts attention from the **total effect** of salt to the\n",
    "     **direct effect** not mediated by SBP.\n",
    "   - If SBP is also influenced by other common causes of salt and CVD, adjustment\n",
    "     can partly control for confounding, but it may also remove some of the effect\n",
    "     we wish to measure.\n",
    "\n",
    "In practice, one should be clear whether the primary target is:\n",
    "\n",
    "- the **total effect** of salt on CVD (do *not* adjust for mediators such as SBP), or\n",
    "- a **direct effect** of salt that is not explained by SBP (do adjust for SBP).\n",
    "\n",
    "For this workbook, the numerical results are less important than the logic:\n",
    "\n",
    "> Adjustment can change both the size and interpretation of an effect estimate.  \n",
    "> Understanding the causal role of the covariate is essential before deciding\n",
    "> whether it should be included in a regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b12cf",
   "metadata": {},
   "source": [
    "### Stratification by SBP\n",
    "\n",
    "Instead of (or in addition to) regression adjustment, we can explore the\n",
    "association between salt intake and incident CVD **within strata of SBP**.\n",
    "\n",
    "A simple approach is:\n",
    "\n",
    "1. Divide SBP into **tertiles** (low, medium, high).\n",
    "2. Within each tertile, fit a logistic regression model:\n",
    "   $$\n",
    "   \\text{CVD_incident} \\sim \\text{salt\\_g\\_d}\n",
    "   $$\n",
    "3. Compare the odds ratios for `salt_g_d` across SBP strata.\n",
    "\n",
    "This illustrates two ideas:\n",
    "\n",
    "- **Confounding control**: Within a narrow SBP stratum, participants have\n",
    "  similar blood pressure, so there is less variation in SBP to confound\n",
    "  the salt–CVD association.\n",
    "- **Effect modification**: If the salt–CVD association appears stronger\n",
    "  in one SBP stratum than another, this suggests that the effect of salt\n",
    "  may depend on baseline blood pressure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f885bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Stratified analysis by SBP tertiles.\n",
    "\n",
    "We:\n",
    "\n",
    "1. Create SBP tertiles (low, medium, high).\n",
    "2. Within each tertile, fit a logistic regression:\n",
    "       CVD_incident ~ salt_g_d\n",
    "3. Summarise the effect of salt_g_d in each stratum.\n",
    "\n",
    "This allows visual comparison with the crude and SBP-adjusted models.\n",
    "\"\"\"\n",
    "\n",
    "# Copy the complete-case dataset from above\n",
    "df_strat = df_salt.copy()\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1. Create SBP tertiles\n",
    "# ---------------------------------------------------------------\n",
    "# qcut assigns approximately equal numbers of observations to each group.\n",
    "df_strat[\"SBP_tertile\"] = pd.qcut(\n",
    "    df_strat[COVARIATE_VAR],\n",
    "    q=3,\n",
    "    labels=[\"low SBP\", \"medium SBP\", \"high SBP\"]\n",
    ")\n",
    "\n",
    "print(\"SBP tertile counts:\\n\")\n",
    "print(df_strat[\"SBP_tertile\"].value_counts().sort_index(), \"\\n\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2. Fit logistic regression within each SBP stratum\n",
    "# ---------------------------------------------------------------\n",
    "rows_strata = []\n",
    "\n",
    "for level in df_strat[\"SBP_tertile\"].cat.categories:\n",
    "    df_t = df_strat[df_strat[\"SBP_tertile\"] == level]\n",
    "\n",
    "    print(f\"Fitting model in stratum: {level} (n = {df_t.shape[0]})\")\n",
    "\n",
    "    # Check for sufficient variation in outcome and exposure\n",
    "    if df_t[OUTCOME_VAR].nunique() < 2 or df_t[EXPOSURE_VAR].nunique() < 2:\n",
    "        print(\"  Not enough variation in outcome or exposure to fit the model.\\n\")\n",
    "        continue\n",
    "\n",
    "    m_t = smf.logit(f\"{OUTCOME_VAR} ~ {EXPOSURE_VAR}\", data=df_t).fit(disp=False)\n",
    "\n",
    "    rows_strata.append(\n",
    "        summarise_logit_coef(\n",
    "            m_t,\n",
    "            var_name=EXPOSURE_VAR,\n",
    "            label=f\"SBP tertile: {level}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Combine into a summary table, if any strata were analysable\n",
    "if rows_strata:\n",
    "    summary_strata = pd.DataFrame(rows_strata)\n",
    "    print(\"\\nStratum-specific odds ratios for salt_g_d (by SBP tertile):\\n\")\n",
    "    display(summary_strata.round(3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c25cf",
   "metadata": {},
   "source": [
    "### Interpreting the stratified results by SBP tertile\n",
    "\n",
    "The table shows the association between salt intake (`salt_g_d`) and incident CVD\n",
    "within strata of SBP:\n",
    "\n",
    "- **Low SBP tertile**  \n",
    "  - OR ≈ 0.99 (95 % CI 0.95 to 1.02), p ≈ 0.45  \n",
    "  - Point estimate slightly below 1.0, but the confidence interval is narrow and\n",
    "    clearly includes 1.0.\n",
    "\n",
    "- **Medium SBP tertile**  \n",
    "  - OR ≈ 1.02 (95 % CI 0.99 to 1.06), p ≈ 0.14  \n",
    "  - Point estimate slightly above 1.0, with a confidence interval that again\n",
    "    includes 1.0 and is compatible with no association.\n",
    "\n",
    "- **High SBP tertile**  \n",
    "  - OR ≈ 1.00 (95 % CI 0.98 to 1.03), p ≈ 0.99  \n",
    "  - Point estimate essentially equal to 1.0, with a narrow confidence interval\n",
    "    centred on no association.\n",
    "\n",
    "Taken together:\n",
    "\n",
    "- All three odds ratios are **very close to 1.0**, and all confidence intervals\n",
    "  comfortably include 1.0.\n",
    "- There is **no clear pattern** of a stronger or weaker salt–CVD association in\n",
    "  any SBP tertile.\n",
    "- The small differences in point estimates (slightly <1 in the low SBP group,\n",
    "  slightly >1 in the medium SBP group) are entirely compatible with **random\n",
    "  variation**.\n",
    "\n",
    "For this synthetic dataset, the stratified analysis suggests that:\n",
    "\n",
    "- There is **no strong evidence** of an association between salt intake and\n",
    "  incident CVD within SBP strata.\n",
    "- There is also **no evidence of effect modification** by SBP: the salt–CVD\n",
    "  association does not appear meaningfully different between low, medium, and\n",
    "  high SBP groups.\n",
    "\n",
    "This complements the regression-based adjustment:\n",
    "\n",
    "> Both adjustment and stratification lead us to the same conclusion: in this\n",
    "> particular synthetic cohort, salt intake is not an important predictor of CVD\n",
    "> once SBP (and other built-in risk structure) is taken into account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef62bb",
   "metadata": {},
   "source": [
    "### Predicted probability of incident CVD across salt intake\n",
    "\n",
    "So far we have interpreted regression coefficients and odds ratios. It can also be\n",
    "helpful to translate a logistic regression model into **predicted probabilities**.\n",
    "\n",
    "In this section we use the **SBP-adjusted** logistic model for incident CVD and:\n",
    "\n",
    "- Fix SBP at a reference value (for example, 130 mmHg).\n",
    "- Vary daily salt intake (`salt_g_d`) across its observed range.\n",
    "- Compute the **predicted probability** of incident CVD for each salt value.\n",
    "- Plot this probability curve.\n",
    "\n",
    "This produces a smooth graph showing how the model predicts CVD risk to change as\n",
    "salt intake increases, **conditional on SBP being held constant**. The plot does not\n",
    "prove causality, but it is a powerful way to:\n",
    "\n",
    "- Visualise the *shape* of the association implied by the fitted model.\n",
    "- Relate abstract model coefficients to changes in predicted risk on the probability\n",
    "  scale.\n",
    "- Compare different models (for example, crude vs adjusted) by inspecting how their\n",
    "  prediction curves differ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32caa1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predicted probability of incident CVD across salt intake.\n",
    "\n",
    "We:\n",
    "\n",
    "- Use the SBP-adjusted logistic model.\n",
    "- Fix SBP at a reference value (for example, 130 mmHg).\n",
    "- Vary salt_g_d across its observed range.\n",
    "- Plot the predicted probability of CVD.\n",
    "\n",
    "This visualises the (conditional) effect of salt for a given SBP.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Choose a reference value for SBP (for example, median)\n",
    "sbp_ref = df_salt[COVARIATE_VAR].median()\n",
    "\n",
    "# Construct a grid of salt values over the central range\n",
    "salt_grid = np.linspace(\n",
    "    df_salt[EXPOSURE_VAR].quantile(0.05),\n",
    "    df_salt[EXPOSURE_VAR].quantile(0.95),\n",
    "    100\n",
    ")\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    EXPOSURE_VAR: salt_grid,\n",
    "    COVARIATE_VAR: sbp_ref,\n",
    "})\n",
    "\n",
    "pred_df[\"p_cvd\"] = model_adj.predict(pred_df)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.plot(pred_df[EXPOSURE_VAR], pred_df[\"p_cvd\"], linewidth=2)\n",
    "\n",
    "ax.set_xlabel(\"Salt intake (g/day)\")\n",
    "ax.set_ylabel(\"Predicted probability of incident CVD\")\n",
    "ax.set_title(f\"Adjusted logistic model: CVD_incident ~ salt_g_d + SBP\\n(SBP fixed at {sbp_ref:.1f} mmHg)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17332cf",
   "metadata": {},
   "source": [
    "### Interpreting the predicted probability curve\n",
    "\n",
    "When you run the prediction plot, you will notice that the **predicted probability\n",
    "of incident CVD decreases slightly as salt intake increases** (with SBP fixed at a\n",
    "reference value such as 130 mmHg).\n",
    "\n",
    "This negative slope is often counter-intuitive, so it is important to understand why\n",
    "it appears.\n",
    "\n",
    "#### 1. SBP is held constant — the main causal pathway is removed\n",
    "In the FB2NEP synthetic dataset:\n",
    "\n",
    "- Salt intake has only a **modest direct effect** on CVD.\n",
    "- The *major* pathway from salt to CVD operates through **raising SBP**.\n",
    "- When we fix SBP at a constant value (for example 130 mmHg), we deliberately\n",
    "  remove this pathway.\n",
    "\n",
    "What remains in the model is a small **residual association**, which may even be\n",
    "slightly negative because:\n",
    "\n",
    "- Salt intake is correlated with other factors (such as physical activity or SES)\n",
    "  in the synthetic data generation.\n",
    "- Once SBP is controlled for, these correlations can produce a small negative\n",
    "  conditional association.\n",
    "\n",
    "This is an excellent example of the difference between:\n",
    "\n",
    "- **Total effect** (salt → SBP → CVD + any direct effect), and\n",
    "- **Direct effect** (salt → CVD, *not* via SBP).\n",
    "\n",
    "The plot shows **only the direct effect**, because SBP is held constant.\n",
    "\n",
    "#### 2. A negative slope does *not* imply that salt is protective\n",
    "The model is telling us:\n",
    "\n",
    "> *Given two individuals with the same SBP, slightly higher salt intake does not\n",
    "> meaningfully increase CVD risk in this dataset.*\n",
    "\n",
    "This is not a biological claim; it is an artefact of the **structural choices**\n",
    "in the synthetic dataset:\n",
    "\n",
    "- The direct salt → CVD term in the data generator is deliberately small.\n",
    "- SBP carries most of the signal.\n",
    "- Conditioning on SBP absorbs nearly all of salt’s effect.\n",
    "\n",
    "#### 3. The educational message\n",
    "\n",
    "This visualisation reinforces two important lessons:\n",
    "\n",
    "- **Adjustment changes the estimand.**  \n",
    "  By fixing SBP, we move from the total effect to the direct effect.\n",
    "\n",
    "- **Interpreting adjusted prediction curves requires causal thinking.**  \n",
    "  Without a DAG, one might wrongly conclude that salt is “protective”.\n",
    "\n",
    "In reality, the example shows how removing the primary pathway of influence can\n",
    "make an exposure appear unrelated or even slightly inversely related to an\n",
    "outcome in a regression model.\n",
    "\n",
    "> The key takeaway: always decide which effect — total or direct — you are trying\n",
    "> to estimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "energy_intro_fb2nep_7",
   "metadata": {},
   "source": [
    "## 4. Special case: energy intake in nutritional epidemiology\n",
    "\n",
    "### 4.1 Why total energy intake is different\n",
    "\n",
    "In nutritional epidemiology, **total energy intake** (for example, `energy_kcal`)\n",
    "is not a classical confounder in the usual sense. Instead, it is a kind of\n",
    "“scaling” variable:\n",
    "\n",
    "- Individuals who eat **more total energy** tend to consume more of many nutrients\n",
    "  and foods simply because they eat more food.\n",
    "- Many nutrients are also biologically related to energy intake (for example,\n",
    "  higher energy intake is often associated with higher body size and physical\n",
    "  activity).\n",
    "\n",
    "If we ignore total energy intake, we may incorrectly attribute the effect of\n",
    "“eating more food overall” to a specific nutrient or food.\n",
    "\n",
    "### 4.2 Common energy-adjustment methods\n",
    "\n",
    "Several approaches are used to adjust nutrient intakes for total energy:\n",
    "\n",
    "1. **Nutrient density method**\n",
    "   - Express the nutrient per unit of energy, for example g/MJ or % of energy.\n",
    "   - Example: grams of fibre per 1000 kcal.\n",
    "\n",
    "2. **Residual method**\n",
    "   - Regress the nutrient of interest on total energy intake.\n",
    "   - Use the **residuals** (observed minus expected nutrient intake given energy)\n",
    "     as an energy-adjusted exposure.\n",
    "   - This removes the part of the nutrient intake that is explained by total\n",
    "     energy intake.\n",
    "\n",
    "3. **Energy-adjusted models**\n",
    "   - Include both the nutrient and total energy intake as covariates in the\n",
    "     regression model of interest.\n",
    "\n",
    "Each method has advantages and disadvantages. The residual method and energy-adjusted\n",
    "models are particularly useful when working with food-frequency questionnaires (FFQs),\n",
    "where measurement error and strong correlations between nutrients can be substantial.\n",
    "\n",
    "### 4.3 Special case of FFQs\n",
    "\n",
    "FFQs typically record **relative** frequencies of consumption over long periods.\n",
    "Reported intakes of many foods and nutrients are highly correlated, and systematic\n",
    "measurement error is common. Adjusting for total energy intake can:\n",
    "\n",
    "- Reduce measurement error that is common to many foods (for example, general\n",
    "  over-reporting or under-reporting).\n",
    "- Focus analyses on **diet composition** rather than total amount of food.\n",
    "\n",
    "We now illustrate the residual method using `salt_g_d` and `energy_kcal` in the FB2NEP cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "energy_residual_example_fb2nep_7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Energy-adjustment example using the residual method.\n",
    "\n",
    "We:\n",
    "- Consider salt intake (salt_g_d) and total energy intake (energy_kcal).\n",
    "- Regress salt_g_d on energy_kcal.\n",
    "- Compute residuals as energy-adjusted salt intake.\n",
    "- Illustrate the effect of adjustment with a simple association with BMI.\n",
    "\"\"\"\n",
    "\n",
    "for var in [\"salt_g_d\", \"energy_kcal\", \"BMI\"]:\n",
    "    if var not in df.columns:\n",
    "        raise KeyError(f\"Variable '{var}' not found in df.\")\n",
    "\n",
    "df_energy = df[[\"salt_g_d\", \"energy_kcal\", \"BMI\"]].dropna().copy()\n",
    "print(f\"Sample size (complete cases): {df_energy.shape[0]} observations\\n\")\n",
    "\n",
    "# Fit linear model: salt_g_d ~ energy_kcal\n",
    "model_salt_energy = smf.ols(\"salt_g_d ~ energy_kcal\", data=df_energy).fit()\n",
    "print(\"Linear regression: salt_g_d ~ energy_kcal\\n\")\n",
    "display(model_salt_energy.summary().tables[1])\n",
    "\n",
    "# Compute residuals: energy-adjusted salt intake\n",
    "df_energy[\"salt_residual\"] = model_salt_energy.resid\n",
    "\n",
    "print(\"\\nFirst five rows with residuals:\")\n",
    "display(df_energy.head())\n",
    "\n",
    "# Compare associations of BMI with raw and energy-adjusted salt\n",
    "m_raw = smf.ols(\"BMI ~ salt_g_d\", data=df_energy).fit()\n",
    "m_adj = smf.ols(\"BMI ~ salt_residual\", data=df_energy).fit()\n",
    "\n",
    "print(\"\\nAssociation with BMI (raw salt):\")\n",
    "display(m_raw.summary().tables[1])\n",
    "\n",
    "print(\"\\nAssociation with BMI (energy-adjusted salt, residuals):\")\n",
    "display(m_adj.summary().tables[1])\n",
    "\n",
    "print(\"\\nInterpretation: the residual approach removes the part of salt intake that is\"\n",
    "      \" explained by total energy. The comparison of the two models illustrates how\"\n",
    "      \" energy adjustment can change estimated associations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colliders_mediators_intro_fb2nep_7",
   "metadata": {},
   "source": [
    "## 5. Colliders and mediators (brief overview)\n",
    "\n",
    "### 5.1 Colliders\n",
    "\n",
    "A **collider** is a variable that is *caused* by two (or more) other variables.\n",
    "In a simple diagram:\n",
    "\n",
    "```text\n",
    "exercise  →\n",
    "            fitness\n",
    "genes     →\n",
    "```\n",
    "\n",
    "Here, `fitness` is a collider on the path between `exercise` and `genes`. If we\n",
    "**condition** on fitness (for example, by restricting the analysis to individuals\n",
    "with high fitness, or adjusting for fitness in a model), we can induce an\n",
    "association between exercise and genes even if none exists in the population.\n",
    "\n",
    "This is known as **collider bias** or **selection bias** when the collider is\n",
    "related to being included in the study.\n",
    "\n",
    "### 5.2 Mediators\n",
    "\n",
    "A **mediator** lies *on* the causal pathway between exposure and outcome:\n",
    "\n",
    "```text\n",
    "salt intake → blood pressure → stroke\n",
    "```\n",
    "\n",
    "If we are interested in the **total effect** of salt intake on stroke risk,\n",
    "we should **not** adjust for blood pressure, because this would remove part of\n",
    "the genuine effect (the indirect pathway through blood pressure).\n",
    "\n",
    "If we are specifically interested in the **direct effect** of salt that is not\n",
    "mediated by blood pressure, then adjusting for blood pressure is appropriate,\n",
    "but the interpretation changes.\n",
    "\n",
    "The key message is that we should adjust for **confounders**, avoid adjusting\n",
    "for **colliders**, and think carefully before adjusting for **mediators**.\n",
    "DAGs help us to reason about which variables fall into which category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collider_demo_fb2nep_7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Short simulation to illustrate collider bias.\n",
    "\n",
    "We simulate:\n",
    "- exercise and genes as independent variables.\n",
    "- fitness as a function of both exercise and genes (a collider).\n",
    "- risk as a function of genes only.\n",
    "\n",
    "We then:\n",
    "- Fit a logistic model of risk on exercise in the full sample.\n",
    "- Restrict to high fitness (conditioning on the collider) and refit.\n",
    "\n",
    "Conditioning on fitness induces a spurious association between exercise and risk.\n",
    "\"\"\"\n",
    "\n",
    "rng = np.random.default_rng(11088)\n",
    "n = 5000\n",
    "\n",
    "exercise = rng.normal(0, 1, n)\n",
    "genes = rng.normal(0, 1, n)\n",
    "fitness = 0.8 * exercise + 0.8 * genes + rng.normal(0, 1, n)\n",
    "risk_lin = 1.2 * genes + rng.normal(0, 1, n)\n",
    "risk = (risk_lin > 0).astype(int)\n",
    "\n",
    "dfc = pd.DataFrame({\"exercise\": exercise, \"genes\": genes, \"fitness\": fitness, \"risk\": risk})\n",
    "\n",
    "print(\"Correlation exercise–genes (should be ~0):\")\n",
    "print(dfc[[\"exercise\", \"genes\"]].corr(), \"\\n\")\n",
    "\n",
    "    # Full sample\n",
    "print(\"Full sample: exercise → risk (logistic):\")\n",
    "m_full = smf.logit(\"risk ~ exercise\", dfc).fit(disp=False)\n",
    "print(m_full.summary().tables[1])\n",
    "\n",
    "# Condition on high fitness (top 30 %)\n",
    "thr = dfc[\"fitness\"].quantile(0.70)\n",
    "df_high = dfc[dfc[\"fitness\"] >= thr]\n",
    "print(\"\\nHigh fitness sample size:\", df_high.shape[0])\n",
    "\n",
    "print(\"High fitness: exercise → risk (logistic):\")\n",
    "m_cond = smf.logit(\"risk ~ exercise\", df_high).fit(disp=False)\n",
    "print(m_cond.summary().tables[1])\n",
    "\n",
    "print(\"\\nInterpretation: conditioning on fitness (a collider) induces an apparent\"\n",
    "      \" association between exercise and risk even though exercise does not cause\"\n",
    "      \" risk in the data-generating mechanism.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "counterfactuals_fb2nep_7",
   "metadata": {},
   "source": [
    "## 6. Counterfactuals\n",
    "\n",
    "Modern causal inference often uses **counterfactual** or **potential outcome**\n",
    "language. For each individual we imagine:\n",
    "\n",
    "- \\( Y(1) \\): the outcome that would occur if the individual were exposed.\n",
    "- \\( Y(0) \\): the outcome that would occur if the same individual were not exposed.\n",
    "\n",
    "The **causal effect** for that individual is the (usually unobservable) difference\n",
    "\\( Y(1) - Y(0) \\). In practice we cannot observe both outcomes for the same\n",
    "person, so we rely on comparisons between groups, together with assumptions about\n",
    "confounding, measurement, and model specification.\n",
    "\n",
    "Adjustment strategies (for example, regression with appropriate covariates based on\n",
    "a sensible DAG) are used to make the exposed and unexposed groups more comparable,\n",
    "so that the difference in observed outcomes approximates the difference between\n",
    "counterfactual outcomes.\n",
    "\n",
    "Workbook 9 returns to these ideas and introduces more formal notation and methods\n",
    "for estimating causal effects under explicit assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflection_exercises_fb2nep_7",
   "metadata": {},
   "source": [
    "## 9. Reflection and exercises\n",
    "\n",
    "1. **Draw a DAG** for the association between red meat intake and incident cancer\n",
    "   in the FB2NEP cohort. Include at least age, sex, SES_class, IMD_quintile,\n",
    "   smoking_status, and family history. Identify plausible confounders,\n",
    "   colliders, and mediators.\n",
    "\n",
    "2. **Confounders in practice**: Choose a different exposure (for example,\n",
    "   `fruit_veg_g_d` or `salt_g_d`) and a relevant outcome. Propose at least two\n",
    "   variables as potential confounders based on subject-matter knowledge. Fit\n",
    "   crude and adjusted models and compare the estimates.\n",
    "\n",
    "3. **Energy adjustment**: Using `energy_kcal` and a nutrient of your choice\n",
    "   (for example, `fibre_g_d`), implement the nutrient density method and the\n",
    "   residual method. Compare the associations with BMI or another suitable\n",
    "   outcome for the raw, density-based, and residual-based exposures.\n",
    "\n",
    "4. **Collider bias**: Modify the collider simulation to use a different\n",
    "   collider (for example, an indicator of study participation) and show how\n",
    "   conditioning on participation can induce associations between variables\n",
    "   that are otherwise independent.\n",
    "\n",
    "5. **Mediators**: For a hypothetical causal chain in nutrition (for example,\n",
    "   `diet quality → BMI → blood pressure → CVD`), decide which variables you\n",
    "   would adjust for when estimating the total effect of diet quality on CVD,\n",
    "   and which you would *not* adjust for. Explain your reasoning.\n",
    "\n",
    "6. **Counterfactual thinking**: In your own words, describe what it would mean\n",
    "   to say that “reducing salt intake by 2 g/day would reduce average SBP by\n",
    "   5 mmHg” in terms of potential outcomes. What assumptions would be needed for\n",
    "   this statement to be interpreted causally in an observational study?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
