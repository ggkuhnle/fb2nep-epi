{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf09d523",
   "metadata": {},
   "source": [
    "# 03 · Exposure analysis — intake vs biomarker\n",
    "\n",
    "> **Purpose**: characterise dietary exposures and examine construct validity via biomarkers.\n",
    "\n",
    "> **Learning objectives**\n",
    "- Inspect distributions of key exposures (energy, fruit & veg, red meat, salt, alcohol) and biomarkers.\n",
    "- Demonstrate energy scaling (per 1000 kcal) and interpret implications.\n",
    "- Show intake–biomarker alignment: fruit & veg → vitamin C; salt → urinary sodium.\n",
    "- Probe non-linearity with splines/bins and report simple effect estimates.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f4b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the repo root (which has scripts/bootstrap.py) is on sys.path.\n",
    "import sys, os, pathlib, subprocess\n",
    "\n",
    "REPO_NAME = \"fb2nep-epi\"\n",
    "REPO_URL  = \"https://github.com/ggkuhnle/fb2nep-epi.git\"\n",
    "IN_COLAB  = \"google.colab\" in sys.modules\n",
    "\n",
    "def ensure_repo_on_path():\n",
    "    here = pathlib.Path.cwd()\n",
    "    # Walk up a few levels to find scripts/bootstrap.py\n",
    "    for p in [here, *here.parents]:\n",
    "        if (p / \"scripts\" / \"bootstrap.py\").exists():\n",
    "            os.chdir(p)                 # normalise CWD to repo root\n",
    "            sys.path.append(str(p))     # ensure imports like \"from scripts...\" work\n",
    "            return p\n",
    "    # Not found locally: if on Colab, clone then chdir\n",
    "    if IN_COLAB:\n",
    "        # clone only if missing\n",
    "        if not (pathlib.Path(\"/content\") / REPO_NAME).exists():\n",
    "            subprocess.run([\"git\", \"clone\", REPO_URL], check=False)\n",
    "        os.chdir(f\"/content/{REPO_NAME}\")\n",
    "        sys.path.append(os.getcwd())\n",
    "        return pathlib.Path.cwd()\n",
    "    # Otherwise, we can’t proceed\n",
    "    raise FileNotFoundError(\"Could not find repo root containing scripts/bootstrap.py\")\n",
    "\n",
    "repo_root = ensure_repo_on_path()\n",
    "print(\"Repo root:\", repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c14ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap: ensure repo root on sys.path, then import init\n",
    "import sys, pathlib\n",
    "sys.path.append(str(pathlib.Path.cwd().parent))\n",
    "from scripts.bootstrap import init\n",
    "df, ctx = init()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee27fc75",
   "metadata": {},
   "source": [
    "## 1) Variables of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "expo = ['energy_kcal','fruit_veg_g_d','red_meat_g_d','salt_g_d','alcohol_units_wk','fibre_g_d','ssb_ml_d']\n",
    "biom = ['plasma_vitC_umol_L','urinary_sodium_mmol_L']\n",
    "core = ['age','sex','BMI','SES_class']\n",
    "avail = [c for c in expo+biom+core if c in df.columns]\n",
    "df[avail].describe(include='all').T.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2539c492",
   "metadata": {},
   "source": [
    "## 2) Distributions (orientation, not inference)\n",
    "Look for skew/heavy tails that might motivate transformations later (log1p, z-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_cols = [c for c in ['energy_kcal','fruit_veg_g_d','red_meat_g_d','salt_g_d','alcohol_units_wk','plasma_vitC_umol_L','urinary_sodium_mmol_L'] if c in df]\n",
    "for col in plot_cols:\n",
    "    x = df[col].dropna()\n",
    "    plt.figure(figsize=(5.2,4))\n",
    "    plt.hist(x, bins=40, alpha=0.9)\n",
    "    plt.xlabel(col); plt.ylabel('count'); plt.title(col)\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276397d0",
   "metadata": {},
   "source": [
    "## 3) Energy scaling\n",
    "Dietary components tend to correlate with total energy. Normalise selected intakes per **1000 kcal** to reduce confounding by energy intake (a simple density approach; not universally appropriate but useful as a teaching baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bfedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "d = df.copy()\n",
    "eps = 1e-6\n",
    "if 'energy_kcal' in d:\n",
    "    for v in ['fruit_veg_g_d','red_meat_g_d','salt_g_d','fibre_g_d','ssb_ml_d']:\n",
    "        if v in d:\n",
    "            d[v+'_per_1k'] = d[v] / (d['energy_kcal']+eps) * 1000\n",
    "            \n",
    "# Correlations with energy (raw vs density) — orientation\n",
    "corrs = {}\n",
    "for v in ['fruit_veg_g_d','red_meat_g_d','salt_g_d']:\n",
    "    if v in d:\n",
    "        cr = d[[v,'energy_kcal']].corr().iloc[0,1]\n",
    "        dv = v+'_per_1k'\n",
    "        cr_den = d[[dv,'energy_kcal']].corr().iloc[0,1] if dv in d else np.nan\n",
    "        corrs[v] = {'raw_vs_energy': round(cr,3), 'density_vs_energy': round(cr_den,3)}\n",
    "pd.DataFrame(corrs).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5aac33",
   "metadata": {},
   "source": [
    "**Interpretation prompt**: Do density adjustments reduce the apparent energy correlation as expected? When might density scaling be inappropriate (e.g., if energy is on the causal pathway for your question)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69013a80",
   "metadata": {},
   "source": [
    "## 4) Intake ↔ biomarker alignment (construct validity)\n",
    "Two expected monotone patterns:\n",
    "\n",
    "- Fruit & veg (g/day) → **plasma vitamin C** (µmol/L)\n",
    "- Salt (g/day) → **urinary sodium** (mmol/L)\n",
    "\n",
    "We’ll check both **quintile monotonicity** and **scatter with linear fit**, and then a simple **partialled** estimate adjusting for energy and basic covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2304cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "out = {}\n",
    "if {'fruit_veg_g_d','plasma_vitC_umol_L'} <= set(d):\n",
    "    q = pd.qcut(d['fruit_veg_g_d'], 5, duplicates='drop')\n",
    "    fv_tab = d.groupby(q)['plasma_vitC_umol_L'].agg(['mean','std','count']).round(2)\n",
    "    out['fruitveg→vitC'] = fv_tab\n",
    "    display(fv_tab)\n",
    "    assert fv_tab['mean'].is_monotonic_increasing, \"Vitamin C should increase across fruit/veg quintiles\"\n",
    "\n",
    "if {'salt_g_d','urinary_sodium_mmol_L'} <= set(d):\n",
    "    q = pd.qcut(d['salt_g_d'], 5, duplicates='drop')\n",
    "    na_tab = d.groupby(q)['urinary_sodium_mmol_L'].agg(['mean','std','count']).round(2)\n",
    "    out['salt→urNa'] = na_tab\n",
    "    display(na_tab)\n",
    "    assert na_tab['mean'].is_monotonic_increasing, \"Urinary sodium should increase across salt quintiles\"\n",
    "\n",
    "print('Monotone checks passed where applicable ✅')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f500834f",
   "metadata": {},
   "source": [
    "### Scatter + fitted line\n",
    "Note the **noise**: within-person variation, assay error, and reporting error all dilute the signal. We use simple least squares for the visual trend (not a causal estimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280d9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt\n",
    "pairs = [\n",
    "    ('fruit_veg_g_d','plasma_vitC_umol_L','Fruit & veg (g/day)','Plasma vitamin C (µmol/L)'),\n",
    "    ('salt_g_d','urinary_sodium_mmol_L','Salt (g/day)','Urinary sodium (mmol/L)')\n",
    "]\n",
    "for xcol,ycol,xlab,ylab in pairs:\n",
    "    if {xcol,ycol} <= set(d):\n",
    "        xy = d[[xcol,ycol]].dropna()\n",
    "        if xy.empty: continue\n",
    "        plt.figure(figsize=(5.4,4))\n",
    "        plt.scatter(xy[xcol], xy[ycol], s=10, alpha=0.6)\n",
    "        b1,b0 = np.polyfit(xy[xcol], xy[ycol], 1)\n",
    "        grid = np.linspace(xy[xcol].min(), xy[xcol].max(), 120)\n",
    "        plt.plot(grid, b1*grid+b0)\n",
    "        plt.xlabel(xlab); plt.ylabel(ylab); plt.title(f\"{xcol} vs {ycol}\")\n",
    "        plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2381eb8e",
   "metadata": {},
   "source": [
    "### Partialled estimates (adjusting for energy and basics)\n",
    "We’re not doing causal inference here—just showing that the **exposure–biomarker signal persists** after adjusting for **energy**, **age**, **sex**, and **SES**. We report the adjusted slope (per unit exposure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6440ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from patsy import dmatrix\n",
    "\n",
    "def partial_slope(df_, x, y, adjust=('energy_kcal','age','sex','SES_class')):\n",
    "    cols = [c for c in [x,y,*adjust] if c in df_.columns]\n",
    "    dd = df_[cols].dropna().copy()\n",
    "    # encode categoricals\n",
    "    rhs_terms = []\n",
    "    for v in adjust:\n",
    "        if v in dd.columns:\n",
    "            if dd[v].dtype=='object' or str(dd[v].dtype).startswith('category'):\n",
    "                rhs_terms.append(f'C({v})')\n",
    "            else:\n",
    "                rhs_terms.append(v)\n",
    "    RHS = ' + '.join(rhs_terms) if rhs_terms else '1'\n",
    "    # Build design by hand: y ~ x + adjust\n",
    "    X = dmatrix('1 + ' + x + (' + ' + RHS if RHS!='1' else ''), data=dd, return_type='dataframe')\n",
    "    mod = sm.OLS(dd[y], X).fit()\n",
    "    coef = mod.params.get(x, float('nan'))\n",
    "    ci = mod.conf_int().loc[x].tolist() if x in mod.params.index else [float('nan'), float('nan')]\n",
    "    return {'n': len(dd), 'beta': coef, 'lo': ci[0], 'hi': ci[1]}\n",
    "\n",
    "res = []\n",
    "if {'fruit_veg_g_d','plasma_vitC_umol_L'} <= set(d):\n",
    "    res.append(('fruit_veg_g_d → plasma_vitC_umol_L', partial_slope(d,'fruit_veg_g_d','plasma_vitC_umol_L')))\n",
    "if {'salt_g_d','urinary_sodium_mmol_L'} <= set(d):\n",
    "    res.append(('salt_g_d → urinary_sodium_mmol_L', partial_slope(d,'salt_g_d','urinary_sodium_mmol_L')))\n",
    "\n",
    "pd.DataFrame([{'Relation': k, **v} for k,v in res]).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8173d94",
   "metadata": {},
   "source": [
    "## 5) Non-linearity check (bins & splines)\n",
    "Visualise possible curvature with **exposure bins** and optionally a **spline** term (for flexible fit). Use this to **motivate** transformations in later modelling, not as proof of causality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccfc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import bs\n",
    "\n",
    "def binned_means(df_, x, y, k=10):\n",
    "    dd = df_[[x,y]].dropna().copy()\n",
    "    dd['bin'] = pd.qcut(dd[x], q=k, duplicates='drop')\n",
    "    return dd.groupby('bin')[y].mean()\n",
    "\n",
    "checks = [\n",
    "    ('fruit_veg_g_d','plasma_vitC_umol_L','Fruit & veg (g/day)','Vit C (µmol/L)'),\n",
    "    ('salt_g_d','urinary_sodium_mmol_L','Salt (g/day)','Urinary Na (mmol/L)')\n",
    "]\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "for x,y,xlab,ylab in checks:\n",
    "    if {x,y} <= set(d):\n",
    "        dd = d[[x,y]].dropna().copy()\n",
    "        # Binned means\n",
    "        bm = binned_means(d, x, y, k=10)\n",
    "        # Spline fit (df=4)\n",
    "        Xs = dmatrix('1 + bs('+x+', df=4)', data=dd, return_type='dataframe')\n",
    "        fit = sm.OLS(dd[y], Xs).fit()\n",
    "        grid = np.linspace(dd[x].min(), dd[x].max(), 120)\n",
    "        Xg = dmatrix('1 + bs(x, df=4)', data={'x':grid}, return_type='dataframe')\n",
    "        yg = fit.predict(Xg)\n",
    "\n",
    "        plt.figure(figsize=(5.6,4.2))\n",
    "        # plot binned means\n",
    "        ctrs = bm.index.map(lambda c: 0.5*(c.left+c.right))\n",
    "        plt.scatter(list(ctrs), bm.values, s=24, alpha=0.8, label='Binned means')\n",
    "        # spline\n",
    "        plt.plot(grid, yg, label='Spline (df=4)')\n",
    "        plt.xlabel(xlab); plt.ylabel(ylab); plt.title(f\"Non-linearity check: {x} → {y}\")\n",
    "        plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68b789d",
   "metadata": {},
   "source": [
    "## 6) # TODO — your turn\n",
    "1. **Energy scaling**: Create `red_meat_g_d_per_1k` and `salt_g_d_per_1k` if not already present. Compare their correlations with energy vs the raw variables. Write one sentence interpreting the change.\n",
    "2. **Biomarker alignment**: Compute **Spearman** correlations for (fruit&veg, vit C) and (salt, urinary Na). Are results consistent with the monotone checks?\n",
    "3. **Adjusted slope**: Re-run `partial_slope` adding `BMI` to the adjusters. Does the exposure coefficient change meaningfully?\n",
    "4. **Non-linearity**: Using the spline plot you created, argue briefly (2–3 sentences) whether a log or spline term is warranted in later models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6fc71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Spearman correlations (example)\n",
    "import scipy.stats as st\n",
    "pairs = []\n",
    "if {'fruit_veg_g_d','plasma_vitC_umol_L'} <= set(d):\n",
    "    a = d[['fruit_veg_g_d','plasma_vitC_umol_L']].dropna()\n",
    "    rho,p = st.spearmanr(a['fruit_veg_g_d'], a['plasma_vitC_umol_L'])\n",
    "    pairs.append({'pair':'fruit&veg ~ vitC','rho':round(rho,3),'p':p})\n",
    "if {'salt_g_d','urinary_sodium_mmol_L'} <= set(d):\n",
    "    b = d[['salt_g_d','urinary_sodium_mmol_L']].dropna()\n",
    "    rho,p = st.spearmanr(b['salt_g_d'], b['urinary_sodium_mmol_L'])\n",
    "    pairs.append({'pair':'salt ~ urinaryNa','rho':round(rho,3),'p':p})\n",
    "import pandas as pd\n",
    "pd.DataFrame(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fe283d",
   "metadata": {},
   "source": [
    "> ## Key takeaways\n",
    ">\n",
    "> - Energy drives many diet correlations; density scaling can clarify patterns but must align with your causal story.\n",
    "> - Construct validity checks (intake ↔ biomarker) should show **monotone** trends despite noise.\n",
    "> - Simple partialling (energy, age, sex, SES) helps show the signal is not purely compositional.\n",
    "> - Non-linearity diagnostics guide later modelling choices (transform, polynomial, or spline)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
