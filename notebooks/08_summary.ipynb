{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 · Summary & Assessment prep\n",
    "\n",
    "> **Purpose**: consolidate the full workflow, align outputs with Assessment 1, and generate a short submission checklist.\n",
    "\n",
    "> **Learning objectives**\n",
    "- Recap the end-to-end epidemiology workflow used in this module.\n",
    "- Verify that your pipeline produces the minimum required outputs for A1.\n",
    "- Prepare a clean export of figures and text (DAG + 500 words) for submission.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76589898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the repo root (which has scripts/bootstrap.py) is on sys.path.\n",
    "import sys, os, pathlib, subprocess\n",
    "\n",
    "REPO_NAME = \"fb2nep-epi\"\n",
    "REPO_URL  = \"https://github.com/ggkuhnle/fb2nep-epi.git\"\n",
    "IN_COLAB  = \"google.colab\" in sys.modules\n",
    "\n",
    "def ensure_repo_on_path():\n",
    "    here = pathlib.Path.cwd()\n",
    "    # Walk up a few levels to find scripts/bootstrap.py\n",
    "    for p in [here, *here.parents]:\n",
    "        if (p / \"scripts\" / \"bootstrap.py\").exists():\n",
    "            os.chdir(p)                 # normalise CWD to repo root\n",
    "            sys.path.append(str(p))     # ensure imports like \"from scripts...\" work\n",
    "            return p\n",
    "    # Not found locally: if on Colab, clone then chdir\n",
    "    if IN_COLAB:\n",
    "        # clone only if missing\n",
    "        if not (pathlib.Path(\"/content\") / REPO_NAME).exists():\n",
    "            subprocess.run([\"git\", \"clone\", REPO_URL], check=False)\n",
    "        os.chdir(f\"/content/{REPO_NAME}\")\n",
    "        sys.path.append(os.getcwd())\n",
    "        return pathlib.Path.cwd()\n",
    "    # Otherwise, we can’t proceed\n",
    "    raise FileNotFoundError(\"Could not find repo root containing scripts/bootstrap.py\")\n",
    "\n",
    "repo_root = ensure_repo_on_path()\n",
    "print(\"Repo root:\", repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap: ensure repo root on path, then import init\n",
    "import sys, pathlib\n",
    "sys.path.append(str(pathlib.Path.cwd().parent))\n",
    "from scripts.bootstrap import init\n",
    "df, ctx = init()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Recap — the workflow you implemented\n",
    "1. **Intro & integrity**: load data, check ranges, flags ↔ dates, expected monotone signals.\n",
    "2. **Describe the population**: robust *Table 1*; missingness exploration.\n",
    "3. **Exposure analysis**: distributions; intake vs biomarker (construct validity).\n",
    "4. **Theory → Model**: DAGs; decide a minimal sufficient adjustment set.\n",
    "5. **Cross-sectional models**: transformations, non-linearity, diagnostics, VIF.\n",
    "6. **Prospective models**: incident outcomes (logistic / survival), interpretation.\n",
    "7. **Advanced**: confounding vs collider vs mediator; missing-data sensitivity.\n",
    "\n",
    "Your **assessment** now asks you to pull a defensible thread through these steps for one clear question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Reproducibility snapshot (optional in submission)\n",
    "Capture versions to make your environment explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, numpy, pandas, matplotlib, statsmodels\n",
    "print({\n",
    "  'python': sys.version.split()[0],\n",
    "  'numpy': numpy.__version__,\n",
    "  'pandas': pandas.__version__,\n",
    "  'matplotlib': matplotlib.__version__,\n",
    "  'statsmodels': statsmodels.__version__\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Assessment 1 — checklist generator\n",
    "This cell checks for the expected artefacts and gives you a quick status table.\n",
    "\n",
    "**Expected at minimum**:\n",
    "- A **DAG figure** (PNG/PDF) describing your reasoning & adjustment set.\n",
    "- A **500-word** methods/results/interpretation/limitations text.\n",
    "- One clear **Table 1** (CSV or embedded output) relevant to your question.\n",
    "- One primary **logistic regression** on the chosen outcome (unadjusted + adjusted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, pathlib\n",
    "root = pathlib.Path.cwd().parent  # repo root\n",
    "artefacts = {\n",
    "    'Table 1 CSV (submission/table1_by_OUTCOME.csv)': root / 'submission' / 'table1_by_OUTCOME.csv',\n",
    "    'DAG image (submission/dag.png)':                 root / 'submission' / 'dag.png',\n",
    "    'DAG PDF (optional)':                             root / 'submission' / 'dag.pdf',\n",
    "    '500 words (submission/summary_500w.txt)':        root / 'submission' / 'summary_500w.txt',\n",
    "}\n",
    "rows = []\n",
    "for label, path in artefacts.items():\n",
    "    exists = path.exists()\n",
    "    size = path.stat().st_size if exists else 0\n",
    "    rows.append({'Artefact': label, 'Exists': bool(exists), 'Bytes': int(size), 'Path': str(path)})\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an item is missing, use the helper snippets below to create it. Use the versions you produced in earlier notebooks if you prefer — the point is *consistency* with your chosen question and DAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Helper — export your DAG image (template)\n",
    "If you built a DAG in a previous notebook, re-run the cell there to regenerate the figure into `submission/`. Otherwise, adapt this minimal template.\n",
    "\n",
    "_Note_: `networkx` is optional; feel free to export a diagram made elsewhere as long as it matches your model narrative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "Path('submission').mkdir(exist_ok=True)\n",
    "try:\n",
    "    import networkx as nx, matplotlib.pyplot as plt\n",
    "    G = nx.DiGraph()\n",
    "    # EDIT THESE EDGES to match your final model\n",
    "    G.add_edges_from([\n",
    "        ('SES','Exposure'), ('SES','Outcome'),\n",
    "        ('Age','Exposure'), ('Age','Outcome'),\n",
    "        ('Smoking','Outcome'),\n",
    "        ('Exposure','Outcome')\n",
    "    ])\n",
    "    pos = {'SES':(-1,1),'Age':(1,1),'Smoking':(1.8,0.7),'Exposure':(0,0),'Outcome':(0,-1)}\n",
    "    plt.figure(figsize=(5.2,4.2))\n",
    "    nx.draw(G, pos, with_labels=True, node_size=1600, node_color='#e6f2ff', arrows=True)\n",
    "    plt.axis('off'); plt.tight_layout()\n",
    "    plt.savefig('submission/dag.png', dpi=200)\n",
    "    plt.savefig('submission/dag.pdf')\n",
    "    print('Saved submission/dag.png and dag.pdf')\n",
    "except Exception as e:\n",
    "    print('DAG export skipped — install networkx/matplotlib or supply your own image. Error:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Helper — logistic model export (tidy OR table)\n",
    "Run your **unadjusted** and **adjusted** logistic regressions and save a simple OR table for the **primary exposure**. Edit `OUTCOME`, `EXPOSURE`, and `adj` to match your assessment choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "\n",
    "# === EDIT THESE FOR YOUR QUESTION ===\n",
    "OUTCOME  = 'Cancer_incident'          # e.g., 'Cancer_incident' or 'CVD_incident'\n",
    "EXPOSURE = 'red_meat_g_d'             # e.g., 'red_meat_g_d' or 'salt_g_d'\n",
    "adj = ['age','sex','BMI','SES_class','IMD_quintile','smoking_status']\n",
    "# ===================================\n",
    "\n",
    "dat = df[[OUTCOME, EXPOSURE] + adj].dropna().copy()\n",
    "def wrap_cat(d, v):\n",
    "    return f\"C({v})\" if (d[v].dtype=='object' or str(d[v].dtype).startswith('category')) else v\n",
    "rhs_adj = ' + '.join([EXPOSURE] + [wrap_cat(dat, v) for v in adj])\n",
    "\n",
    "def fitlog(formula, data):\n",
    "    y, X = dmatrices(formula, data=data, return_type='dataframe')\n",
    "    return sm.Logit(y, X).fit(disp=False)\n",
    "\n",
    "fit_u  = fitlog(f\"{OUTCOME} ~ {EXPOSURE}\", dat)\n",
    "fit_a  = fitlog(f\"{OUTCOME} ~ \" + rhs_adj, dat)\n",
    "\n",
    "def tidy_or(f):\n",
    "    OR = np.exp(f.params).rename('OR')\n",
    "    CI = np.exp(f.conf_int()).rename(columns={0:'2.5%',1:'97.5%'})\n",
    "    return pd.concat([OR,CI], axis=1).round(3)\n",
    "\n",
    "tab_u = tidy_or(fit_u).filter(like=EXPOSURE, axis=0)\n",
    "tab_a = tidy_or(fit_a).filter(like=EXPOSURE, axis=0)\n",
    "tab = pd.concat([tab_u.assign(Model='Unadjusted'), tab_a.assign(Model='Adjusted')])\n",
    "tab = tab[['Model','OR','2.5%','97.5%']]\n",
    "tab.to_csv('submission/primary_logistic_or.csv', index=True)\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Helper — Table 1 export\n",
    "If you used the `make_table1` utility in notebook 02, re-use it here. Otherwise, this quick variant creates a minimal overall + by-outcome table and writes to CSV. Edit the outcome and variable lists as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "Path('submission').mkdir(exist_ok=True)\n",
    "\n",
    "OUTCOME = OUTCOME  # keep aligned with the cell above\n",
    "cont = ['age','BMI','SBP','energy_kcal','fruit_veg_g_d','red_meat_g_d','salt_g_d']\n",
    "cat  = ['sex','smoking_status','physical_activity','SES_class','IMD_quintile','menopausal_status']\n",
    "\n",
    "def simple_table1(data, group, cont, cat):\n",
    "    pieces = []\n",
    "    # continuous\n",
    "    for v in cont:\n",
    "        g = data.groupby(group)[v].agg(['mean','std','median','count']).round(2)\n",
    "        g.index.name = 'group'\n",
    "        g['variable'] = v\n",
    "        g = g.reset_index().set_index(['variable','group'])\n",
    "        pieces.append(g)\n",
    "    # categorical\n",
    "    for v in cat:\n",
    "        ct = (data.groupby([group, v]).size().unstack(fill_value=0))\n",
    "        pct = (ct.T / ct.T.sum()).T.round(3)\n",
    "        combined = pd.concat({'n': ct, 'pct': pct}, axis=1)\n",
    "        combined['variable'] = v\n",
    "        combined = combined.rename_axis(index={'':'level'}).reset_index().set_index(['variable','level'])\n",
    "        pieces.append(combined)\n",
    "    return pd.concat(pieces, axis=0, sort=False)\n",
    "\n",
    "t1 = simple_table1(df, OUTCOME, cont, cat)\n",
    "t1.to_csv(f'submission/table1_by_{OUTCOME}.csv')\n",
    "t1.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Helper — 500 words template\n",
    "Run this to create `submission/summary_500w.txt`; paste or edit it to fit your analysis. Keep to **≤ 500 words** (the assert warns if you exceed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "text = (\n",
    "    \"Title: [Your exposure → outcome question here]\\n\\n\"\n",
    "    \"Methods: We analysed N=[…] adults from the FB2NEP synthetic cohort. The primary outcome was […]. \"\n",
    "    \"The exposure was […], with construct validity supported by […]. We specified a DAG and selected a minimal \"\n",
    "    \"adjustment set: […]. We fit unadjusted and adjusted logistic regressions; sensitivity checks included […] (e.g., simple imputation vs CC).\\n\\n\"\n",
    "    \"Results: [Key numbers: Table 1 highlights; unadjusted OR; adjusted OR with 95% CI; brief direction of change.]\\n\\n\"\n",
    "    \"Interpretation: The adjusted association suggests […]. Given measurement error and residual confounding, \"\n",
    "    \"the true effect may be […]. Findings align/contrast with […].\\n\\n\"\n",
    "    \"Limitations: Synthetic data; exposure misclassification; potential MNAR missingness; model misspecification; generalisability.\\n\"\n",
    ")\n",
    "Path('submission').mkdir(exist_ok=True)\n",
    "Path('submission/summary_500w.txt').write_text(text, encoding='utf-8')\n",
    "print('Wrote submission/summary_500w.txt (edit this file to finalise text).')\n",
    "assert len(text.split()) <= 500, 'Keep the summary ≤ 500 words.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Self-check vs marking rubric\n",
    "\n",
    "- **Data handling & clarity (25%)**: Does your Table 1 match the question? Missingness patterns noted? Units/coding clear?\n",
    "- **Correctness & interpretation (30%)**: Are models appropriate (logistic/survival as needed)? OR/CI reported correctly?\n",
    "- **Causal reasoning (25%)**: Is the DAG coherent? Is the adjustment set minimal and justified (no colliders/mediators unless direct effect intended)?\n",
    "- **Communication (20%)**: Is the DAG legible; table readable; 500 words concise and precise (British English)?\n",
    "\n",
    "Final tip: make sure the **n** used in models is explicit (after exclusions/imputation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Key takeaways\n",
    ">\n",
    "> - Your analysis should tell a coherent causal story from **DAG → model → result → interpretation**.\n",
    "> - Prefer **simplicity with justification** over complicated models without diagnostics.\n",
    "> - Export your artefacts to `submission/` and verify with the checklist before uploading."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
