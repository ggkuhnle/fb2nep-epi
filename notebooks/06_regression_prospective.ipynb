{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 · Regression analysis (prospective: logistic & survival)\n",
    "\n",
    "> **Purpose**: analyse incident outcomes using logistic regression (risk over follow-up) and time-to-event models (Cox proportional hazards).\n",
    "\n",
    "> **Learning objectives**\n",
    "- Construct follow-up time and censoring from baseline and event dates.\n",
    "- Fit incident-outcome **logistic regression** (didactic) and interpret ORs.\n",
    "- Fit a **Cox PH** model with `statsmodels` (PHReg) and interpret hazard ratios.\n",
    "- Run light diagnostics: PH reasonableness, non-linearity, sensitivity to adjustment sets.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Bootstrap: ensure repo root on path, then import init\n",
    "import sys, pathlib\n",
    "sys.path.append(str(pathlib.Path.cwd().parent))\n",
    "from scripts.bootstrap import init\n",
    "df, ctx = init()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Build a survival dataset\n",
    "We need **time** from baseline to event (or censor) and an **event** indicator (1=event, 0=censored). If there’s no explicit study end date, we assume **administrative censoring at 10 years** (teaching default). Edit the outcome/exposure below to change question.\n",
    "\n",
    "_Default example_: `salt_g_d → CVD_incident` (confounders: age, sex, SES, IMD, smoking, BMI)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "\n",
    "# === EDIT THESE FOR YOUR QUESTION ===\n",
    "OUTCOME_FLAG = 'CVD_incident'       # or 'Cancer_incident'\n",
    "OUTCOME_DATE = 'CVD_date'           # or 'Cancer_date'\n",
    "EXPOSURE     = 'salt_g_d'           # e.g., 'red_meat_g_d'\n",
    "ADJUST = ['age','sex','BMI','SES_class','IMD_quintile','smoking_status']\n",
    "# ===================================\n",
    "\n",
    "use = ['id','baseline_date', OUTCOME_FLAG, OUTCOME_DATE, EXPOSURE] + ADJUST\n",
    "surv = df[use].copy()\n",
    "\n",
    "# Parse dates (robust to string/NA)\n",
    "for c in ['baseline_date', OUTCOME_DATE]:\n",
    "    if c in surv:\n",
    "        surv[c] = pd.to_datetime(surv[c], errors='coerce')\n",
    "\n",
    "# Administrative censor if no event: 10 years after baseline (teaching default)\n",
    "admin_censor_days = 3650\n",
    "surv['censor_date'] = surv['baseline_date'] + pd.to_timedelta(admin_censor_days, unit='D')\n",
    "surv['event'] = surv[OUTCOME_FLAG].fillna(0).astype(int)\n",
    "surv['event_date'] = np.where(surv['event']==1, surv[OUTCOME_DATE], pd.NaT)\n",
    "surv['time_end'] = np.where(surv['event']==1, surv['event_date'], surv['censor_date'])\n",
    "surv['time_days'] = (pd.to_datetime(surv['time_end']) - pd.to_datetime(surv['baseline_date'])).dt.days\n",
    "surv['time_years'] = surv['time_days'] / 365.25\n",
    "\n",
    "# Drop impossible/negative times\n", 
    "surv = surv[(surv['time_years'] > 0) & ~surv['time_years'].isna()].copy()\n",
    "surv[['time_years','event']].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Sanity_: median follow-up should be several years; event proportion matches cohort design (roughly 10–12% by construction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Incident logistic regression (teaching)\n",
    "Treat the **incident flag** as a binary outcome and model it with logistic regression. This ignores varying follow-up time but is useful as a didactic baseline; **Cox** below is preferred for time-to-event with censoring."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "\n",
    "work = surv.dropna(subset=[OUTCOME_FLAG, EXPOSURE]).copy()\n",
    "work['exp_log1p'] = np.log1p(work[EXPOSURE])  # often helpful\n",
    "\n",
    "def cat_term(df_, v):\n",
    "    return f\"C({v})\" if (v in df_.columns and (df_[v].dtype=='object' or str(df_[v].dtype).startswith('category'))) else v\n",
    "\n",
    "rhs_u = 'exp_log1p'\n",
    "y_u, X_u = dmatrices(f'{OUTCOME_FLAG} ~ {rhs_u}', data=work, return_type='dataframe')\n",
    "fit_log_u = sm.Logit(y_u, X_u).fit(disp=False)\n",
    "\n",
    "rhs_a = ' + '.join(['exp_log1p'] + [cat_term(work, v) for v in ADJUST])\n",
    "y_a, X_a = dmatrices(f'{OUTCOME_FLAG} ~ ' + rhs_a, data=work, return_type='dataframe')\n",
    "fit_log_a = sm.Logit(y_a, X_a).fit(disp=False)\n",
    "\n",
    "def tidy_or(f):\n",
    "    OR = np.exp(f.params).rename('OR')\n",
    "    CI = np.exp(f.conf_int()).rename(columns={0:'2.5%',1:'97.5%'})\n",
    "    return pd.concat([OR,CI], axis=1).round(3)\n",
    "\n",
    "tidy_or(fit_log_u).filter(like='exp_log1p', axis=0), tidy_or(fit_log_a).filter(like='exp_log1p', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: OR for `exp_log1p` approximates the multiplicative change in **odds** of having an event during follow-up per 1-unit increase in log(1+exposure), adjusted for covariates. Use hazard ratios from Cox below when time matters (it usually does)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Cox proportional hazards (PHReg, statsmodels)\n",
    "We model **time_years** with censoring using the Cox PH model as implemented in `statsmodels.duration.hazard_regression.PHReg`. We’ll include the exposure (log1p) and the same confounders. (No extra dependencies.)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from statsmodels.duration.hazard_regression import PHReg\n",
    "\n",
    "# Build design: encode categoricals as dummies (no intercept; PHReg handles baseline via partial likelihood)\n",
    "Z = work[['exp_log1p'] + ADJUST].copy()\n",
    "Z = pd.get_dummies(Z, drop_first=True)\n",
    "\n",
    "endog = work['time_years']\n",
    "status = work['event']\n",
    "\n",
    "cox = PHReg(endog, Z, status=status)\n",
    "res_cox = cox.fit(disp=False)\n",
    "res_cox.summary()  # shows log(HR) coefficients and SEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract hazard ratios (HR)** for readability:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = res_cox.params\n",
    "conf   = res_cox.conf_int()\n",
    "HR = np.exp(params).rename('HR')\n",
    "HR_CI = np.exp(conf)\n",
    "hr_tab = pd.concat([HR, HR_CI], axis=1).rename(columns={0:'2.5%',1:'97.5%'}).round(3)\n",
    "hr_tab.filter(like='exp_log1p', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: HR > 1 for `exp_log1p` suggests higher hazard (instantaneous risk) with higher exposure, conditional on the covariates and the PH assumption.\n",
    "\n",
    "### Non-linearity / scaling\n",
    "As in cross-sectional models, it’s reasonable to consider a log transform (`log1p`) for skewed exposures and to test simple **curvature** (e.g., quadratic term) if diagnostics suggest it. Keep models interpretable; justify with EDA and clinical sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Light PH diagnostics\n",
    "Formal tests are involved; here’s a **quick, pragmatic check**: interact key covariates with log(time) and test if interactions are ~0 (violations if large & significant). This is a *heuristic* rather than a full Schoenfeld analysis."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "work_diag = work.copy()\n",
    "work_diag['log_t'] = np.log(work_diag['time_years'])\n",
    "Z0 = pd.get_dummies(work_diag[['exp_log1p'] + ADJUST], drop_first=True)\n",
    "Zt = Z0.mul(work_diag['log_t'], axis=0)\n",
    "Z_ph = pd.concat([Z0, Zt.add_suffix(':log_t')], axis=1)\n",
    "\n",
    "cox_ph = PHReg(work_diag['time_years'], Z_ph, status=work_diag['event'])\n",
    "res_ph = cox_ph.fit(disp=False)\n",
    "# Pull interaction rows only\n",
    "ph_terms = res_ph.params[res_ph.params.index.str.endswith(':log_t')]\n",
    "ph_ci = res_ph.conf_int().loc[ph_terms.index]\n",
    "ph_tab = pd.concat([ph_terms.rename('coef'), ph_ci], axis=1).rename(columns={0:'2.5%',1:'97.5%'}).round(3)\n",
    "ph_tab.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Heuristic_: large interactions (CI far from 0) suggest PH issues for those covariates. If present, consider stratification, time-varying effects, or restricting follow-up periods, and **report the limitation** transparently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Sensitivity: alternative adjustment sets\n",
    "Compare unadjusted, minimal sufficient set (from your **DAG**), and an over-adjusted set (including a potential **mediator**) to illustrate estimate movement. Keep your primary estimand clear (total vs direct effect)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cox_fit(exposure, adjust_vars):\n",
    "    Z = pd.get_dummies(work[['exp_log1p'] + adjust_vars].rename(columns={exposure:'exp_log1p'}), drop_first=True)\n",
    "    model = PHReg(work['time_years'], Z, status=work['event'])\n",
    "    res = model.fit(disp=False)\n",
    "    # return HR for the exposure term\n",
    "    b = res.params['exp_log1p']\n",
    "    lo, hi = res.conf_int().loc['exp_log1p']\n",
    "    return float(np.exp(b)), float(np.exp(lo)), float(np.exp(hi))\n",
    "\n",
    "sets = {\n",
    "  'Unadjusted': [],\n",
    "  'Minimal DAG set': ['age','sex','SES_class','IMD_quintile','smoking_status'],\n",
    "  'Over-adjusted (adds BMI)': ['age','sex','SES_class','IMD_quintile','smoking_status','BMI']\n",
    "}\n",
    "rows = []\n",
    "for name, s in sets.items():\n",
    "    try:\n",
    "        hr, lo, hi = cox_fit(EXPOSURE, s)\n",
    "        rows.append({'Model': name, 'HR': round(hr,3), '2.5%': round(lo,3), '97.5%': round(hi,3)})\n",
    "    except Exception as e:\n",
    "        rows.append({'Model': name, 'HR': np.nan, '2.5%': np.nan, '97.5%': np.nan})\n",
    "import pandas as pd\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) # TODO — your practice\n",
    "1. Swap to **`EXPOSURE='red_meat_g_d'`** and **`OUTCOME='Cancer_incident'`**; repeat the logistic and Cox analyses. Report OR and HR with 95% CI.\n",
    "2. Test a non-linear exposure term (e.g., **quadratic** or log1p vs raw). Does fit or interpretation improve?\n",
    "3. Rerun Cox with your **minimal sufficient adjustment set** from the DAG notebook. How does the exposure HR move vs unadjusted and over-adjusted?\n",
    "4. Briefly comment on **PH reasonableness** using the log-time interactions table. Any large deviations?\n",
    "5. (Optional) Export a tidy CSV with your final HR result for the assessment submission."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# (5) Export final HR for the exposure (edit label as needed)\n",
    "final = {'Exposure': EXPOSURE, 'Outcome': OUTCOME_FLAG, 'HR': hr_tab.loc['exp_log1p','HR'] if 'HR' in hr_tab else np.nan,\n",
    "         'CI_low': hr_tab.loc['exp_log1p','2.5%'] if 'HR' in hr_tab else np.nan,\n",
    "         'CI_high': hr_tab.loc['exp_log1p','97.5%'] if 'HR' in hr_tab else np.nan}\n",
    "pd.DataFrame([final]).to_csv('submission/final_hr.csv', index=False)\n",
    "print('Saved submission/final_hr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Key takeaways\n",
    ">\n",
    "> - Construct time & censoring carefully; Cox PH is the standard for time-to-event with censoring.\n",
    "> - Logistic on the incident flag is **didactic**; report ORs but prefer HRs when time varies.\n",
    "> - Keep transformations and non-linearity **motivated** by EDA and diagnostics.\n",
    "> - Adjustment sets should follow your **DAG**; show how estimates move under different sets and discuss why.\n",
    "> - Document assumptions (PH, measurement error, residual confounding) and provide a brief sensitivity narrative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
  "language_info": { "name": "python" }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

