{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro_fb2nep_6",
      "metadata": {},
      "source": [
        "# FB2NEP Workbook 6 – Regression and Modelling (Part 1)\n",
        "\n",
        "This workbook introduces the foundations of regression modelling in nutritional epidemiology.\n",
        "\n",
        "We focus on:\n",
        "\n",
        "- Theoretical background to regression.\n",
        "- Linear regression.\n",
        "- Logistic regression.\n",
        "- Model assumptions and diagnostics.\n",
        "- Interpretation of coefficients (β), odds ratios (OR), and the idea of hazard ratios (HR).\n",
        "- A first introduction to confounding, colliders, mediators, and causal diagrams.\n",
        "\n",
        "All analyses use the synthetic *FB2NEP cohort*.\n",
        "\n",
        "Run the first code cell to configure the repository and load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "id": "bootstrap_fb2nep_6",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# FB2NEP bootstrap cell – use in *all* workbooks\n",
        "#\n",
        "# This cell initialises the repository context and loads the synthetic cohort\n",
        "# into a DataFrame called df. It tries a few possible locations for scripts/bootstrap.py.\n",
        "\n",
        "import pathlib\n",
        "import runpy\n",
        "\n",
        "bootstrap_candidates = [\n",
        "    \"scripts/bootstrap.py\",\n",
        "    \"../scripts/bootstrap.py\",\n",
        "    \"../../scripts/bootstrap.py\",\n",
        "]\n",
        "\n",
        "bootstrap_ns = None\n",
        "\n",
        "for rel in bootstrap_candidates:\n",
        "    p = pathlib.Path(rel)\n",
        "    if p.exists():\n",
        "        print(f\"Loading bootstrap from: {p}\")\n",
        "        bootstrap_ns = runpy.run_path(str(p))\n",
        "        break\n",
        "else:\n",
        "    raise FileNotFoundError(\n",
        "        \"Could not find scripts/bootstrap.py. \"\n",
        "        \"Please check that you are running this notebook inside fb2nep-epi.\"\n",
        "    )\n",
        "\n",
        "if \"init\" not in bootstrap_ns:\n",
        "    raise RuntimeError(\"bootstrap.py does not define init().\")\n",
        "\n",
        "# init() returns the main DataFrame and a context object\n",
        "df, CTX = bootstrap_ns[\"init\"]()\n",
        "\n",
        "# Convenience variables used in several workbooks\n",
        "REPO_ROOT = CTX.repo_root\n",
        "CSV_REL = CTX.csv_rel\n",
        "IN_COLAB = CTX.in_colab\n",
        "\n",
        "print(\"Repository root:\", REPO_ROOT)\n",
        "print(\"Main dataset:\", CSV_REL)\n",
        "print(\"df shape:\", df.shape)\n",
        "print(\"IN_COLAB:\", IN_COLAB)"
      ]
    },
    {
      "cell_type": "code",
      "id": "inspect_data_fb2nep_6",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Quick inspection of the first rows and selected variables\n",
        "#\n",
        "# The goal of this cell is simply to become familiar with the structure of the\n        "# dataset and to check that the key variables required for this workbook are present.\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "display(df.head())\n",
        "\n",
        "cols_of_interest = [c for c in [\"SBP\", \"BMI\", \"age\", \"sex\", \"smoking_status\", \"CVD_incident\"] if c in df.columns]\n",
        "print(\"\\nColumns of interest:\", cols_of_interest)\n",
        "display(df[cols_of_interest].dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "id": "imports_fb2nep_6",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Import packages used throughout this workbook\n",
        "#\n",
        "# pandas      – data handling (DataFrame operations)\n",
        "# numpy       – numerical operations and random number generation\n",
        "# matplotlib  – basic plotting\n",
        "# statsmodels – regression modelling (linear and logistic)\n",
        "# scipy.stats – additional statistical functions (for example, skewness)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from scipy import stats\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Significance level used for confidence intervals\n",
        "#\n",
        "# In most applications, alpha = 0.05 is used (corresponding to a 95 % confidence interval).\n",
        "# In this module we occasionally use a slightly unusual value for alpha, mainly to\n        "# emphasise the relationship between alpha and the confidence level.\n",
        "\n",
        "ALPHA = 0.0314\n",
        "print(f\"Using alpha = {ALPHA:.4f}; nominal confidence level = {100 * (1 - ALPHA):.2f} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "theory_intro_fb2nep_6",
      "metadata": {},
      "source": [
        "# 0. Theoretical background\n",
        "\n",
        "Regression models allow us to quantify how an outcome changes when predictors change,\n",
        "while adjusting for other relevant variables.\n",
        "\n",
        "Regression is central to observational epidemiology because we rarely compare\n",
        "single exposure groups in isolation. Instead, we typically adjust for age, sex,\n",
        "socio-economic status, and other potential confounders."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "what_is_regression_fb2nep_6",
      "metadata": {},
      "source": [
        "## 0.1 What is a regression model?\n",
        "\n",
        "A regression model expresses the expected value of an outcome as a function of one or\n        "more predictors.\n",
        "\n",
        "Examples in nutritional epidemiology include questions such as:\n",
        "\n",
        "- How does systolic blood pressure (SBP) vary with BMI, age, and sex?\n",
        "- How does the probability of cardiovascular disease (CVD) vary with smoking status?\n",
        "\n",
        "Different regression types address different kinds of outcomes:\n",
        "\n",
        "- **Linear regression** – continuous outcomes (for example, SBP, BMI).\n",
        "- **Logistic regression** – binary outcomes (for example, incident CVD: yes/no).\n",
        "- **Cox regression** – time-to-event outcomes (for example, time to CVD event; introduced conceptually here and in more detail in a later workbook).\n",
        "\n",
        "Regression models are essential for:\n",
        "\n",
        "- Describing associations.\n",
        "- Adjusting for confounding.\n",
        "- Making predictions for new observations.\n",
        "- Providing a building block for more advanced causal analyses."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "assumptions_fb2nep_6",
      "metadata": {},
      "source": [
        "## 0.2 Assumptions of linear regression\n",
        "\n",
        "Linear regression rests on several assumptions about the relationship between predictors\n",
        "and outcome, and about the residuals (errors).\n",
        "\n",
        "1. **Linearity**  \n",
        "   The relationship between each predictor and the outcome is approximately linear.\n",
        "\n",
        "2. **Normally distributed residuals**  \n",
        "   Residuals (differences between observed and fitted values) should follow an\n",
        "   approximately normal distribution.\n",
        "\n",
        "3. **Homoscedasticity** (constant variance)  \n",
        "   The variance of residuals should be roughly constant across the range of fitted values.\n",
        "\n",
        "4. **Independence**  \n",
        "   Observations (and their errors) are independent of one another.\n",
        "\n",
        "In practice, these assumptions are rarely met perfectly, but we aim for them to be\n",
        "approximately satisfied. Diagnostic plots help to assess this."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "coeff_interp_fb2nep_6",
      "metadata": {},
      "source": [
        "## 0.3 Interpretation of regression coefficients\n",
        "\n",
        "### Linear regression\n",
        "\n",
        "In a linear model, the coefficient β for a predictor represents the average change in\n",
        "the outcome associated with a one-unit increase in that predictor, assuming all other\n",
        "variables in the model are held constant.\n",
        "\n",
        "For example, in a model `SBP ~ BMI + age + sex`, the coefficient of BMI expresses how\n",
        "many mmHg SBP changes per 1 kg/m² difference in BMI, adjusted for age and sex.\n",
        "\n",
        "### Logistic regression\n",
        "\n",
        "Logistic regression models the log-odds of a binary outcome. Coefficients operate on\n",
        "the log-odds scale, but after exponentiation, `exp(β)`, they can be interpreted as\n",
        "odds ratios (OR):\n",
        "\n",
        "- OR > 1 suggests increased odds of the outcome.\n",
        "- OR < 1 suggests decreased odds of the outcome.\n",
        "\n",
        "### Cox regression (conceptual)\n",
        "\n",
        "In Cox regression for time-to-event outcomes, coefficients are interpreted on the\n",
        "log-hazard scale. After exponentiation, `exp(β)` is a **hazard ratio (HR)**:\n",
        "\n",
        "- HR > 1 suggests a higher instantaneous risk (hazard) of the event.\n",
        "- HR < 1 suggests a lower instantaneous risk.\n",
        "\n",
        "Cox regression is introduced conceptually here and used more formally in a later workbook.\n",
        "\n",
        "We return to interpretation of β, OR, and HR after fitting models to the FB2NEP dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sim_intro_fb2nep_6",
      "metadata": {},
      "source": [
        "## 0.4 Simulated example: residuals and assumptions\n",
        "\n",
        "Before working with real data, we use a simple simulated example to illustrate\n",
        "the behaviour of residuals when model assumptions are satisfied and when they\n",
        "are clearly violated.\n",
        "\n",
        "We generate two artificial datasets:\n",
        "\n",
        "- Case 1: residuals approximately normal, homoscedastic.\n",
        "- Case 2: residuals skewed and heteroscedastic (variance increases with fitted values)."
      ]
    },
    {
      "cell_type": "code",
      "id": "sim_residuals_fb2nep_6",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulated example: normal vs skewed / heteroscedastic residuals\n",
        "#\n",
        "# The main purpose of this cell is to visualise how residuals can look when the\n        "# assumptions of linear regression are satisfied or clearly violated.\n",
        "\n",
        "# Number of observations\n",
        "n = 500\n",
        "\n",
        "# Predictor x from a standard normal distribution\n",
        "x = np.random.normal(0, 1, size=n)\n",
        "\n",
        "# Case 1: assumptions approximately satisfied\n",
        "# -------------------------------------------\n",
        "# Outcome y1 follows a linear relation with x plus normal residuals.\n",
        "eps1 = np.random.normal(0, 1, size=n)\n",
        "y1 = 3 + 2 * x + eps1\n",
        "\n",
        "# Fit a simple linear model y1 ~ x using numpy.polyfit\n",
        "b1 = np.polyfit(x, y1, 1)\n",
        "fitted1 = b1[1] + b1[0] * x\n",
        "res1 = y1 - fitted1\n",
        "\n",
        "# Case 2: assumptions clearly violated\n",
        "# ------------------------------------\n",
        "# Outcome y2 has the same linear component, but residuals are skewed\n",
        "# (for example, from an exponential distribution). This leads to\n",
        "# non-normal and heteroscedastic residuals.\n",
        "eps2 = np.random.exponential(scale=1.0, size=n)\n",
        "y2 = 3 + 2 * x + eps2\n",
        "\n",
        "b2 = np.polyfit(x, y2, 1)\n",
        "fitted2 = b2[1] + b2[0] * x\n",
        "res2 = y2 - fitted2\n",
        "\n",
        "# Plot residuals vs fitted values for both cases\n",
        "fig, axes = plt.subplots(1, 2, figsize=(11, 4))\n",
        "\n",
        "axes[0].scatter(fitted1, res1, alpha=0.4)\n",
        "axes[0].axhline(0, color=\"black\", linestyle=\"--\")\n",
        "axes[0].set_title(\"Normal residuals: assumptions satisfied\")\n",
        "axes[0].set_xlabel(\"Fitted values\")\n",
        "axes[0].set_ylabel(\"Residuals\")\n",
        "\n",
        "axes[1].scatter(fitted2, res2, alpha=0.4)\n",
        "axes[1].axhline(0, color=\"black\", linestyle=\"--\")\n",
        "axes[1].set_title(\"Skewed residuals: assumptions violated\")\n",
        "axes[1].set_xlabel(\"Fitted values\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Case 1 residual skewness:\", stats.skew(res1))\n",
        "print(\"Case 2 residual skewness:\", stats.skew(res2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sim_exercise_fb2nep_6",
      "metadata": {},
      "source": [
        "### Exercise (short)\n",
        "\n",
        "- How do the two panels differ in terms of the spread and symmetry of residuals?\n",
        "- In which case would you be more comfortable applying linear regression methods\n",
        "  that assume normal, homoscedastic residuals?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lin_model_intro_fb2nep_6",
      "metadata": {},
      "source": [
        "# 1. Linear regression in practice\n",
        "\n",
        "We now move to the FB2NEP dataset and fit a linear regression model.\n",
        "\n",
        "We model systolic blood pressure (SBP) as a function of:\n",
        "\n",
        "- BMI (kg/m²)\n",
        "- age (years)\n",
        "- sex (male/female)\n",
        "\n",
        "This reflects a typical epidemiological model with established determinants of blood pressure."
      ]
    },
    {
      "cell_type": "code",
      "id": "lin_model_fit_fb2nep_6",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Linear regression model for SBP\n",
        "#\n",
        "# Steps in this cell:\n",
        "# 1. Ensure that sex is treated as a categorical variable.\n",
        "# 2. Specify the model using a formula (SBP as outcome, BMI, age, and sex as predictors).\n",
        "# 3. Fit the model using ordinary least squares (OLS).\n",
        "# 4. Display a detailed summary of the fitted model.\n",
        "\n",
        "# 1. Ensure that sex is treated as a categorical variable\n",
        "if \"sex\" in df.columns:\n",
        "    df[\"sex\"] = df[\"sex\"].astype(\"category\")\n",
        "\n",
        "# 2. Specify and 3. fit the linear regression model using a formula\n",
        "formula_lin = \"SBP ~ BMI + age + C(sex)\"\n",
        "model_lin = smf.ols(formula_lin, data=df).fit()\n",
        "\n",
        "# 4. Show a detailed summary of the fitted model\n",
        "model_lin.summary()"
      ]
    },
    {
      "cell_type": "code",
      "id": "lin_model_params_fb2nep_6",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Inspect estimated coefficients and confidence intervals\n",
        "#\n",
        "# model_lin.params        – point estimates of β\n",
        "# model_lin.conf_int(...) – confidence intervals for β\n",
        "#\n",
        "# The confidence level is determined by ALPHA defined earlier:\n",
        "# confidence level = 100 * (1 - ALPHA) %.\n",
        "\n",
        "print(\"Estimated coefficients (β):\")\n",
        "print(model_lin.params)\n",
        "\n",
        "conf_level = 100 * (1 - ALPHA)\n",
        "print(f\"\\n{conf_level:.2f} % confidence intervals for coefficients (alpha = {ALPHA}):\")\n",
        "model_lin.conf_int(alpha=ALPHA)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lin_model_interp_fb2nep_6",
      "metadata": {},
      "source": [
        "### Interpretation exercise\n",
        "\n",
        "Using the output above:\n",
        "\n",
        "- How would you describe the association between BMI and SBP in words?\n",
        "- How does SBP differ on average between men and women (reference category vs\n",
        "  indicator category)?\n",
        "- Does the confidence interval for age suggest a precise estimate, given the\n",
        "  confidence level used in the previous cell?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "diagnostics_intro_fb2nep_6",
      "metadata": {},
      "source": [
        "# 2. Diagnostics for the linear model\n",
        "\n",
        "We now examine whether the model assumptions appear reasonable for the fitted\n",
        "linear regression.\n",
        "\n",
        "We plot:\n",
        "\n",
        "- Residuals versus fitted values (for homoscedasticity).\n",
        "- The distribution of residuals (for approximate normality)."
      ]
    },
    {
      "cell_type": "code",
      "id": "diagnostics_plots_fb2nep_6",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Diagnostic plots for the SBP linear model\n",
        "#\n",
        "# Steps:\n",
        "# 1. Extract fitted values and residuals from the model.\n",
        "# 2. Plot residuals against fitted values to inspect homoscedasticity.\n",
        "# 3. Plot a histogram of residuals to inspect approximate normality.\n",
        "\n",
        "# 1. Extract fitted values and residuals from the model\n",
        "fitted = model_lin.fittedvalues\n",
        "residuals = model_lin.resid\n",
        "\n",
        "# 2 and 3. Create diagnostic plots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(11, 4))\n",
        "\n",
        "# Plot 1: residuals vs fitted\n",
        "axes[0].scatter(fitted, residuals, alpha=0.4)\n",
        "axes[0].axhline(0, color=\"black\", linestyle=\"--\")\n",
        "axes[0].set_title(\"Residuals vs fitted values\")\n",
        "axes[0].set_xlabel(\"Fitted SBP\")\n",
        "axes[0].set_ylabel(\"Residuals\")\n",
        "\n",
        "# Plot 2: histogram of residuals\n",
        "axes[1].hist(residuals, bins=30)\n",
        "axes[1].set_title(\"Distribution of residuals\")\n",
        "axes[1].set_xlabel(\"Residual\")\n",
        "axes[1].set_ylabel(\"Number of observations\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "diagnostics_ex_fb2nep_6",
      "metadata": {},
      "source": [
        "### Exercise (diagnostics)\n",
        "\n",
        "- Does the spread of residuals appear roughly constant across fitted values,\n",
        "  or does it increase or decrease?\n",
        "- Do residuals appear approximately symmetric around zero?\n",
        "- Are there any obvious outliers or clusters of points that might require\n",
        "  further investigation?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "logit_intro_fb2nep_6",
      "metadata": {},
      "source": [
        "# 3. Logistic regression: incident CVD as outcome\n",
        "\n",
        "Many epidemiological outcomes are binary: participants either experience an\n",
        "event or they do not.\n",
        "\n",
        "Here, we model incident cardiovascular disease (`CVD_incident`, 0/1) as a function of:\n",
        "\n",
        "- age\n",
        "- BMI\n",
        "- sex\n",
        "- smoking status\n",
        "\n",
        "The logistic model estimates log-odds. After exponentiation, coefficients are\n",
        "interpreted as odds ratios."
      ]
    },
    {
      "cell_type": "code",
      "id": "logit_fit_fb2nep_6",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Logistic regression model for incident CVD\n",
        "#\n",
        "# Steps in this cell:\n",
        "# 1. Ensure that smoking status is treated as a categorical variable.\n",
        "# 2. Restrict the dataset to complete cases for all variables used in the model.\n",
        "# 3. Specify the logistic regression formula.\n",
        "# 4. Fit the model and display a summary.\n",
        "\n",
        "# 1. Ensure that smoking status is treated as a categorical variable\n",
        "if \"smoking_status\" in df.columns:\n",
        "    df[\"smoking_status\"] = df[\"smoking_status\"].astype(\"category\")\n",
        "\n",
        "# 2. Restrict to rows with complete data on all variables used in the model\n",
        "required_cols = [\"CVD_incident\", \"age\", \"BMI\", \"sex\", \"smoking_status\"]\n",
        "df_logit = df.dropna(subset=required_cols)\n",
        "\n",
        "print(\"Number of observations used in logistic regression:\", df_logit.shape[0])\n",
        "\n",
        "# 3. Specify and 4. fit the logistic regression model\n",
        "formula_logit = \"CVD_incident ~ age + BMI + C(sex) + C(smoking_status)\"\n",
        "model_logit = smf.logit(formula_logit, data=df_logit).fit()\n",
        "\n",
        "# Show a detailed summary\n",
        "model_logit.summary()"
      ]
    },
    {
      "cell_type": "code",
      "id": "logit_or_fb2nep_6",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Extract odds ratios and confidence intervals from the logistic model\n",
        "#\n",
        "# model_logit.params           – coefficients on the log-odds scale\n",
        "# np.exp(params)              – odds ratios (OR)\n",
        "# model_logit.conf_int(...)   – confidence intervals on the log-odds scale\n",
        "# np.exp(conf_int)            – confidence intervals for OR\n",
        "\n",
        "params = model_logit.params\n",
        "conf_int = model_logit.conf_int(alpha=ALPHA)\n",
        "\n",
        "# Convert to odds ratios and odds ratio confidence intervals\n",
        "OR = np.exp(params)\n",
        "CI_lower = np.exp(conf_int[0])\n",
        "CI_upper = np.exp(conf_int[1])\n",
        "\n",
        "or_table = pd.DataFrame({\n",
        "    \"OR\": OR,\n",
        "    \"CI_lower\": CI_lower,\n",
        "    \"CI_upper\": CI_upper\n",
        "})\n",
        "\n",
        "conf_level = 100 * (1 - ALPHA)\n",
        "print(f\"Odds ratios with {conf_level:.2f} % confidence intervals (alpha = {ALPHA}):\")\n",
        "or_table"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "logit_interp_fb2nep_6",
      "metadata": {},
      "source": [
        "## 3.1 Interpreting odds ratios\n",
        "\n",
        "Using the odds ratio table above:\n",
        "\n",
        "- How does the odds of incident CVD change per 1 kg/m² increase in BMI?\n",
        "- How does the odds of incident CVD compare between current smokers and never smokers?\n",
        "- For age, what does the odds ratio per year mean in practice? Would it be more\n",
        "  interpretable to express the effect per 10 years (for example, by multiplying\n",
        "  the coefficient by 10 before exponentiation)?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "confounding_intro_fb2nep_6",
      "metadata": {},
      "source": [
        "# 4. Confounding, colliders, mediators, and model structure\n",
        "\n",
        "Regression models are often used to address **confounding**.\n",
        "\n",
        "A *confounder* is a variable that is associated with both the exposure and the\n",
        "outcome, and is not on the causal pathway between them.\n",
        "\n",
        "For example, consider a simple structure:\n",
        "\n",
        "```text\n",
        "age → BMI → SBP\n",
        "age → SBP\n",
        "```\n",
        "\n",
        "- Age influences both BMI and SBP.\n",
        "- If age is not included in the model, the estimated association between BMI and\n",
        "  SBP may be distorted (confounded).\n",
        "\n",
        "### 4.1 Mediators and colliders\n",
        "\n",
        "- A *mediator* lies on the causal pathway between exposure and outcome\n",
        "  (for example, diet → blood lipids → CVD). Adjusting for a mediator changes the\n",
        "  interpretation of the exposure effect: it becomes a *direct* effect.\n",
        "\n",
        "- A *collider* is a variable that is influenced by two or more other variables\n",
        "  (for example, BMI → hospital admission ← smoking). Conditioning on a collider\n",
        "  (for example, restricting to admitted patients) can create *spurious* associations\n",
        "  between its causes.\n",
        "\n",
        "Later workbooks will explore more complex structures, including explicit examples\n",
        "of collider bias and mediation analysis.\n",
        "\n",
        "### 4.2 Directed acyclic graphs (DAGs)\n",
        "\n",
        "Directed acyclic graphs (DAGs) are simple diagrams that encode assumptions about\n",
        "causal structure:\n",
        "\n",
        "- Nodes represent variables (for example, age, BMI, SBP).\n",
        "- Arrows represent assumed causal relationships.\n",
        "- There are no feedback loops (no directed cycles).\n",
        "\n",
        "Software such as `dagitty` can be used (in a web browser or via R) to draw DAGs and\n",
        "to identify minimal sets of variables that should be adjusted for in a regression model.\n",
        "\n",
        "In this workbook we use only simple text diagrams, but the ideas are the same.\n",
        "\n",
        "### 4.3 Causal frameworks: Bradford Hill and counterfactuals (very brief)\n",
        "\n",
        "Two complementary ways to think about causality are:\n",
        "\n",
        "- **Bradford Hill considerations** – a set of aspects such as strength of association,\n",
        "  consistency, temporality, dose–response, and plausibility. These are not strict\n",
        "  rules, but prompts to evaluate whether an observed association is *compatible* with\n",
        "  a causal explanation.\n",
        "\n",
        "- **Counterfactual framework** – compares what would happen to the *same* individual\n",
        "  under different exposure conditions (for example, CVD risk if an individual eats a\n",
        "  high-flavanol diet versus if they do not). In practice we never observe both versions\n",
        "  for the same person, so we rely on study design and adjustment (for example, via\n",
        "  regression) to approximate these comparisons.\n",
        "\n",
        "Here, the goal is simply to recognise that the choice of covariates in a regression\n",
        "model reflects assumptions about the underlying causal structure."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cox_conceptual_fb2nep_6",
      "metadata": {},
      "source": [
        "# 5. Cox regression (conceptual overview)\n",
        "\n",
        "In many cohort studies, interest lies not only in *whether* an event occurs (for example,\n",
        "incident CVD), but also in *when* it occurs. Time-to-event data can be analysed with\n",
        "survival models.\n",
        "\n",
        "The **Cox proportional hazards model** is widely used:\n",
        "\n",
        "- The outcome is time from baseline to the event (or censoring).\n",
        "- The model focuses on the *hazard* – the instantaneous risk of the event at a given time.\n",
        "- Coefficients are interpreted as hazard ratios (HR) after exponentiation.\n",
        "\n",
        "Key ideas (without code at this stage):\n",
        "\n",
        "- HR compares hazards between exposure groups, adjusted for covariates.\n",
        "- A HR of 1.3 for current smokers versus never smokers would mean that, at any given\n",
        "  time, current smokers have 30 % higher instantaneous risk of the event, assuming the\n",
        "  proportional hazards assumption holds.\n",
        "- Censoring (for example, end of follow-up, loss to follow-up, death from other causes)\n",
        "  is explicitly accounted for.\n",
        "\n",
        "Cox regression is implemented in many software packages. A later workbook will fit\n",
        "Cox models using the FB2NEP synthetic cohort."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary_fb2nep_6",
      "metadata": {},
      "source": [
        "# 6. Summary\n",
        "\n",
        "In this workbook you have:\n",
        "\n",
        "- Reviewed the concept of a regression model and why it is important in\n",
        "  nutritional epidemiology.\n",
        "- Learned about key assumptions of linear regression and how to visualise\n",
        "  residuals.\n",
        "- Fitted and interpreted a linear regression model for SBP.\n",
        "- Produced diagnostic plots to assess residual structure.\n",
        "- Fitted a logistic regression model for incident CVD and interpreted\n",
        "  coefficients as odds ratios.\n",
        "- Seen how confounding, mediators, and colliders arise from underlying causal\n",
        "  structures, and how regression adjustment attempts to address confounding.\n",
        "- Been introduced to DAGs as a tool for making causal assumptions explicit, and to\n        "two broader causal frameworks (Bradford Hill considerations and the counterfactual\n        "approach).\n",
        "- Met the basic ideas of Cox regression and hazard ratios, to be developed further\n",
        "  in a later workbook.\n",
        "\n",
        "Subsequent workbooks extend these ideas to time-to-event outcomes using Cox\n",
        "regression and provide more practice with DAGs and causal reasoning."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
