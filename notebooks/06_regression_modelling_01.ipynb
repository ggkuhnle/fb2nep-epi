{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f32623dd",
   "metadata": {},
   "source": [
    "# FB2NEP Workbook 6 – Regression and Modelling: Foundations\n",
    "\n",
    "This workbook introduces the foundations of regression modelling in nutritional epidemiology.\n",
    "\n",
    "We will focus on:\n",
    "\n",
    "- Theoretical background to regression.\n",
    "- Linear, logistic, and Cox proportional hazards regression.\n",
    "- Quantile regression.\n",
    "- Model assumptions and diagnostics.\n",
    "- Non-linear models (polynomials and splines).\n",
    "- Interpretation of coefficients (β, OR, RR, HR).\n",
    "- Generating predictions from fitted models.\n",
    "\n",
    "All analyses use the synthetic *FB2NEP cohort*.\n",
    "\n",
    "Run the first code cell to configure the repository and load the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c9bd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FB2NEP bootstrap cell\n",
    "\n",
    "This cell:\n",
    "\n",
    "- Locates and runs the common `bootstrap.py` script.\n",
    "- Makes the main analysis DataFrame `df` available.\n",
    "- Optionally exposes a context dictionary `CTX` with additional information.\n",
    "\n",
    "You *must* run this cell before running any of the later analysis cells.\n",
    "\"\"\"\n",
    "\n",
    "import pathlib\n",
    "import runpy\n",
    "\n",
    "bootstrap_paths = [\n",
    "    \"scripts/bootstrap.py\",\n",
    "    \"../scripts/bootstrap.py\",\n",
    "    \"../../scripts/bootstrap.py\",\n",
    "]\n",
    "\n",
    "CTX = None\n",
    "\n",
    "for path in bootstrap_paths:\n",
    "    if pathlib.Path(path).exists():\n",
    "        print(f\"Bootstrapping via: {path}\")\n",
    "        CTX = runpy.run_path(path)\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\"Could not find 'scripts/bootstrap.py' in any expected location.\")\n",
    "\n",
    "# Expect that bootstrap.py defines at least a DataFrame called `df`.\n",
    "if \"df\" not in CTX:\n",
    "    raise KeyError(\"The bootstrap context does not contain a DataFrame named 'df'.\")\n",
    "\n",
    "df = CTX[\"df\"]\n",
    "\n",
    "print(\"DataFrame 'df' loaded.\")\n",
    "print(\"Number of rows:\", len(df))\n",
    "print(\"Number of columns:\", df.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Inspect the first few rows and the variable types.\n",
    "\n",
    "This provides a quick overview of the FB2NEP cohort and its variables.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "display(df.head())\n",
    "display(df.dtypes.head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af831752",
   "metadata": {},
   "source": [
    "## 1. What regression is\n",
    "\n",
    "Regression modelling is a central tool in epidemiology. In its most basic form, regression estimates the **expected value** of an outcome variable given one or more predictors:\n",
    "\n",
    "\\[\n",
    "E(Y \\mid X_1, X_2, \\ldots, X_p).\n",
    "\\]\n",
    "\n",
    "The regression model describes a **systematic component** (the part explained by the predictors) and a **random component** (the unexplained variability, or error term).\n",
    "\n",
    "In this workbook we will:\n",
    "\n",
    "- Start with simple regression models.\n",
    "- Extend to different outcome types.\n",
    "- Introduce models for non-linear relationships and for different parts of the outcome distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb63901",
   "metadata": {},
   "source": [
    "### 1.1 Prediction versus inference\n",
    "\n",
    "Regression can be used for different purposes:\n",
    "\n",
    "- **Prediction**: obtain accurate predictions \\( \\hat{Y} \\) for new individuals.\n",
    "- **Inference**: estimate and interpret the parameters (for example, β, OR, HR) and their uncertainty.\n",
    "\n",
    "In nutritional epidemiology we are often interested primarily in **inference**:\n",
    "\n",
    "- How much higher is blood pressure, on average, in individuals with high sodium intake?\n",
    "- What is the hazard ratio for cardiovascular disease per 5 kg/m² higher BMI?\n",
    "\n",
    "Prediction is also important, for example when developing risk scores, but the focus in this workbook is on understanding **parameters** and **assumptions**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae40a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Simple visual example: BMI and age.\n",
    "\n",
    "Here we:\n",
    "\n",
    "- Create a scatter plot of BMI against age.\n",
    "- Add rudimentary formatting to make the figure readable.\n",
    "\n",
    "We do *not* fit a model yet; this is purely descriptive.\n",
    "\"\"\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.scatter(df[\"age\"], df[\"bmi\"], alpha=0.3, edgecolor=\"none\")\n",
    "\n",
    "ax.set_xlabel(\"Age (years)\")\n",
    "ax.set_ylabel(\"Body mass index (kg/m²)\")\n",
    "ax.set_title(\"Scatter plot of BMI against age (FB2NEP cohort)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad325f39",
   "metadata": {},
   "source": [
    "## 2. Types of regression models\n",
    "\n",
    "In this section we introduce three commonly used regression models in epidemiology:\n",
    "\n",
    "- **Linear regression** for continuous outcomes.\n",
    "- **Logistic regression** for binary outcomes.\n",
    "- **Cox proportional hazards regression** for time-to-event outcomes.\n",
    "\n",
    "The underlying idea is similar in all three cases: we model how the **expected outcome** (mean, probability, hazard) changes with predictors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb0e206",
   "metadata": {},
   "source": [
    "### 2.1 Linear regression\n",
    "\n",
    "Linear regression models a continuous outcome as a linear function of predictors:\n",
    "\n",
    "\\[\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p + \\varepsilon.\n",
    "\\]\n",
    "\n",
    "- \\( Y \\) is a continuous variable (for example, BMI or systolic blood pressure).\n",
    "- \\( X_1, X_2, \\ldots, X_p \\) are predictors (for example, age, sex, smoking status).\n",
    "- \\( \\varepsilon \\) is a random error term.\n",
    "\n",
    "The key quantity is the **conditional mean**:\n",
    "\n",
    "\\[\n",
    "E(Y \\mid X_1, \\ldots, X_p) = \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p.\n",
    "\\]\n",
    "\n",
    "The coefficient \\( \\beta_j \\) describes the expected difference in Y associated with a one-unit difference in \\( X_j \\), holding the other predictors constant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757879a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Linear regression example: BMI on age (and sex).\n",
    "\n",
    "We will:\n",
    "\n",
    "- Fit a simple linear regression model.\n",
    "- Inspect the summary output.\n",
    "- Overlay the fitted line on a scatter plot.\n",
    "\n",
    "Assumptions and diagnostics will be discussed later; for now the aim is to see the basic mechanics.\n",
    "\"\"\"\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# For this example we assume the following variables exist:\n",
    "# - 'bmi': continuous outcome\n",
    "# - 'age': continuous predictor\n",
    "# - 'sex': binary or categorical (for example 'Male', 'Female')\n",
    "\n",
    "# Fit an ordinary least squares (OLS) model using a formula interface.\n",
    "model_lin = smf.ols(\"bmi ~ age + C(sex)\", data=df)\n",
    "result_lin = model_lin.fit()\n",
    "\n",
    "# Display a standard model summary.\n",
    "result_lin.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4565c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot the fitted regression line for BMI ~ age.\n",
    "\n",
    "For visual simplicity we will:\n",
    "\n",
    "- Restrict to one sex (for example, 'Female').\n",
    "- Fit a simple model with age as the only predictor in this subgroup.\n",
    "- Overlay the fitted line on the scatter plot.\n",
    "\n",
    "This is purely for illustration.\n",
    "\"\"\"\n",
    "\n",
    "# Subset to one sex (adjust the label if your dataset uses different coding).\n",
    "df_female = df[df[\"sex\"] == \"Female\"].copy()\n",
    "\n",
    "model_lin_f = smf.ols(\"bmi ~ age\", data=df_female)\n",
    "result_lin_f = model_lin_f.fit()\n",
    "\n",
    "# Create a grid of ages spanning the observed range.\n",
    "age_grid = np.linspace(df_female[\"age\"].min(), df_female[\"age\"].max(), 100)\n",
    "pred_df = pd.DataFrame({\"age\": age_grid})\n",
    "pred_df[\"bmi_hat\"] = result_lin_f.predict(pred_df)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.scatter(df_female[\"age\"], df_female[\"bmi\"], alpha=0.3, edgecolor=\"none\", label=\"Observed BMI\")\n",
    "ax.plot(pred_df[\"age\"], pred_df[\"bmi_hat\"], linewidth=2, label=\"Fitted line\")\n",
    "\n",
    "ax.set_xlabel(\"Age (years)\")\n",
    "ax.set_ylabel(\"Body mass index (kg/m²)\")\n",
    "ax.set_title(\"Linear regression: BMI ~ age (example subset)\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6b5322",
   "metadata": {},
   "source": [
    "### 2.2 Logistic regression\n",
    "\n",
    "Logistic regression is used when the outcome is **binary**, for example the presence or absence of hypertension.\n",
    "\n",
    "Let \\( Y \\in \\{0, 1\\} \\) with \\( Y = 1 \\) indicating that the event (for example, hypertension) is present. The logistic model specifies the **log odds** of the event as a linear function of predictors:\n",
    "\n",
    "\\[\n",
    "\\log\\left(\\frac{p}{1 - p}\\right) = \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p,\n",
    "\\]\n",
    "\n",
    "where \\( p = P(Y = 1 \\mid X_1, \\ldots, X_p) \\).\n",
    "\n",
    "If we exponentiate a coefficient \\( \\beta_j \\), we obtain an **odds ratio**:\n",
    "\n",
    "\\[\n",
    "\\exp(\\beta_j)\n",
    "\\]\n",
    "\n",
    "which describes the multiplicative change in the odds of the outcome associated with a one-unit increase in \\( X_j \\), holding other predictors constant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebfa256",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Logistic regression example: hypertension on BMI and age.\n",
    "\n",
    "We assume there is a binary outcome variable 'hypertension' coded 0/1.\n",
    "\n",
    "The model:\n",
    "\n",
    "    logit(P(hypertension = 1)) = β0 + β1 * bmi + β2 * age + β3 * sex\n",
    "\n",
    "We fit the model and inspect the estimated odds ratios.\n",
    "\"\"\"\n",
    "\n",
    "# Fit logistic regression using the formula interface.\n",
    "model_log = smf.logit(\"hypertension ~ bmi + age + C(sex)\", data=df)\n",
    "result_log = model_log.fit()\n",
    "\n",
    "# Display the model summary.\n",
    "display(result_log.summary())\n",
    "\n",
    "# Extract odds ratios and 95 % confidence intervals.\n",
    "params = result_log.params\n",
    "conf = result_log.conf_int()\n",
    "or_table = pd.DataFrame({\n",
    "    \"OR\": np.exp(params),\n",
    "    \"CI_lower\": np.exp(conf[0]),\n",
    "    \"CI_upper\": np.exp(conf[1]),\n",
    "})\n",
    "\n",
    "or_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f7c30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot predicted probability of hypertension across BMI.\n",
    "\n",
    "We:\n",
    "\n",
    "- Fix age and sex at reference values.\n",
    "- Vary BMI across a grid.\n",
    "- Compute predicted probabilities from the fitted logistic model.\n",
    "\"\"\"\n",
    "\n",
    "# Choose reference values (adjust if needed).\n",
    "age_ref = 60\n",
    "sex_ref = \"Female\"  # adjust if your coding is different\n",
    "\n",
    "bmi_grid = np.linspace(df[\"bmi\"].quantile(0.05),\n",
    "                       df[\"bmi\"].quantile(0.95),\n",
    "                       100)\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"bmi\": bmi_grid,\n",
    "    \"age\": age_ref,\n",
    "    \"sex\": sex_ref,\n",
    "})\n",
    "\n",
    "pred_df[\"p_hyp\"] = result_log.predict(pred_df)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.plot(pred_df[\"bmi\"], pred_df[\"p_hyp\"], linewidth=2)\n",
    "\n",
    "ax.set_xlabel(\"Body mass index (kg/m²)\")\n",
    "ax.set_ylabel(\"Predicted probability of hypertension\")\n",
    "ax.set_title(\"Logistic regression: predicted probability vs BMI\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4330c0",
   "metadata": {},
   "source": [
    "### 2.3 Cox proportional hazards regression\n",
    "\n",
    "In many epidemiological studies we are interested in **time-to-event** outcomes, such as time to incident cardiovascular disease. Cox proportional hazards regression models the **hazard** (the instantaneous event rate) as:\n",
    "\n",
    "\\[\n",
    "h(t \\mid X_1, \\ldots, X_p) = h_0(t) \\exp(\\beta_1 X_1 + \\cdots + \\beta_p X_p),\n",
    "\\]\n",
    "\n",
    "where:\n",
    "\n",
    "- \\( h_0(t) \\) is the **baseline hazard** (unspecified).\n",
    "- The exponentiated coefficients \\( \\exp(\\beta_j) \\) are **hazard ratios**.\n",
    "\n",
    "A hazard ratio \\( \\exp(\\beta_j) > 1 \\) indicates a higher instantaneous risk of the event associated with higher \\( X_j \\), assuming the **proportional hazards assumption** holds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cox regression example: time to CVD event.\n",
    "\n",
    "We assume the dataset contains:\n",
    "\n",
    "- 'time_cvd': follow-up time (for example, in years).\n",
    "- 'event_cvd': event indicator (1 if event occurred, 0 if censored).\n",
    "- 'age', 'sex', 'bmi' as predictors.\n",
    "\n",
    "We use the `lifelines` package for Cox regression.\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    from lifelines import CoxPHFitter\n",
    "except ImportError as e:\n",
    "    raise ImportError(\n",
    "        \"The 'lifelines' package is required for this section. \" \n",
    "        \"Install it with `pip install lifelines` and re-run the cell.\"\n",
    "    ) from e\n",
    "\n",
    "# Select relevant columns and drop missing values.\n",
    "cols = [\"time_cvd\", \"event_cvd\", \"age\", \"bmi\", \"sex\"]\n",
    "df_cox = df[cols].dropna().copy()\n",
    "\n",
    "# Lifelines expects categorical variables to be encoded appropriately.\n",
    "# Here we create a simple indicator for sex == 'Female' as an example.\n",
    "df_cox[\"sex_female\"] = (df_cox[\"sex\"] == \"Female\").astype(int)\n",
    "\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_cox[[\"time_cvd\", \"event_cvd\", \"age\", \"bmi\", \"sex_female\"]],\n",
    "        duration_col=\"time_cvd\",\n",
    "        event_col=\"event_cvd\")\n",
    "\n",
    "cph.print_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c36f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot example survival curves for two profiles.\n",
    "\n",
    "We:\n",
    "\n",
    "- Define two hypothetical profiles (for example, lower vs higher BMI).\n",
    "- Use the fitted Cox model to estimate survival curves.\n",
    "\"\"\"\n",
    "\n",
    "# Define two example profiles.\n",
    "profile_low = {\n",
    "    \"age\": 60,\n",
    "    \"bmi\": 24,\n",
    "    \"sex_female\": 1,\n",
    "}\n",
    "\n",
    "profile_high = {\n",
    "    \"age\": 60,\n",
    "    \"bmi\": 32,\n",
    "    \"sex_female\": 1,\n",
    "}\n",
    "\n",
    "profiles = pd.DataFrame([profile_low, profile_high])\n",
    "profiles.index = [\"BMI 24\", \"BMI 32\"]\n",
    "\n",
    "surv = cph.predict_survival_function(profiles)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "for label in surv.columns:\n",
    "    ax.plot(surv.index, surv[label], label=label)\n",
    "\n",
    "ax.set_xlabel(\"Follow-up time\")\n",
    "ax.set_ylabel(\"Estimated survival probability\")\n",
    "ax.set_title(\"Cox model: example survival curves\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c8c198",
   "metadata": {},
   "source": [
    "## 3. Quantile regression\n",
    "\n",
    "So far we have focused on models for the **mean** of the outcome (linear regression), the **probability** of a binary outcome (logistic regression), or the **hazard** of an event (Cox regression).\n",
    "\n",
    "For many nutritional and biomedical variables the distribution is **skewed**. In such cases it can be helpful to model not only the mean, but also specific **quantiles** (for example, the median or upper decile).\n",
    "\n",
    "**Quantile regression** estimates conditional quantiles of \\( Y \\) given predictors. For the median (quantile 0.5) we write:\n",
    "\n",
    "\\[\n",
    "Q_{0.5}(Y \\mid X) = \\beta_0(0.5) + \\beta_1(0.5) X.\n",
    "\\]\n",
    "\n",
    "The interpretation of \\( \\beta_1(0.5) \\) is:\n",
    "\n",
    "> The expected difference in the *median* of Y associated with a one-unit difference in X, holding other predictors constant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7100780",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Quantile regression example: BMI on age.\n",
    "\n",
    "We:\n",
    "\n",
    "- Fit an ordinary least squares (OLS) model (mean regression).\n",
    "- Fit a median (q = 0.5) quantile regression model.\n",
    "- Fit an upper-quantile (q = 0.9) model.\n",
    "- Compare the fitted lines.\n",
    "\n",
    "We use `statsmodels` for quantile regression.\n",
    "\"\"\"\n",
    "\n",
    "from statsmodels.regression.quantile_regression import QuantReg\n",
    "\n",
    "# Subset to complete cases for age and bmi.\n",
    "df_qr = df[[\"age\", \"bmi\"]].dropna().copy()\n",
    "\n",
    "# Ordinary least squares for comparison.\n",
    "ols_model = smf.ols(\"bmi ~ age\", data=df_qr).fit()\n",
    "\n",
    "# Quantile regression at median (0.5) and 0.9.\n",
    "qr_model_05 = QuantReg(df_qr[\"bmi\"], sm.add_constant(df_qr[\"age\"]))\n",
    "qr_result_05 = qr_model_05.fit(q=0.5)\n",
    "\n",
    "qr_model_09 = QuantReg(df_qr[\"bmi\"], sm.add_constant(df_qr[\"age\"]))\n",
    "qr_result_09 = qr_model_09.fit(q=0.9)\n",
    "\n",
    "# Create prediction grid.\n",
    "age_grid = np.linspace(df_qr[\"age\"].min(), df_qr[\"age\"].max(), 100)\n",
    "X_grid = sm.add_constant(age_grid)\n",
    "\n",
    "bmi_hat_ols = ols_model.predict(pd.DataFrame({\"age\": age_grid}))\n",
    "bmi_hat_05 = qr_result_05.predict(X_grid)\n",
    "bmi_hat_09 = qr_result_09.predict(X_grid)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.scatter(df_qr[\"age\"], df_qr[\"bmi\"], alpha=0.2, edgecolor=\"none\", label=\"Observed BMI\")\n",
    "ax.plot(age_grid, bmi_hat_ols, linewidth=2, label=\"OLS (mean)\")\n",
    "ax.plot(age_grid, bmi_hat_05, linewidth=2, linestyle=\"--\", label=\"Quantile 0.5 (median)\")\n",
    "ax.plot(age_grid, bmi_hat_09, linewidth=2, linestyle=\":\", label=\"Quantile 0.9\")\n",
    "\n",
    "ax.set_xlabel(\"Age (years)\")\n",
    "ax.set_ylabel(\"Body mass index (kg/m²)\")\n",
    "ax.set_title(\"BMI ~ age: mean and quantile regression\")\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15621372",
   "metadata": {},
   "source": [
    "### 3.1 Strengths and limitations of quantile regression\n",
    "\n",
    "**Strengths:**\n",
    "\n",
    "- Provides a more complete description of the conditional distribution of Y.\n",
    "- Robust to outliers (especially when modelling the median).\n",
    "- Naturally accommodates heteroscedasticity (non-constant variance).\n",
    "\n",
    "**Limitations:**\n",
    "\n",
    "- Interpretation can be less intuitive than mean regression.\n",
    "- Confidence intervals and hypothesis tests are more complex.\n",
    "- More demanding computationally (although not an issue for this workbook).\n",
    "\n",
    "In nutritional epidemiology quantile regression can be particularly useful when:\n",
    "\n",
    "- The upper tail of a distribution is of special interest (for example, high sodium intake).\n",
    "- The outcome distribution is strongly skewed (for example, some biomarkers).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3face152",
   "metadata": {},
   "source": [
    "## 4. Assumptions of regression models\n",
    "\n",
    "All models are simplifications of reality. To interpret results sensibly we need to be aware of their assumptions.\n",
    "\n",
    "Here we briefly review key assumptions for:\n",
    "\n",
    "- Linear regression.\n",
    "- Logistic regression.\n",
    "- Cox proportional hazards regression.\n",
    "\n",
    "Diagnostics and practical illustrations follow in the next section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02930333",
   "metadata": {},
   "source": [
    "### 4.1 Linearity\n",
    "\n",
    "In a standard linear regression model we assume that the relationship between each continuous predictor and the outcome is **linear** (after any transformations we choose).\n",
    "\n",
    "If the true relationship is markedly non-linear, then:\n",
    "\n",
    "- The model may fit poorly.\n",
    "- Estimates of effect may be biased.\n",
    "- Residual plots may show systematic patterns.\n",
    "\n",
    "Later in this workbook we will introduce non-linear models (polynomials and splines) that relax this assumption.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c225a919",
   "metadata": {},
   "source": [
    "### 4.2 Independence\n",
    "\n",
    "We usually assume that the residuals (errors) are **independent** between individuals.\n",
    "\n",
    "Violations of independence can occur when:\n",
    "\n",
    "- The same individual contributes multiple observations (for example, repeated measures).\n",
    "- Observations are clustered (for example, participants from the same household or clinic).\n",
    "\n",
    "More advanced methods, such as mixed models or cluster-robust standard errors, are used in those situations. Here we make the simplifying assumption of independence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c84a6",
   "metadata": {},
   "source": [
    "### 4.3 Homoscedasticity\n",
    "\n",
    "**Homoscedasticity** means that the variance of the residuals is constant across levels of the predictors.\n",
    "\n",
    "If residual variance increases or decreases with fitted values (heteroscedasticity), then:\n",
    "\n",
    "- Estimates of standard errors may be biased.\n",
    "- Confidence intervals and P-values may be unreliable.\n",
    "\n",
    "Residual-versus-fitted plots can be used to detect such patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa269417",
   "metadata": {},
   "source": [
    "### 4.4 Normality of residuals\n",
    "\n",
    "For linear regression, we often assume that the residuals are approximately **normally distributed**.\n",
    "\n",
    "- This assumption is not necessary for obtaining unbiased estimates of the mean.\n",
    "- It matters mainly for **inference** (confidence intervals and tests) in small samples.\n",
    "\n",
    "Normality can be explored with **Q–Q plots**, which compare the distribution of residuals with a theoretical normal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f594460",
   "metadata": {},
   "source": [
    "### 4.5 Multicollinearity\n",
    "\n",
    "**Multicollinearity** arises when predictors are strongly correlated with one another.\n",
    "\n",
    "Consequences:\n",
    "\n",
    "- Coefficients may be unstable.\n",
    "- Standard errors become large.\n",
    "- It can be difficult to disentangle separate effects.\n",
    "\n",
    "The **variance inflation factor (VIF)** is a commonly used diagnostic: large VIF values indicate problematic collinearity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d216e4a3",
   "metadata": {},
   "source": [
    "### 4.6 Separation in logistic regression\n",
    "\n",
    "In logistic regression, **separation** occurs when a predictor (or combination of predictors) perfectly predicts the outcome (for example, all smokers have disease, all non-smokers are healthy).\n",
    "\n",
    "Consequences:\n",
    "\n",
    "- Maximum likelihood estimates may not exist or may be extremely large.\n",
    "- Standard logistic regression fails.\n",
    "\n",
    "In practice one may:\n",
    "\n",
    "- Collapse categories.\n",
    "- Use penalised logistic regression.\n",
    "- Rethink the model structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff44e6",
   "metadata": {},
   "source": [
    "### 4.7 Proportional hazards in Cox regression\n",
    "\n",
    "The Cox model assumes that hazard ratios are **constant over time** (proportional hazards). In other words:\n",
    "\n",
    "\\[\n",
    "\\frac{h(t \\mid X = 1)}{h(t \\mid X = 0)} = \\text{constant in } t.\n",
    "\\]\n",
    "\n",
    "Violations of this assumption can be detected using:\n",
    "\n",
    "- Plots of log(-log(survival)) curves.\n",
    "- Schoenfeld residuals and associated tests.\n",
    "\n",
    "If proportional hazards does not hold, options include:\n",
    "\n",
    "- Stratified Cox models.\n",
    "- Time-varying coefficients.\n",
    "- Alternative modelling approaches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706e120",
   "metadata": {},
   "source": [
    "## 5. Model diagnostics\n",
    "\n",
    "We now illustrate a few standard diagnostic tools for regression models.\n",
    "\n",
    "The aim is not to be exhaustive, but to provide a first hands-on experience with:\n",
    "\n",
    "- Residual plots.\n",
    "- Q–Q plots.\n",
    "- Influence diagnostics.\n",
    "- Goodness-of-fit metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe2798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Diagnostics for linear regression: residual plots and Q–Q plot.\n",
    "\n",
    "We use the previously fitted linear model 'result_lin'.\n",
    "\"\"\"\n",
    "\n",
    "# Compute residuals and fitted values.\n",
    "resid = result_lin.resid\n",
    "fitted = result_lin.fittedvalues\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Residuals vs fitted values.\n",
    "axes[0].scatter(fitted, resid, alpha=0.3, edgecolor=\"none\")\n",
    "axes[0].axhline(0, color=\"black\", linewidth=1)\n",
    "axes[0].set_xlabel(\"Fitted values\")\n",
    "axes[0].set_ylabel(\"Residuals\")\n",
    "axes[0].set_title(\"Residuals vs fitted\")\n",
    "\n",
    "# Q–Q plot for residuals.\n",
    "sm.ProbPlot(resid).qqplot(line=\"45\", ax=axes[1])\n",
    "axes[1].set_title(\"Q–Q plot of residuals\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a585427",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Variance Inflation Factors (VIF) for linear regression predictors.\n",
    "\n",
    "We:\n",
    "\n",
    "- Construct the design matrix for the linear model.\n",
    "- Compute VIF for each predictor.\n",
    "\n",
    "High VIF values (for example, > 5 or > 10) may indicate problematic collinearity.\n",
    "\"\"\"\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Build design matrix for the linear model.\n",
    "X = result_lin.model.exog\n",
    "vif_values = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "vif_table = pd.DataFrame({\n",
    "    \"variable\": result_lin.model.exog_names,\n",
    "    \"VIF\": vif_values,\n",
    "})\n",
    "\n",
    "vif_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b06a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Receiver operating characteristic (ROC) curve for logistic regression.\n",
    "\n",
    "We:\n",
    "\n",
    "- Compute predicted probabilities of hypertension.\n",
    "- Calculate true positive and false positive rates.\n",
    "- Plot the ROC curve and compute the area under the curve (AUC).\n",
    "\n",
    "This provides a measure of overall discrimination.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Ensure no missing values for the logistic model variables.\n",
    "df_log = df[[\"hypertension\", \"bmi\", \"age\", \"sex\"]].dropna().copy()\n",
    "result_log = smf.logit(\"hypertension ~ bmi + age + C(sex)\", data=df_log).fit(disp=False)\n",
    "\n",
    "y_true = df_log[\"hypertension\"]\n",
    "y_score = result_log.predict(df_log)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "auc = roc_auc_score(y_true, y_score)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.plot(fpr, tpr, linewidth=2, label=f\"ROC curve (AUC = {auc:.3f})\")\n",
    "ax.plot([0, 1], [0, 1], linestyle=\"--\", color=\"grey\", label=\"No discrimination\")\n",
    "\n",
    "ax.set_xlabel(\"False positive rate\")\n",
    "ax.set_ylabel(\"True positive rate\")\n",
    "ax.set_title(\"ROC curve for logistic regression\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e40da8",
   "metadata": {},
   "source": [
    "## 6. Non-linear models\n",
    "\n",
    "The term \"linear regression\" refers to linearity in the **parameters** (β), not necessarily in the predictors themselves.\n",
    "\n",
    "Many epidemiological relationships are **non-linear**. For example:\n",
    "\n",
    "- Body mass index and mortality risk.\n",
    "- Age and blood pressure.\n",
    "- Sodium intake and blood pressure.\n",
    "\n",
    "To capture such patterns we can:\n",
    "\n",
    "- Add **polynomial terms** (for example, age²).\n",
    "- Use **splines**, which fit smooth curves made of polynomial segments.\n",
    "\n",
    "In this section we briefly introduce both approaches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7416718",
   "metadata": {},
   "source": [
    "### 6.1 Polynomial regression\n",
    "\n",
    "A simple extension of linear regression is to add powers of a predictor, for example:\n",
    "\n",
    "\\[\n",
    "Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\varepsilon.\n",
    "\\]\n",
    "\n",
    "This is still a linear model in the parameters \\( \\beta_0, \\beta_1, \\beta_2 \\), but represents a **curved** relationship between X and Y.\n",
    "\n",
    "Caution is required:\n",
    "\n",
    "- High-order polynomials can behave very erratically at the boundaries of the data.\n",
    "- Interpretation of individual coefficients is difficult; the focus should be on the **overall shape** of the fitted curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Polynomial regression example: BMI on age and age².\n",
    "\n",
    "We:\n",
    "\n",
    "- Create a squared age term.\n",
    "- Fit a model with age and age².\n",
    "- Plot the fitted curve and compare with the simple linear model.\n",
    "\"\"\"\n",
    "\n",
    "df_poly = df[[\"age\", \"bmi\"]].dropna().copy()\n",
    "df_poly[\"age2\"] = df_poly[\"age\"] ** 2\n",
    "\n",
    "model_poly = smf.ols(\"bmi ~ age + age2\", data=df_poly).fit()\n",
    "\n",
    "age_grid = np.linspace(df_poly[\"age\"].min(), df_poly[\"age\"].max(), 100)\n",
    "pred_poly = model_poly.predict(pd.DataFrame({\n",
    "    \"age\": age_grid,\n",
    "    \"age2\": age_grid ** 2,\n",
    "}))\n",
    "\n",
    "pred_lin = ols_model.predict(pd.DataFrame({\"age\": age_grid}))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.scatter(df_poly[\"age\"], df_poly[\"bmi\"], alpha=0.2, edgecolor=\"none\", label=\"Observed BMI\")\n",
    "ax.plot(age_grid, pred_lin, linewidth=2, label=\"Linear model\")\n",
    "ax.plot(age_grid, pred_poly, linewidth=2, linestyle=\"--\", label=\"Polynomial (age + age²)\")\n",
    "\n",
    "ax.set_xlabel(\"Age (years)\")\n",
    "ax.set_ylabel(\"Body mass index (kg/m²)\")\n",
    "ax.set_title(\"Polynomial regression: BMI ~ age + age²\")\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293c9622",
   "metadata": {},
   "source": [
    "### 6.2 Splines\n",
    "\n",
    "**Splines** provide a more flexible and stable approach to modelling non-linear relationships.\n",
    "\n",
    "Idea:\n",
    "\n",
    "- The range of X is divided into intervals by \"knots\".\n",
    "- Within each interval we fit low-degree polynomials.\n",
    "- The pieces are joined smoothly at the knots.\n",
    "\n",
    "A widely used choice in epidemiology is the **restricted cubic spline**, which behaves linearly beyond the outer knots and smoothly between knots.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "- Flexible yet stable.\n",
    "- Interpretation focuses on the **shape** of the curve.\n",
    "- Works well in large cohorts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad31d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Restricted cubic spline example: BMI on age.\n",
    "\n",
    "We:\n",
    "\n",
    "- Construct spline basis functions for age.\n",
    "- Fit a linear model using the spline terms.\n",
    "- Plot the fitted spline curve.\n",
    "\n",
    "We use `patsy` to generate the spline basis.\n",
    "\"\"\"\n",
    "\n",
    "from patsy import dmatrix\n",
    "\n",
    "# Use a subset with complete data.\n",
    "df_spline = df[[\"age\", \"bmi\"]].dropna().copy()\n",
    "\n",
    "# Construct a spline basis for age with 4 degrees of freedom.\n",
    "# The function 'cr' creates a cubic regression spline.\n",
    "spline_basis = dmatrix(\"cr(age, df=4)\", data=df_spline, return_type=\"dataframe\")\n",
    "spline_cols = spline_basis.columns\n",
    "\n",
    "# Fit OLS with spline terms.\n",
    "df_spline_model = pd.concat([df_spline[\"bmi\"], spline_basis], axis=1)\n",
    "formula_spline = \"bmi ~ \" + \" + \".join(spline_cols)\n",
    "model_spline = smf.ols(formula_spline, data=df_spline_model).fit()\n",
    "\n",
    "# Prediction grid.\n",
    "age_grid = np.linspace(df_spline[\"age\"].min(), df_spline[\"age\"].max(), 100)\n",
    "spline_grid = dmatrix(\"cr(age, df=4)\",\n",
    "                      data={\"age\": age_grid},\n",
    "                      return_type=\"dataframe\")\n",
    "\n",
    "pred_spline = model_spline.predict(spline_grid)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.scatter(df_spline[\"age\"], df_spline[\"bmi\"], alpha=0.2, edgecolor=\"none\", label=\"Observed BMI\")\n",
    "ax.plot(age_grid, pred_spline, linewidth=2, label=\"Spline fit (df = 4)\")\n",
    "\n",
    "ax.set_xlabel(\"Age (years)\")\n",
    "ax.set_ylabel(\"Body mass index (kg/m²)\")\n",
    "ax.set_title(\"Restricted cubic spline: BMI ~ age\")\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d782e2b",
   "metadata": {},
   "source": [
    "### 6.3 Comparing models\n",
    "\n",
    "To decide whether a non-linear term is useful we can compare models using:\n",
    "\n",
    "- Visual inspection of fitted curves.\n",
    "- Goodness-of-fit measures such as the Akaike information criterion (AIC).\n",
    "- Likelihood ratio tests (for nested models).\n",
    "\n",
    "For example, we can compare:\n",
    "\n",
    "- A simple linear model (BMI ~ age).\n",
    "- A polynomial model (BMI ~ age + age²).\n",
    "- A spline model (BMI ~ spline(age)).\n",
    "\n",
    "Lower AIC values indicate better trade-off between fit and complexity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01ac8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compare linear, polynomial, and spline models using AIC.\n",
    "\n",
    "This is a simple numeric comparison; interpretation still relies on graphs and subject-matter knowledge.\n",
    "\"\"\"\n",
    "\n",
    "aic_results = pd.DataFrame({\n",
    "    \"model\": [\"Linear\", \"Polynomial (age + age²)\", \"Spline (df = 4)\"],\n",
    "    \"AIC\": [ols_model.aic, model_poly.aic, model_spline.aic],\n",
    "})\n",
    "\n",
    "aic_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc1579",
   "metadata": {},
   "source": [
    "## 7. Interpreting effect estimates\n",
    "\n",
    "Different regression models produce different types of effect estimates. It is important to be clear about their meaning.\n",
    "\n",
    "- **β (beta) coefficients** in linear regression: expected difference in the mean outcome per unit change in the predictor.\n",
    "- **Odds ratios (OR)** in logistic regression: multiplicative change in the odds of the outcome.\n",
    "- **Risk ratios (RR)**: multiplicative change in risk (probability); not directly estimated in standard logistic models.\n",
    "- **Hazard ratios (HR)** in Cox regression: multiplicative change in the instantaneous hazard.\n",
    "\n",
    "In non-linear models (polynomials, splines, quantile regression) the interpretation usually focuses on the **shape of the curve** rather than individual coefficients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extract and summarise effect estimates from the fitted models.\n",
    "\n",
    "We:\n",
    "\n",
    "- Summarise β estimates from the linear model.\n",
    "- Present odds ratios from the logistic model.\n",
    "- Present hazard ratios from the Cox model.\n",
    "\n",
    "This illustrates how different models report different effect measures.\n",
    "\"\"\"\n",
    "\n",
    "# Linear regression coefficients (bmi ~ age + C(sex)).\n",
    "beta_lin = result_lin.params.to_frame(name=\"estimate\")\n",
    "beta_lin[\"model\"] = \"Linear (BMI)\"\n",
    "\n",
    "# Logistic regression odds ratios (hypertension ~ bmi + age + C(sex)).\n",
    "params_log = result_log.params\n",
    "conf_log = result_log.conf_int()\n",
    "or_table = pd.DataFrame({\n",
    "    \"estimate\": np.exp(params_log),\n",
    "    \"CI_lower\": np.exp(conf_log[0]),\n",
    "    \"CI_upper\": np.exp(conf_log[1]),\n",
    "})\n",
    "or_table[\"model\"] = \"Logistic (hypertension)\"\n",
    "\n",
    "# Cox model hazard ratios.\n",
    "cox_summary = cph.summary[[\"coef\", \"exp(coef)\", \"exp(coef) lower 95%\", \"exp(coef) upper 95%\"]].copy()\n",
    "cox_summary.rename(columns={\n",
    "    \"coef\": \"coef\",\n",
    "    \"exp(coef)\": \"HR\",\n",
    "    \"exp(coef) lower 95%\": \"CI_lower\",\n",
    "    \"exp(coef) upper 95%\": \"CI_upper\",\n",
    "}, inplace=True)\n",
    "cox_summary[\"model\"] = \"Cox (time to CVD)\"\n",
    "\n",
    "display(beta_lin)\n",
    "display(or_table)\n",
    "display(cox_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25703405",
   "metadata": {},
   "source": [
    "## 8. Estimation and inference (brief overview)\n",
    "\n",
    "Most regression models in this workbook are estimated using **maximum likelihood** (or, in the case of ordinary least squares, a closely related approach).\n",
    "\n",
    "The key ideas are:\n",
    "\n",
    "- Parameters are estimated by finding values that make the observed data \"most likely\" under the assumed model.\n",
    "- Standard errors quantify the typical variation of estimates across hypothetical repeated samples.\n",
    "- **Wald tests** and **likelihood ratio tests** are used to assess whether coefficients differ from zero.\n",
    "- **Confidence intervals** indicate a range of parameter values that are compatible with the observed data and the model assumptions.\n",
    "\n",
    "A full treatment of the underlying theory is beyond the scope of FB2NEP, but it is important to know that:\n",
    "\n",
    "- Estimates are subject to sampling variability.\n",
    "- P-values and confidence intervals rely on model assumptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b0aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Manual computation of a confidence interval for a linear regression coefficient.\n",
    "\n",
    "We illustrate the basic idea using the coefficient for 'age' in the linear model.\n",
    "\n",
    "The 95 % confidence interval is:\n",
    "\n",
    "    estimate ± 1.96 * standard_error\n",
    "\n",
    "under a normal approximation.\n",
    "\"\"\"\n",
    "\n",
    "# Extract estimate and standard error for 'age'.\n",
    "age_est = result_lin.params[\"age\"]\n",
    "age_se = result_lin.bse[\"age\"]\n",
    "\n",
    "ci_lower = age_est - 1.96 * age_se\n",
    "ci_upper = age_est + 1.96 * age_se\n",
    "\n",
    "print(\"Coefficient for age (linear model):\", f\"{age_est:.3f}\")\n",
    "print(\"Standard error:\", f\"{age_se:.3f}\")\n",
    "print(\"Approximate 95 % CI:\", f\"[{ci_lower:.3f}, {ci_upper:.3f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ac3741",
   "metadata": {},
   "source": [
    "## 9. Predictions from fitted models\n",
    "\n",
    "One of the most practical uses of regression models is to obtain **predicted values** for specified combinations of predictors.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Predicted mean BMI at age 65 years in women.\n",
    "- Predicted probability of hypertension at age 65 years for different BMI values.\n",
    "- Predicted survival curves for different risk profiles.\n",
    "\n",
    "In all cases it is important to remember:\n",
    "\n",
    "- Predictions depend on the **assumed model** and its **fitted parameters**.\n",
    "- Uncertainty in predictions can be quantified (for example, by confidence intervals or prediction intervals).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prediction from a linear model: BMI at age 65.\n",
    "\n",
    "We:\n",
    "\n",
    "- Create a small DataFrame with the desired predictor values.\n",
    "- Use the `predict` method of the fitted model.\n",
    "\n",
    "For simplicity we focus on a single sex.\n",
    "\"\"\"\n",
    "\n",
    "# Example: predict BMI at age 65 for women.\n",
    "new_data = pd.DataFrame({\n",
    "    \"age\": [65],\n",
    "    \"sex\": [\"Female\"],\n",
    "})\n",
    "\n",
    "pred_bmi = result_lin.predict(new_data)\n",
    "\n",
    "print(\"Predicted mean BMI at age 65 (Female):\", float(pred_bmi.iloc[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prediction from a logistic model: probability of hypertension.\n",
    "\n",
    "We:\n",
    "\n",
    "- Create a grid of BMI values at a fixed age and sex.\n",
    "- Compute predicted probabilities using the logistic model.\n",
    "\"\"\"\n",
    "\n",
    "bmi_grid = np.linspace(df[\"bmi\"].quantile(0.05),\n",
    "                       df[\"bmi\"].quantile(0.95),\n",
    "                       100)\n",
    "\n",
    "new_data = pd.DataFrame({\n",
    "    \"bmi\": bmi_grid,\n",
    "    \"age\": age_ref,\n",
    "    \"sex\": sex_ref,\n",
    "})\n",
    "\n",
    "new_data[\"p_hyp\"] = result_log.predict(new_data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.plot(new_data[\"bmi\"], new_data[\"p_hyp\"], linewidth=2)\n",
    "\n",
    "ax.set_xlabel(\"Body mass index (kg/m²)\")\n",
    "ax.set_ylabel(\"Predicted probability of hypertension\")\n",
    "ax.set_title(\"Predicted probability vs BMI (age = 60, sex = Female)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a816305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prediction from a spline model.\n",
    "\n",
    "We:\n",
    "\n",
    "- Use the spline model fitted earlier (BMI ~ spline(age)).\n",
    "- Compute predicted BMI over an age grid.\n",
    "- Plot the curve, which captures non-linearity.\n",
    "\"\"\"\n",
    "\n",
    "age_grid = np.linspace(df_spline[\"age\"].min(), df_spline[\"age\"].max(), 100)\n",
    "spline_grid = dmatrix(\"cr(age, df=4)\",\n",
    "                      data={\"age\": age_grid},\n",
    "                      return_type=\"dataframe\")\n",
    "\n",
    "pred_spline = model_spline.predict(spline_grid)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "ax.plot(age_grid, pred_spline, linewidth=2)\n",
    "ax.set_xlabel(\"Age (years)\")\n",
    "ax.set_ylabel(\"Predicted BMI (kg/m²)\")\n",
    "ax.set_title(\"Predicted BMI vs age (spline model)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb06e645",
   "metadata": {},
   "source": [
    "## 10. Summary and further reading\n",
    "\n",
    "In this workbook you have:\n",
    "\n",
    "- Reviewed the basic idea of regression as modelling conditional expectations.\n",
    "- Fitted and interpreted linear, logistic, and Cox proportional hazards models.\n",
    "- Seen how quantile regression extends the idea to conditional quantiles.\n",
    "- Examined key model assumptions and basic diagnostics.\n",
    "- Introduced non-linear models using polynomial terms and splines.\n",
    "- Obtained predictions from fitted models.\n",
    "\n",
    "These tools are building blocks for more advanced topics in nutritional epidemiology:\n",
    "\n",
    "- Confounding and adjustment.\n",
    "- Causal diagrams (DAGs).\n",
    "- Mediation analysis.\n",
    "- Missing data and more complex model structures.\n",
    "\n",
    "These topics are developed further in **Workbook 7**.\n",
    "\n",
    "**Suggested further reading:**\n",
    "\n",
    "- Kleinbaum, D. G., and Klein, M. *Logistic Regression: A Self-Learning Text.*\n",
    "- Harrell, F. E. *Regression Modelling Strategies.*\n",
    "- Rothman, K. J., Greenland, S., and Lash, T. L. *Modern Epidemiology.*\n",
    "- Koenker, R. *Quantile Regression.*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
