{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 · Description of the population — Table 1 & missing data\n",
    "\n",
    "> **Purpose**: produce a defensible baseline description of the cohort, and explore missingness.\n",
    "\n",
    "> **Learning objectives**\n",
    "- Create a “Table 1” summary of baseline characteristics by outcome.\n",
    "- Handle numeric vs categorical variables appropriately.\n",
    "- Explore missing data (MCAR/MAR/MNAR patterns) visually and descriptively.\n",
    "- Recognise the limits of simple imputation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap: ensure repo root on path, then import init\n",
    "import sys, pathlib\n",
    "sys.path.append(str(pathlib.Path.cwd().parent))\n",
    "from scripts.bootstrap import init\n",
    "df, ctx = init()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Baseline description\n",
    "A classic “Table 1” shows demographics, lifestyle, and clinical measures overall and by outcome group.\n",
    "\n",
    "Here we’ll look at **CVD_incident** as the stratifier; the same pipeline works for cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "\n",
    "def table1(data, groupvar, cont, cat):\n",
    "    out = []\n",
    "    for v in cont:\n",
    "        desc = data.groupby(groupvar)[v].agg(['mean','std','median']).round(2)\n",
    "        out.append(desc)\n",
    "    for v in cat:\n",
    "        desc = data.groupby([groupvar,v]).size().unstack(fill_value=0)\n",
    "        desc = (desc.T / desc.T.sum()).T.round(3)\n",
    "        out.append(desc)\n",
    "    return out\n",
    "\n",
    "cont_vars = ['age','BMI','SBP','energy_kcal','fruit_veg_g_d','red_meat_g_d','salt_g_d']\n",
    "cat_vars = ['sex','smoking_status','physical_activity','SES_class','IMD_quintile','menopausal_status']\n",
    "\n",
    "tbls = table1(df, 'CVD_incident', cont_vars, cat_vars)\n",
    "tbls[0].head()  # just show first piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e97b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_table1(\n",
    "    df: pd.DataFrame,\n",
    "    group: str | None = None,\n",
    "    continuous: list[str] = None,\n",
    "    categorical: list[str] = None,\n",
    "    digits: int = 2,\n",
    "    include_overall: bool = True,\n",
    "    dropna_group: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a single tidy 'Table 1' DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Source data.\n",
    "    group : str | None\n",
    "        Optional stratifier (e.g., 'CVD_incident'). If None, only overall is returned.\n",
    "    continuous : list[str]\n",
    "        Names of continuous variables to summarise.\n",
    "    categorical : list[str]\n",
    "        Names of categorical variables to summarise.\n",
    "    digits : int\n",
    "        Rounding for numeric statistics.\n",
    "    include_overall : bool\n",
    "        Include an 'Overall' column alongside group columns.\n",
    "    dropna_group : bool\n",
    "        Drop rows with missing group when grouping.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with MultiIndex rows:\n",
    "      (variable, stat_or_level)  × columns = group(s) (plus Overall if requested).\n",
    "    \"\"\"\n",
    "\n",
    "    continuous = continuous or []\n",
    "    categorical = categorical or []\n",
    "    data = df.copy()\n",
    "\n",
    "    # Ensure categoricals are categorical dtype for stable level order\n",
    "    for c in categorical:\n",
    "        if c in data.columns and data[c].dtype.name not in (\"category\",):\n",
    "            data[c] = data[c].astype(\"category\")\n",
    "\n",
    "    # Helper: numeric summary\n",
    "    def cont_summary(d: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "        if not cols:\n",
    "            return pd.DataFrame()\n",
    "        s = d[cols].agg([\"mean\", \"std\", \"median\", \"count\"]).T\n",
    "        s = s.rename(columns={\"std\": \"sd\", \"count\": \"n\"})\n",
    "        return s\n",
    "\n",
    "    # Helper: categorical counts/percents\n",
    "    def cat_summary(d: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "        pieces = []\n",
    "        for c in cols:\n",
    "            ct = d[c].value_counts(dropna=False)\n",
    "            n = ct.astype(int)\n",
    "            p = (n / n.sum()).astype(float)\n",
    "            tmp = pd.DataFrame({\"n\": n, \"%\": p})\n",
    "            tmp.index.name = \"level\"\n",
    "            tmp[\"variable\"] = c\n",
    "            pieces.append(tmp.reset_index())\n",
    "        if pieces:\n",
    "            out = pd.concat(pieces, axis=0, ignore_index=True)\n",
    "            # MultiIndex rows: (variable, level) with columns n, %\n",
    "            out = out.set_index([\"variable\", \"level\"]).sort_index()\n",
    "        else:\n",
    "            out = pd.DataFrame()\n",
    "        return out\n",
    "\n",
    "    # Build overall\n",
    "    cols = []\n",
    "    if include_overall:\n",
    "        cont_overall = cont_summary(data, continuous).round(digits)\n",
    "        cat_overall = cat_summary(data, categorical)\n",
    "        # unify into same row space using MultiIndex\n",
    "        cont_overall.index = pd.MultiIndex.from_product([cont_overall.index, [\"mean\",\"sd\",\"median\",\"n\"]])\n",
    "        cont_overall = cont_overall.stack().unstack(-1)  # to have a single column we’ll rename\n",
    "        cont_overall.columns = [\"Overall\"]  # single stat stacked per row\n",
    "        # For continuous we want separate rows for each stat:\n",
    "        # (variable, stat) -> value in \"Overall\"\n",
    "        cont_overall = cont_overall[\"Overall\"].unstack(level=1).round(digits)\n",
    "\n",
    "        if not cat_overall.empty:\n",
    "            cat_overall = cat_overall.copy()\n",
    "            cat_overall[\"Overall_n\"] = cat_overall[\"n\"].astype(\"Int64\")\n",
    "            cat_overall[\"Overall_%\"] = (100 * cat_overall[\"%\"]).round(1)\n",
    "            cat_overall = cat_overall.drop(columns=[\"n\", \"%\"])\n",
    "\n",
    "    # Build by group\n",
    "    group_cols = []\n",
    "    if group and group in data:\n",
    "        if dropna_group:\n",
    "            gdata = data.dropna(subset=[group])\n",
    "        else:\n",
    "            gdata = data.copy()\n",
    "        grouped = gdata.groupby(group, observed=True)\n",
    "\n",
    "        # Continuous by group\n",
    "        cont_by = []\n",
    "        if continuous:\n",
    "            for g, d in grouped:\n",
    "                s = cont_summary(d, continuous)\n",
    "                s.index = pd.MultiIndex.from_product([s.index, [\"mean\",\"sd\",\"median\",\"n\"]])\n",
    "                s = s.stack().unstack(-1)\n",
    "                s.columns = [str(g)]\n",
    "                s = s[str(g)].unstack(level=1).round(digits)\n",
    "                cont_by.append(s)\n",
    "            cont_by = pd.concat(cont_by, axis=1) if cont_by else pd.DataFrame()\n",
    "\n",
    "        # Categorical by group\n",
    "        cat_by = []\n",
    "        if categorical:\n",
    "            for g, d in grouped:\n",
    "                cs = cat_summary(d, categorical)\n",
    "                if cs.empty:\n",
    "                    continue\n",
    "                cs = cs.copy()\n",
    "                cs[f\"{g}_n\"] = cs[\"n\"].astype(\"Int64\")\n",
    "                cs[f\"{g}_%\"] = (100 * cs[\"%\"]).round(1)\n",
    "                cs = cs.drop(columns=[\"n\", \"%\"])\n",
    "                cat_by.append(cs)\n",
    "            cat_by = pd.concat(cat_by, axis=1) if cat_by else pd.DataFrame()\n",
    "\n",
    "    # Combine continuous overall + by-group\n",
    "    blocks = []\n",
    "    if include_overall:\n",
    "        blocks.append(cont_overall)\n",
    "    if group and continuous:\n",
    "        blocks.append(cont_by)\n",
    "    cont_block = pd.concat(blocks, axis=1) if blocks else pd.DataFrame()\n",
    "    if not cont_block.empty:\n",
    "        cont_block.index.names = [\"variable\", \"stat\"]\n",
    "\n",
    "    # Combine categorical overall + by-group\n",
    "    if include_overall:\n",
    "        cat_all = cat_overall if group is None else pd.concat([cat_overall, cat_by], axis=1)\n",
    "    else:\n",
    "        cat_all = cat_by if group else pd.DataFrame()\n",
    "\n",
    "    # Stack results with a blank row between continuous and categorical (nicer display)\n",
    "    if cont_block.empty and (cat_all is None or cat_all.empty):\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    parts = []\n",
    "    if not cont_block.empty:\n",
    "        parts.append(cont_block)\n",
    "    if cat_all is not None and not cat_all.empty:\n",
    "        # align column order: Overall, then groups interleaving n/% for categoricals\n",
    "        # leave as-is; it’s readable\n",
    "        parts.append(cat_all)\n",
    "\n",
    "    out = pd.concat(parts, axis=0)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ---- Use it on this cohort ----\n",
    "continuous = ['age','BMI','SBP','energy_kcal','fruit_veg_g_d','red_meat_g_d','salt_g_d']\n",
    "categorical = ['sex','smoking_status','physical_activity','SES_class','IMD_quintile','menopausal_status']\n",
    "\n",
    "t1 = make_table1(\n",
    "    df,\n",
    "    group=\"CVD_incident\",\n",
    "    continuous=continuous,\n",
    "    categorical=categorical,\n",
    "    digits=2,\n",
    "    include_overall=True\n",
    ")\n",
    "\n",
    "t1.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "- Which variables differ most clearly between incident vs non-incident CVD?\n",
    "- How would you decide which variables to adjust for in regression later?\n",
    "- What are the limits of “Table 1 p-values”?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Missing data overview\n",
    "Missingness can be:\n",
    "- **MCAR** (completely at random).\n",
    "- **MAR** (depends on observed variables, e.g. age, SES).\n",
    "- **MNAR** (depends on unobserved values — hard to detect).\n",
    "\n",
    "Synthetic data were generated with ~2–3% MCAR, 5–8% MAR, tiny MNAR. Let’s explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall % missing per variable\n",
    "missing = df.isnull().mean().sort_values(ascending=False).round(3)\n",
    "missing.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of missingness (simple)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(df[missing.index[:20]].isnull(), aspect='auto', interpolation='none', cmap='gray_r')\n",
    "plt.xlabel('Variables (top 20 by missingness)')\n",
    "plt.ylabel('Individuals')\n",
    "plt.title('Missingness pattern (white=missing)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple associations with missingness\n",
    "Check whether missingness correlates with observed variables — a clue for MAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: missing vitamin C vs SES\n",
    "miss_vitC = df['plasma_vitC_umol_L'].isnull().astype(int)\n",
    "pd.crosstab(df['SES_class'], miss_vitC, normalize='index').round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handling missing data (teaching only)\n",
    "- **Complete case analysis**: drop missing rows.\n",
    "- **Simple imputation**: mean/median — acceptable for teaching but not best practice.\n",
    "- **Better**: multiple imputation (beyond this course).\n",
    "\n",
    "⚠️ We use only crude strategies here to highlight the issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc = df.dropna(subset=['plasma_vitC_umol_L','urinary_sodium_mmol_L'])\n",
    "print(\"Original n=\",len(df),\"; complete-case n=\",len(df_cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple median imputation example for BMI\n",
    "bmi_imp = df['BMI'].fillna(df['BMI'].median())\n",
    "print(\"BMI: before missing=\",df['BMI'].isnull().sum(),\"; after=\",bmi_imp.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Key takeaways\n",
    ">\n",
    "> - A reproducible “Table 1” builds the foundation for all later analyses.\n",
    "> - Always check **missingness patterns**; assume MCAR is rare.\n",
    "> - Simple imputations are for teaching — in practice, use multiple imputation.\n",
    "> - Missingness itself may hold **epidemiological meaning** (e.g. low SES → more missing biomarker data).\n",
    "\n",
    "> **Next:** analyse exposures — distributions and how biomarkers track with intake."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
