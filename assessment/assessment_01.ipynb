{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment 1 — Nutritional Epidemiology (Template)\n",
    "\n",
    "**Task**: Analyse the provided dataset to inform a public-health recommendation.\n",
    "\n",
    "**Deliverables**\n",
    "- A clear diagram (DAG/workflow) showing reasoning and adjustment set.\n",
    "- ~500 words: succinct methods, key results, interpretation, limitations.\n",
    "- Minimum analyses: defensible Table 1; one primary logistic regression on chosen outcome (unadjusted + adjusted); justification of adjustment set.\n",
    "\n",
    "> Tip: run all cells top-to-bottom. Use British English. Keep your code and prose clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Setup (works in Colab or locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust bootstrap loader (no assumptions about CWD)\n",
    "import pathlib, runpy, sys, os\n",
    "candidates = [\n",
    "    pathlib.Path(\"notebooks/_bootstrap.py\"),\n",
    "    pathlib.Path(\"_bootstrap.py\"),\n",
    "    pathlib.Path(\"../notebooks/_bootstrap.py\")\n",
    "]\n",
    "for p in candidates:\n",
    "    if p.exists():\n",
    "        print(f\"Bootstrapping via: {p}\")\n",
    "        runpy.run_path(str(p))\n",
    "        break\n",
    "else:\n",
    "    # minimal fallback: try to load dataset directly\n",
    "    import pandas as pd\n",
    "    CSV_REL = \"data/synthetic/fb2nep.csv\"\n",
    "    assert os.path.exists(CSV_REL), \"Dataset missing and _bootstrap.py not found.\"\n",
    "    df = pd.read_csv(CSV_REL)\n",
    "    IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "print(df.shape, \"— dataset ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Choose your analysis\n",
    "Pick one **primary outcome** and one **primary exposure**. Suggested: `Cancer_incident` (outcome) and `red_meat_g_d` (exposure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>> EDIT THESE <<<<\n",
    "OUTCOME = \"Cancer_incident\"   # or \"CVD_incident\"\n",
    "EXPOSURE = \"red_meat_g_d\"     # e.g. fruit_veg_g_d, salt_g_d, alcohol_units_wk, BMI\n",
    "\n",
    "# Proposed adjustment set (edit as justified by your DAG)\n",
    "ADJUST_VARS = [\n",
    "    \"age\", \"BMI\", \"IMD_quintile\", \"SES_class\", \"sex\", \"smoking_status\"\n",
    "]\n",
    "\n",
    "assert OUTCOME in df.columns and EXPOSURE in df.columns\n",
    "for v in ADJUST_VARS:\n",
    "    assert v in df.columns, f\"Missing covariate: {v}\"\n",
    "print(\"Outcome:\", OUTCOME, \"Exposure:\", EXPOSURE)\n",
    "print(\"Adjustment:\", ADJUST_VARS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Table 1 (baseline characteristics)\n",
    "Simple, defensible table — impute *only* for table display (do not use imputed data for models). Provide means/SDs or medians/IQR; counts/percentages for categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [c for c in df.select_dtypes(include=[\"float64\",\"int64\"]).columns if c not in [\"id\"]]\n",
    "cat_cols = [c for c in df.columns if df[c].dtype==\"object\" or str(df[c].dtype).startswith(\"category\")]\n",
    "cat_cols = [c for c in cat_cols if c not in [\"CVD_date\",\"Cancer_date\",\"baseline_date\"]]\n",
    "\n",
    "df_imp = df.copy()\n",
    "for c in num_cols:\n",
    "    df_imp[c] = df_imp[c].fillna(df_imp[c].median())\n",
    "for c in cat_cols:\n",
    "    mode = df_imp[c].mode(dropna=True)\n",
    "    if len(mode):\n",
    "        df_imp[c] = df_imp[c].fillna(mode.iloc[0])\n",
    "\n",
    "by = OUTCOME\n",
    "cont = [\"age\",\"BMI\",\"SBP\",\"energy_kcal\",\"fruit_veg_g_d\",\"red_meat_g_d\",\"ssb_ml_d\",\"fibre_g_d\",\"salt_g_d\"]\n",
    "cont = [c for c in cont if c in df_imp.columns]\n",
    "cat  = [\"sex\",\"smoking_status\",\"physical_activity\",\"IMD_quintile\",\"SES_class\"]\n",
    "cat = [c for c in cat if c in df_imp.columns]\n",
    "\n",
    "import pandas as pd\n",
    "blocks = []\n",
    "for c in cont:\n",
    "    g = df_imp.groupby(by)[c].agg([\"mean\",\"std\",\"median\",\"count\"]).round(2)\n",
    "    g.columns = pd.MultiIndex.from_product([[c], g.columns])\n",
    "    blocks.append(g)\n",
    "cont_block = pd.concat(blocks, axis=1) if blocks else pd.DataFrame()\n",
    "cat_blocks = []\n",
    "for c in cat:\n",
    "    g = df_imp.groupby([by, c]).size().unstack(fill_value=0)\n",
    "    g.columns = pd.MultiIndex.from_product([[c], g.columns])\n",
    "    cat_blocks.append(g)\n",
    "cat_block = pd.concat(cat_blocks, axis=1) if cat_blocks else pd.DataFrame()\n",
    "\n",
    "table1 = pd.concat([cont_block, cat_block], axis=1)\n",
    "table1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Table 1 (CSV) for submission bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"submission\", exist_ok=True)\n",
    "table1.to_csv(\"submission/table1.csv\")\n",
    "print(\"Saved submission/table1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Primary analysis — Logistic regression (unadjusted & adjusted)\n",
    "Unadjusted: `OUTCOME ~ EXPOSURE`  \n",
    "Adjusted: `OUTCOME ~ EXPOSURE + ADJUST_VARS` (justify via DAG/epidemiological reasoning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "\n",
    "model_df = df[[OUTCOME, EXPOSURE] + ADJUST_VARS].dropna().copy()\n",
    "print(\"Complete-case rows:\", model_df.shape[0])\n",
    "\n",
    "# Unadjusted\n",
    "y_u, X_u = dmatrices(f\"{OUTCOME} ~ {EXPOSURE}\", data=model_df, return_type=\"dataframe\")\n",
    "fit_u = sm.Logit(y_u, X_u).fit(disp=False)\n",
    "OR_u = (np.exp(fit_u.params).rename(\"OR\")\n",
    "        .to_frame().join(np.exp(fit_u.conf_int()).rename(columns={0:\"2.5%\",1:\"97.5%\"})))\n",
    "\n",
    "# Adjusted (categoricals to factors via patsy C())\n",
    "def fmt_term(v):\n",
    "    return f\"C({v})\" if (model_df[v].dtype==\"object\" or str(model_df[v].dtype).startswith(\"category\")) else v\n",
    "rhs_terms = [fmt_term(v) for v in [EXPOSURE] + ADJUST_VARS]\n",
    "formula_a = f\"{OUTCOME} ~ \" + \" + \".join(rhs_terms)\n",
    "y_a, X_a = dmatrices(formula_a, data=model_df, return_type=\"dataframe\")\n",
    "fit_a = sm.Logit(y_a, X_a).fit(disp=False)\n",
    "OR_a = (np.exp(fit_a.params).rename(\"OR\")\n",
    "        .to_frame().join(np.exp(fit_a.conf_int()).rename(columns={0:\"2.5%\",1:\"97.5%\"})))\n",
    "\n",
    "OR_u.round(3), OR_a.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model outputs for submission bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR_u.round(4).to_csv(\"submission/or_unadjusted.csv\")\n",
    "OR_a.round(4).to_csv(\"submission/or_adjusted.csv\")\n",
    "with open(\"submission/formula.txt\",\"w\") as f:\n",
    "    f.write(formula_a + \"\\n\")\n",
    "print(\"Saved submission/or_*.csv and submission/formula.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) DAG (optional but recommended)\n",
    "Provide a simple DAG for your question (e.g., `red_meat_g_d → Cancer_incident`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import networkx as nx, matplotlib.pyplot as plt\n",
    "    G = nx.DiGraph()\n",
    "    exposure = EXPOSURE\n",
    "    outcome  = OUTCOME\n",
    "    # >>> EDIT: propose your confounders here (mirrors ADJUST_VARS)\n",
    "    conf = [v for v in ADJUST_VARS]\n",
    "    for c in conf:\n",
    "        G.add_edge(c, exposure)\n",
    "        G.add_edge(c, outcome)\n",
    "    G.add_edge(exposure, outcome)\n",
    "    pos = nx.spring_layout(G, seed=11088)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    nx.draw_networkx(G, pos=pos, node_size=1200, font_size=9)\n",
    "    plt.axis('off'); os.makedirs(\"submission\", exist_ok=True)\n",
    "    plt.tight_layout(); plt.savefig(\"submission/dag.png\", dpi=200)\n",
    "    plt.show()\n",
    "    print(\"Saved submission/dag.png\")\n",
    "except Exception as e:\n",
    "    print(\"DAG skipped:\", e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 500-word write-up (methods, results, interpretation, limitations)\n",
    "Write **~500 words**. The cell below will check length and save `submission/summary.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = r'''\n",
    "Replace this with ~500 words covering:\n",
    "- **Question** & rationale (exposure, outcome)\n",
    "- **Data & methods** (cohort; Table 1 approach; model; adjustment set; missingness handling)\n",
    "- **Results** (OR [95% CI] for exposure; any sensitivity observation)\n",
    "- **Interpretation** (direction/size; plausibility; comparison to literature if relevant)\n",
    "- **Limitations** (measurement error, residual confounding, selection, model simplifications)\n",
    "'''\n",
    "wc = len(TEXT.split())\n",
    "print(f\"Word count: {wc}\")\n",
    "assert 350 <= wc <= 650, \"Aim for roughly 500 words (350–650 permitted).\"  # relaxed band\n",
    "os.makedirs(\"submission\", exist_ok=True)\n",
    "with open(\"submission/summary.txt\",\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(TEXT.strip()+\"\\n\")\n",
    "print(\"Saved submission/summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Export submission bundle (zip)\n",
    "Creates `submission_<exposure>_to_<outcome>.zip` containing: Table 1 CSV, OR tables, formula, DAG PNG (if any), 500-word text, and an HTML export of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, zipfile, pathlib, subprocess, shlex\n",
    "stem = f\"submission_{EXPOSURE}_to_{OUTCOME}\"\n",
    "zip_path = f\"{stem}.zip\"\n",
    "\n",
    "# HTML export (best-effort; works in Colab and Jupyter if nbconvert present)\n",
    "try:\n",
    "    r = subprocess.run(shlex.split(\"jupyter nbconvert --to html --output submission/notebook.html --execute --inplace False\"), check=False)\n",
    "    if r.returncode != 0:\n",
    "        raise RuntimeError(\"nbconvert failed or missing; continuing without HTML export.\")\n",
    "except Exception as e:\n",
    "    print(\"Notebook HTML export skipped:\", e)\n",
    "\n",
    "files = [\n",
    "    \"submission/table1.csv\",\n",
    "    \"submission/or_unadjusted.csv\",\n",
    "    \"submission/or_adjusted.csv\",\n",
    "    \"submission/formula.txt\",\n",
    "    \"submission/summary.txt\",\n",
    "    \"submission/notebook.html\",\n",
    "    \"submission/dag.png\"\n",
    "]\n",
    "files = [f for f in files if pathlib.Path(f).exists()]\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as z:\n",
    "    for f in files:\n",
    "        z.write(f)\n",
    "print(\"Created:\", zip_path)\n",
    "zip_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
