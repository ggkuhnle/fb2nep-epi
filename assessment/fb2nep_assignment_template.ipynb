{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0767b358",
   "metadata": {},
   "source": [
    "# FB2NEP — Data Analysis Notebook (Assessment)\n",
    "\n",
    "This notebook supports the **FB2NEP assessment**. Complete the **Data mapping** cell and use the provided code to answer the question paper. The notebook allows:\n",
    "- Describing the study population (Table 1) with comparisons by factors like sex, deprivation, or disease incidence.\n",
    "- Comparing groups with/without cancer or CVD.\n",
    "- Assessing whether data are missing at random.\n",
    "- Analysing associations between nutrient intake and blood pressure (BP) or disease (via logistic or Cox regression).\n",
    "- Exploring different models and data transformations.\n",
    "- Drawing conclusions based on results.\n",
    "\n",
    "Set `ADD_JITTER` to `True` to add random noise to continuous variables (for varied results). If running on Google Colab, the repository will be cloned automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, sys, math, json, textwrap, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "from lifelines import CoxPHFitter  # For Cox regression\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "print(\"Versions:\")\n",
    "print(\"pandas\", pd.__version__)\n",
    "print(\"statsmodels\", sm.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "\n",
    "# Detect if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# Option to add jitter to continuous variables\n",
    "ADD_JITTER = False  # Set to True to add random noise\n",
    "JITTER_SCALE = 0.05  # Standard deviation of noise as proportion of variable std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d064ff",
   "metadata": {},
   "source": [
    "## Data mapping (REQUIRED)\n",
    "\n",
    "Assign the correct column names from `fb2nep.csv` to the variables below. Run the next cell to list columns if unsure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf61428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository if in Colab\n",
    "if IN_COLAB:\n",
    "    !git clone https://github.com/ggkuhnle/fb2nep-epi.git\n",
    "    %cd fb2nep-epi\n",
    "\n",
    "from scripts.bootstrap import init\n",
    "df, ctx = init()\n",
    "\n",
    "# Add jitter to continuous variables if enabled\n",
    "if ADD_JITTER:\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        noise = np.random.normal(0, df[col].std() * JITTER_SCALE, size=len(df))\n",
    "        df[col] = df[col] + noise\n",
    "    print(\"Jitter added to numeric columns\")\n",
    "\n",
    "print(df.shape, \"— dataset ready\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b8ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDIT THIS CELL ===\n",
    "# Map dataset columns here (strings). Use exact column names from fb2nep.csv.\n",
    "\n",
    "MAPPING = {\n",
    "    # Primary outcome (binary recommended: 0/1). Example: \"CVD_Incidence\"\n",
    "    \"outcome\": \"<OUTCOME_COL>\",\n",
    "    # Time-to-event for Cox regression (if applicable). Example: \"time_to_event\"\n",
    "    \"time\": \"<TIME_COL>\",\n",
    "    # Primary exposure: biomarker variable (continuous). Example: \"flavanol_biomarker\"\n",
    "    \"exposure_biomarker\": \"<BIOMARKER_COL>\",\n",
    "    # Secondary exposure: diet diary (DD) variable (continuous). Example: \"flavanol_dd\"\n",
    "    \"exposure_dd\": \"<DD_COL>\",\n",
    "    # Blood pressure (continuous). Example: \"systolic_bp\"\n",
    "    \"bp\": \"<BP_COL>\",\n",
    "    # Demographics/covariates\n",
    "    \"id\": \"<ID_COL>\",                 # e.g., \"ID\" or \"participant_id\"\n",
    "    \"age\": \"<AGE_COL>\",               # e.g., \"age\"\n",
    "    \"sex\": \"<SEX_COL>\",               # e.g., \"sex\" coded as 0/1 or 'M'/'F'\n",
    "    \"bmi\": \"<BMI_COL>\",               # e.g., \"BMI\"\n",
    "    \"smoking\": \"<SMOKING_COL>\",       # e.g., 'never','former','current'\n",
    "    \"ses\": \"<SES_COL>\",               # socioeconomic status\n",
    "    # Add other confounders as needed:\n",
    "    # \"physical_activity\": \"<PA_COL>\",\n",
    "    # \"energy_intake\": \"<ENERGY_COL>\",\n",
    "}\n",
    "\n",
    "# Candidate confounders for models\n",
    "CANDIDATE_CONFOUNDERS = [\"age\", \"sex\", \"bmi\", \"smoking\", \"ses\"]\n",
    "\n",
    "# Outcome type\n",
    "OUTCOME_IS_BINARY = True  # Set to False if outcome is continuous\n",
    "USE_COX = False  # Set to True for Cox regression (requires 'time' in MAPPING)\n",
    "\n",
    "# Data transformation options\n",
    "TRANSFORM = None  # Options: None, 'log', 'sqrt', or lambda x: <custom>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd020d6",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fb2nep.csv\n",
    "def load_fb2nep():\n",
    "    DATA_PATHS = [Path(p) for p in [\"./data/fb2nep.csv\", \"./fb2nep.csv\", \"../data/fb2nep.csv\"]]\n",
    "    for p in DATA_PATHS:\n",
    "        if p.exists():\n",
    "            return pd.read_csv(p)\n",
    "    raise FileNotFoundError(\"fb2nep.csv not found. Place it in ./data, ./, or ../data\")\n",
    "\n",
    "df = load_fb2nep()\n",
    "\n",
    "# Apply transformations\n",
    "def apply_transform(data, col, transform):\n",
    "    if transform == 'log':\n",
    "        return np.log1p(data[col])\n",
    "    elif transform == 'sqrt':\n",
    "        return np.sqrt(data[col])\n",
    "    elif callable(transform):\n",
    "        return transform(data[col])\n",
    "    return data[col]\n",
    "\n",
    "if TRANSFORM:\n",
    "    for key in ['exposure_biomarker', 'exposure_dd', 'bp']:\n",
    "        if MAPPING.get(key) in df.columns:\n",
    "            df[MAPPING[key]] = apply_transform(df, MAPPING[key], TRANSFORM)\n",
    "            print(f\"Applied {TRANSFORM} transformation to {MAPPING[key]}\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cc97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate mapping and coerce types\n",
    "def validate_mapping(df, mapping):\n",
    "    missing = [k for k, v in mapping.items() if isinstance(v, str) and v.startswith(\"<\")]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Please fill in MAPPING for: {missing}\")\n",
    "    for k, v in mapping.items():\n",
    "        if v and v not in df.columns:\n",
    "            raise KeyError(f\"MAPPING[{k}] refers to '{v}', which is not a column in the dataset.\")\n",
    "    if USE_COX and (not mapping.get(\"time\") or mapping[\"time\"] not in df.columns):\n",
    "        raise ValueError(\"Cox regression requires 'time' column in MAPPING.\")\n",
    "    return True\n",
    "\n",
    "validate_mapping(df, MAPPING)\n",
    "\n",
    "def coerce_types(d, mapping, outcome_is_binary=True):\n",
    "    d = d.copy()\n",
    "    if mapping.get(\"sex\") in d:\n",
    "        if d[mapping[\"sex\"]].dtype == object:\n",
    "            d[mapping[\"sex\"]] = d[mapping[\"sex\"]].astype(str).str.strip().str[0].str.upper().map({\"M\":0, \"F\":1})\n",
    "    if outcome_is_binary and mapping.get(\"outcome\") in d:\n",
    "        if d[mapping[\"outcome\"]].dtype == object:\n",
    "            d[mapping[\"outcome\"]] = d[mapping[\"outcome\"]].astype(str).str.strip().str.lower().map({\"no\":0, \"yes\":1})\n",
    "        d[mapping[\"outcome\"]] = pd.to_numeric(d[mapping[\"outcome\"]], errors=\"coerce\")\n",
    "    return d\n",
    "\n",
    "df = coerce_types(df, MAPPING, OUTCOME_IS_BINARY)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce03b97",
   "metadata": {},
   "source": [
    "## Table 1: Describe study population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c3bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise variables\n",
    "def summarise_series(s):\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        return pd.Series({\n",
    "            \"n\": s.notna().sum(),\n",
    "            \"mean\": s.mean(),\n",
    "            \"sd\": s.std(),\n",
    "            \"median\": s.median(),\n",
    "            \"iqr\": s.quantile(0.75) - s.quantile(0.25)\n",
    "        })\n",
    "    else:\n",
    "        vc = s.value_counts(dropna=False)\n",
    "        total = len(s)\n",
    "        return pd.Series({f\"{k} (n,%)\": f\"{v} ({v/total*100:.1f}%)\" for k, v in vc.items()})\n",
    "\n",
    "def table1(df, cols, by=None):\n",
    "    out = {}\n",
    "    if by is None or by not in df.columns:\n",
    "        for c in cols:\n",
    "            out[c] = summarise_series(df[c])\n",
    "        res = pd.concat(out, axis=1)\n",
    "    else:\n",
    "        groups = df.groupby(by, dropna=False)\n",
    "        parts = []\n",
    "        for lvl, dsub in groups:\n",
    "            part = pd.concat({c: summarise_series(dsub[c]) for c in cols}, axis=1)\n",
    "            part.columns = pd.MultiIndex.from_product([[f\"{by}={lvl}\"], part.columns])\n",
    "            parts.append(part)\n",
    "        res = pd.concat(parts, axis=1)\n",
    "    return res\n",
    "\n",
    "# Select columns for Table 1\n",
    "cols = [c for c in [MAPPING.get(k) for k in [\"age\", \"sex\", \"bmi\", \"smoking\", \"ses\", \"exposure_biomarker\", \"exposure_dd\", \"bp\"]] if c in df.columns]\n",
    "\n",
    "# Compare by factor (edit 'by' to 'sex', 'ses', 'outcome', etc.)\n",
    "COMPARE_BY = \"sex\"  # Change to MAPPING key (e.g., 'ses', 'outcome') to compare groups\n",
    "tbl1 = table1(df, cols, by=MAPPING.get(COMPARE_BY))\n",
    "tbl1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509f4682",
   "metadata": {},
   "source": [
    "## Missingness audit: Are data missing at random?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae084983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missingness summary\n",
    "def missingness_summary(d):\n",
    "    miss = d.isna().mean().sort_values(ascending=False)\n",
    "    out = pd.DataFrame({\"missing_prop\": miss, \"missing_%\": (miss*100).round(1)})\n",
    "    out[\"n_missing\"] = d.isna().sum()\n",
    "    out[\"n\"] = len(d)\n",
    "    return out\n",
    "\n",
    "miss = missingness_summary(df)\n",
    "miss.head(20)\n",
    "\n",
    "# Test for missing at random (example: compare missingness of exposure_biomarker by outcome)\n",
    "def test_mar(df, var, group_by):\n",
    "    if var not in df.columns or group_by not in df.columns:\n",
    "        return \"Invalid column names\"\n",
    "    miss = df[var].isna()\n",
    "    if df[group_by].dtype == object or pd.api.types.is_categorical_dtype(df[group_by]):\n",
    "        contingency = pd.crosstab(miss, df[group_by])\n",
    "        chi2, p = stats.chi2_contingency(contingency)[:2]\n",
    "        return {\"chi2\": chi2, \"p_value\": p, \"contingency\": contingency}\n",
    "    else:\n",
    "        miss_val = df.loc[miss, group_by]\n",
    "        not_miss_val = df.loc[~miss, group_by]\n",
    "        t_stat, p = stats.ttest_ind(miss_val.dropna(), not_miss_val.dropna(), equal_var=False)\n",
    "        return {\"t_stat\": t_stat, \"p_value\": p}\n",
    "\n",
    "mar_test = test_mar(df, MAPPING.get(\"exposure_biomarker\"), MAPPING.get(\"outcome\"))\n",
    "print(\"MAR test (exposure_biomarker by outcome):\")\n",
    "print(mar_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31151829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise missingness matrix\n",
    "def plot_missingness_matrix(d, max_cols=30):\n",
    "    d = d.copy()\n",
    "    if d.shape[1] > max_cols:\n",
    "        d = d.iloc[:, :max_cols]\n",
    "        print(f\"(Showing first {max_cols} columns)\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(d.isna(), aspect='auto', interpolation='nearest')\n",
    "    plt.xlabel(\"Columns (subset if large)\")\n",
    "    plt.ylabel(\"Rows\")\n",
    "    plt.title(\"Missingness matrix\")\n",
    "    plt.show()\n",
    "\n",
    "plot_missingness_matrix(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456661d1",
   "metadata": {},
   "source": [
    "## Biomarker vs Diet Diary (DD) comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ae29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "biom = MAPPING[\"exposure_biomarker\"]\n",
    "dd = MAPPING[\"exposure_dd\"]\n",
    "\n",
    "biom_valid = df[biom].astype(float)\n",
    "dd_valid = df[dd].astype(float)\n",
    "\n",
    "# Scatter & correlation\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(dd_valid, biom_valid, alpha=0.6)\n",
    "plt.xlabel(f\"{dd}\")\n",
    "plt.ylabel(f\"{biom}\")\n",
    "plt.title(\"Biomarker vs DD: scatter\")\n",
    "plt.show()\n",
    "\n",
    "valid = df[[biom, dd]].dropna()\n",
    "r = valid[biom].corr(valid[dd])\n",
    "print(f\"Pearson r = {r:.3f} (n={len(valid)})\")\n",
    "\n",
    "# Bland–Altman\n",
    "def bland_altman(a, b):\n",
    "    a, b = np.asarray(a), np.asarray(b)\n",
    "    diff = a - b\n",
    "    mean = (a + b) / 2\n",
    "    mdiff = np.mean(diff)\n",
    "    sd = np.std(diff, ddof=1)\n",
    "    loa = (mdiff - 1.96*sd, mdiff + 1.96*sd)\n",
    "    return mean, diff, mdiff, loa\n",
    "\n",
    "mean_ab, diff_ab, mdiff, loa = bland_altman(valid[biom], valid[dd])\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(mean_ab, diff_ab, alpha=0.6)\n",
    "plt.axhline(mdiff)\n",
    "plt.axhline(loa[0])\n",
    "plt.axhline(loa[1])\n",
    "plt.xlabel(\"Mean of biomarker and DD\")\n",
    "plt.ylabel(\"Difference (biomarker − DD)\")\n",
    "plt.title(\"Bland–Altman plot\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean difference: {mdiff:.3f}; 95% LoA: [{loa[0]:.3f}, {loa[1]:.3f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f78ec9",
   "metadata": {},
   "source": [
    "## Association: Nutrient intake and blood pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5665f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression: nutrient intake vs BP\n",
    "def fit_linear_model(df, outcome, exposure, covars=None):\n",
    "    covars = covars or []\n",
    "    rhs = exposure if not covars else f\"{exposure} + {' + '.join(covars)}\"\n",
    "    formula = f\"{outcome} ~ {rhs}\"\n",
    "    d = df[[outcome, exposure] + covars].dropna()\n",
    "    model = smf.ols(formula, data=d).fit()\n",
    "    return model, formula\n",
    "\n",
    "bp = MAPPING.get(\"bp\")\n",
    "exposure = MAPPING.get(\"exposure_biomarker\")\n",
    "if bp and exposure in df.columns:\n",
    "    # Minimal model\n",
    "    bp_model, bp_formula = fit_linear_model(df, bp, exposure)\n",
    "    print(f\"Minimal model: {bp_formula}\")\n",
    "    print(bp_model.summary())\n",
    "\n",
    "    # Adjusted model\n",
    "    prespec_covars = [MAPPING[k] for k in CANDIDATE_CONFOUNDERS if MAPPING.get(k) in df.columns]\n",
    "    bp_adj_model, bp_adj_formula = fit_linear_model(df, bp, exposure, prespec_covars)\n",
    "    print(f\"Adjusted model: {bp_adj_formula}\")\n",
    "    print(bp_adj_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f78ec9",
   "metadata": {},
   "source": [
    "## Association: Nutrient intake and disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5665f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic or Cox regression\n",
    "def make_formula(outcome, exposure, covars=None, binary=True):\n",
    "    rhs = exposure if covars is None or len(covars) == 0 else f\"{exposure} + {' + '.join(covars)}\"\n",
    "    return f\"{outcome} ~ {rhs}\"\n",
    "\n",
    "def fit_model(df, formula, covars=None, binary=True, use_cox=False):\n",
    "    d = df.dropna(subset=(covars or []) + formula.split(\"~\")[1].split(\" + \") + ([MAPPING[\"time\"]] if use_cox else []))\n",
    "    if use_cox:\n",
    "        covars = covars or []\n",
    "        model = CoxPHFitter()\n",
    "        d = d[[MAPPING[\"outcome\"], MAPPING[\"time\"], exposure] + covars]\n",
    "        model.fit(d, duration_col=MAPPING[\"time\"], event_col=MAPPING[\"outcome\"])\n",
    "        return model, d\n",
    "    elif binary:\n",
    "        model = smf.logit(formula, data=d).fit(disp=False)\n",
    "        return model, d\n",
    "    else:\n",
    "        model = smf.ols(formula, data=d).fit()\n",
    "        return model, d\n",
    "\n",
    "outcome = MAPPING[\"outcome\"]\n",
    "exposure = MAPPING[\"exposure_biomarker\"]\n",
    "\n",
    "# Minimal model\n",
    "min_formula = make_formula(outcome, exposure, covars=[], binary=OUTCOME_IS_BINARY)\n",
    "min_model, min_data = fit_model(df, min_formula, binary=OUTCOME_IS_BINARY, use_cox=USE_COX)\n",
    "print(f\"Minimal model: {min_formula}\")\n",
    "if USE_COX:\n",
    "    min_model.print_summary()\n",
    "else:\n",
    "    print(min_model.summary())\n",
    "\n",
    "# Adjusted model\n",
    "prespec_covars = [MAPPING[k] for k in CANDIDATE_CONFOUNDERS if MAPPING.get(k) in df.columns]\n",
    "adj_formula = make_formula(outcome, exposure, covars=prespec_covars, binary=OUTCOME_IS_BINARY)\n",
    "adj_model, adj_data = fit_model(df, adj_formula, covars=prespec_covars, binary=OUTCOME_IS_BINARY, use_cox=USE_COX)\n",
    "print(f\"Adjusted model: {adj_formula}\")\n",
    "if USE_COX:\n",
    "    adj_model.print_summary()\n",
    "else:\n",
    "    print(adj_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f31f201",
   "metadata": {},
   "source": [
    "### Change-in-estimate (≥10%) procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc47ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_effect(model, exposure, binary=True, use_cox=False):\n",
    "    if use_cox:\n",
    "        b = model.params_[exposure]\n",
    "        se = model.standard_errors_[exposure]\n",
    "        hr = np.exp(b)\n",
    "        lo = np.exp(b - 1.96*se)\n",
    "        hi = np.exp(b + 1.96*se)\n",
    "        return {\"effect\": hr, \"lo\": lo, \"hi\": hi, \"scale\": \"HR\"}\n",
    "    elif binary:\n",
    "        b = model.params[exposure]\n",
    "        se = model.bse[exposure]\n",
    "        OR = np.exp(b)\n",
    "        lo = np.exp(b - 1.96*se)\n",
    "        hi = np.exp(b + 1.96*se)\n",
    "        return {\"effect\": OR, \"lo\": lo, \"hi\": hi, \"scale\": \"OR\"}\n",
    "    else:\n",
    "        b = model.params[exposure]\n",
    "        se = model.bse[exposure]\n",
    "        lo = b - 1.96*se\n",
    "        hi = b + 1.96*se\n",
    "        return {\"effect\": b, \"lo\": lo, \"hi\": hi, \"scale\": \"beta\"}\n",
    "\n",
    "base_eff = get_effect(min_model, exposure, OUTCOME_IS_BINARY, USE_COX)[\"effect\"]\n",
    "\n",
    "results = []\n",
    "for k in CANDIDATE_CONFOUNDERS:\n",
    "    cov = MAPPING.get(k)\n",
    "    if not cov or cov not in df.columns:\n",
    "        continue\n",
    "    f = make_formula(outcome, exposure, covars=[cov], binary=OUTCOME_IS_BINARY)\n",
    "    m, _ = fit_model(df, f, covars=[cov], binary=OUTCOME_IS_BINARY, use_cox=USE_COX)\n",
    "    eff = get_effect(m, exposure, OUTCOME_IS_BINARY, USE_COX)[\"effect\"]\n",
    "    change = 100 * (eff - base_eff) / base_eff if base_eff != 0 else np.nan\n",
    "    results.append({\"added\": cov, \"effect\": eff, \"% change vs minimal\": change})\n",
    "\n",
    "cei = pd.DataFrame(results).sort_values(\"% change vs minimal\", key=lambda s: s.abs(), ascending=False)\n",
    "cei\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39deeeb",
   "metadata": {},
   "source": [
    "## Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e42553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardised residuals\n",
    "def standardised_residuals(model, use_cox=False):\n",
    "    if use_cox:\n",
    "        return pd.Series(model.residuals, name=\"martingale_resid\")\n",
    "    elif OUTCOME_IS_BINARY:\n",
    "        return pd.Series(model.resid_pearson, name=\"std_resid\")\n",
    "    else:\n",
    "        return pd.Series(model.get_influence().resid_studentized_internal, name=\"std_resid\")\n",
    "\n",
    "resid = standardised_residuals(adj_model, USE_COX)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(resid.values, marker='o', linestyle='none', alpha=0.6)\n",
    "plt.axhline(3, color='red', linestyle='--')\n",
    "plt.axhline(-3, color='red', linestyle='--')\n",
    "plt.title(\"Residuals (approx.)\")\n",
    "plt.xlabel(\"Observation (index in complete-case sample)\")\n",
    "plt.ylabel(\"Residual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8402e395",
   "metadata": {},
   "source": [
    "## Model exploration helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8402e395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run custom models\n",
    "def run_model_with_covars(outcome, exposure, covars, use_cox=False):\n",
    "    f = make_formula(outcome, exposure, covars=covars, binary=OUTCOME_IS_BINARY)\n",
    "    m, _ = fit_model(df, f, covars=covars, binary=OUTCOME_IS_BINARY, use_cox=use_cox)\n",
    "    print(f\"Formula: {f}\")\n",
    "    if use_cox:\n",
    "        m.print_summary()\n",
    "    else:\n",
    "        print(m.summary())\n",
    "\n",
    "# Example: try different exposure or outcome\n",
    "print(\"Use run_model_with_covars(outcome, exposure, covars, use_cox=False) to experiment.\")\n",
    "print(\"Example: run_model_with_covars(MAPPING['bp'], MAPPING['exposure_dd'], prespec_covars)\")\n",
    "print(\"Set use_cox=True for Cox regression (requires 'time' in MAPPING).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e36e7",
   "metadata": {},
   "source": [
    "## Save mapping snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0bf35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = {\n",
    "    \"mapping\": MAPPING,\n",
    "    \"candidates\": CANDIDATE_CONFOUNDERS,\n",
    "    \"binary_outcome\": OUTCOME_IS_BINARY,\n",
    "    \"use_cox\": USE_COX,\n",
    "    \"transform\": str(TRANSFORM),\n",
    "    \"jitter\": ADD_JITTER,\n",
    "}\n",
    "\n",
    "Path(\"./artifacts\").mkdir(exist_ok=True, parents=True)\n",
    "with open(\"./artifacts/data_mapping_snapshot.json\", \"w\") as f:\n",
    "    json.dump(snapshot, f, indent=2)\n",
    "print(\"Saved ./artifacts/data_mapping_snapshot.json\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
